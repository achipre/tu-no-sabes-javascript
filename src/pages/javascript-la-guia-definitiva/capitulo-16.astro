---
import Navegation from "../../components/Navegation.astro";
import Layoutjavascript from "../../layouts/Layoutjavascript.astro";
---
<Layoutjavascript title="JavaScript: La guia definitiva">
  <Navegation capAnterior="capitulo-15" capSiguiente="capitulo-17" />
  <section class="fadeIn">
    <h1>JavaScript del lado del servidor con Node</h1>
    <p>Node es JavaScript con enlaces al sistema operativo subyacente, lo que permite escribir programas JavaScript que leen y escriben archivos, ejecutan procesos hijo y se comunican a través de la red. Esto hace que Node sea útil como:</p>
    <ul>
      <li class="font-normal">Alternativa moderna a los scripts de shell que no adolece de la sintaxis arcana de bash y otros shells de Unix.</li>
      <li class="font-normal">Lenguaje de programación de uso general para ejecutar programas fiables, no sujeto a las restricciones de seguridad impuestas por los navegadores web al código no fiable.</li>
      <li class="font-normal">Entorno popular para escribir servidores web eficientes y altamente concurrentes.</li>
    </ul>
    <p>La característica que define a Node es su concurrencia basada en eventos de un solo hilo, habilitada por una API asíncrona por defecto. Si has programado en otros lenguajes pero no has hecho mucho código JavaScript, o si eres un programador JavaScript experimentado acostumbrado a escribir código para navegadores web, usar Node será un poco de adaptación, como lo es cualquier lenguaje o entorno de programación nuevo. Este capítulo comienza explicando el modelo de programación de Node, con énfasis en la concurrencia, la API de Node para trabajar con datos en streaming y el tipo Buffer de Node para trabajar con datos binarios. Estas secciones iniciales son seguidas por secciones que resaltan y demuestran algunas de las APIs más importantes de Node, incluyendo aquellas para trabajar con archivos, redes, procesos e hilos.</p>
    <p>Un capítulo no es suficiente para documentar todas las APIs de Node, pero mi esperanza es que este capítulo explique lo suficiente de los fundamentos para hacerte productivo con Node, y confiado en que puedes dominar cualquier nueva API que necesites.</p>
    <article>
      <p class="title-article">Instalación del nodo</p>
      <p>Node es un software de código abierto. Visite <a href="https://nodejs.org">https://nodejs.org</a> para descargar e instalar Node para Windows y MacOS. En Linux, puede instalar Node con su gestor de paquetes nor- mal, o puede visitar <a href="https://nodejs.org/en/download">https://nodejs.org/en/download</a> para descargar los binarios directamente. Si trabajas con software en contenedores, puedes encontrar imágenes Docker oficiales de Node en <a href="https://hub.docker.com">https://hub.docker.com</a>.</p>
      <p>Además del ejecutable de Node, una instalación de Node también incluye npm, un gestor de paquetes que permite acceder fácilmente a un vasto ecosistema de herramientas y librerías JavaScript. Los ejemplos de este capítulo utilizarán únicamente los paquetes integrados de Node y no requerirán npm ni ninguna librería externa</p>
      <p>Por último, no pases por alto la documentación oficial de Node, disponible en <a href="https://nodejs.org/api">https://nodejs.org/api</a> y <a href="https://nodejs.org/docs/guides">https://nodejs.org/docs/guides</a>. La he encontrado bien organizada y bien escrita.</p>
    </article>
  </section>
  <section id="1" class="py-4 xs:py-5 sm:py-6">
    <h2>16.1 Conceptos básicos de programación de nodos</h2>
    <p>Comenzaremos este capítulo con un rápido vistazo a cómo están estructurados los programas Node y cómo interactúan con el sistema operativo.</p>
  </section>
  <section id="1-1">
    <h2>16.1.1 Salida de la consola</h2>
    <p>Si está acostumbrado a programar en JavaScript para navegadores web, una de las pequeñas sorpresas de Node es que <codeinline>console.log()</codeinline> no sólo sirve para depurar, sino que es la forma más sencilla de Node de mostrar un mensaje al usuario o, más en general, de enviar la salida al flujo stdout de . Aquí está el clásico programa "Hola Mundo" en Node:</p>
    <pre>
    <code class="language-js">console.log("Hello World!");</code></pre>
    <p>Hay formas más sencillas de escribir en stdout, pero ninguna más elegante u oficial que simplemente llamar a <codeinline>console.log()</codeinline>.</p>
    <p>En los navegadores web, <codeinline>console.log()</codeinline>, <codeinline>console.warn()</codeinline> y <codeinline>console.error()</codeinline> suelen mostrar pequeños iconos junto a su salida en la consola del desarrollador para indicar la variedad del mensaje de registro. Node no hace esto, pero la salida mostrada <codeinline>console.error()</codeinline> se distingue de la salida mostrada con <codeinline>console.log()</codeinline> porque <codeinline>console.error()</codeinline> escribe en el flujo stderr. Si está utilizando Node para escribir un programa que está diseñado para tener stdout redirigido a un archivo o una tubería, puede utilizar <codeinline>console.error()</codeinline> para mostrar el texto a la consola donde el usuario lo verá, a pesar de que el texto impreso con <codeinline>console.log()</codeinline> está oculto.</p>
  </section>
  <section id="1-2" class="py-4 xs:py-5 sm:py-6">
    <h2>16.1.2 Argumentos de la línea de comandos y variables de entorno</h2>
    <p>Si ha escrito anteriormente programas de estilo Unix diseñados para ser invocados desde un terminal u otra interfaz de línea de comandos, sabrá que estos programas suelen obtener su entrada principalmente de argumentos de línea de comandos y, en segundo lugar, de variables de entorno.</p>
    <p>Node sigue estas convenciones de Unix. Un programa Node puede leer sus argumentos de línea de comandos de la matriz de cadenas <codeinline>process.argv</codeinline>. El primer elemento de este array es siempre la ruta al ejecutable de Node. El segundo argumento es la ruta al archivo de código JavaScript que Node está ejecutando. Cualquier elemento restante en este array son los argumentos separados por espacios que pasaste en la línea de comandos cuando invocaste a Node.</p>
    <p>Por ejemplo, supongamos que guardas este programa Node muy corto en el archivo <em>argv.js</em>:</p>
    <pre>
    <code class="language-js">console.log(process.argv);</code></pre>
    <p>A continuación, puede ejecutar el programa y ver una salida como ésta:</p>
    <pre class="language-js">
    $ node --trace-uncaught argv.js --arg1 --arg2 filename
    [
      '/usr/local/bin/node',
      '/private/tmp/argv.js',
      '--arg1',
      '--arg2',
      'filename'
    ]</pre>
    <p>Hay que tener en cuenta un par de cosas:</p>
    <ul>
      <li class="font-normal">El primer y segundo elemento de <codeinline>process.argv</codeinline> serán rutas de sistema de archivos completamente cualificadas al ejecutable Node y al archivo de JavaScript que se está ejecutando, incluso si no los has escrito de esa forma.</li>
      <li class="font-normal">Los argumentos de línea de comandos que están destinados e interpretados por el propio ejecutable Node son consumidos por el ejecutable Node y no aparecen en <codeinline>process.argv</codeinline>. (El argumento de línea de comandos <codeinline>--trace-uncaught</codeinline> en realidad no está haciendo nada útil en el ejemplo anterior; sólo está ahí para demostrar que no aparece en la salida). Cualquier argumento (como <codeinline>--arg1</codeinline> y <codeinline>filename</codeinline>) que aparezca después del nombre del archivo JavaScript aparecerá en <codeinline>process.argv</codeinline>.</li>
    </ul>
    <p>Los programas Node también pueden tomar información de variables de entorno al estilo Unix. Node las hace disponibles a través del objeto <codeinline>process.env</codeinline>. Los nombres de las propiedades de este objeto son nombres de variables de entorno, y los valores de las propiedades (siempre cadenas) son los valores de esas variables.</p>
    <p>Aquí está una lista parcial de las variables de entorno en mi sistema:</p>
    <pre class="language-js">
    $ node -p -e 'process.env'
    &lbrace;
      SHELL: '/bin/bash',
      USER: 'david',
      PATH: '/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin',
      PWD: '/tmp',
      LANG: 'en_US.UTF-8',
      HOME: '/Users/david',
    }</pre>
    <p>Puede utilizar <codeinline>node -h</codeinline> o <codeinline>node --help</codeinline> para averiguar qué hacen los argumentos de línea de comandos <codeinline>-p</codeinline> y <codeinline>-e</codeinline>. Sin embargo, como sugerencia, observe que podría reescribir la línea anterior como <codeinline>node --eval 'process.env' --print</codeinline>.</p>
  </section>
  <section id="1-3">
    <h2>16.1.3 Ciclo de vida del programa</h2>
    <p>El comando <codeinline>node</codeinline> espera un argumento de línea de comandos que especifique el archivo de código Java-Script que se va a ejecutar. Este archivo inicial suele importar otros módulos de código JavaScript, y también puede definir sus propias clases y funciones. Fundamentalmente, sin embargo, Node ejecuta el código JavaScript en el archivo especificado de arriba a abajo. Algunos programas Node salen cuando terminan de ejecutar la última línea de código en el archivo. A menudo, sin embargo, un programa Node seguirá ejecutándose mucho después de que se haya ejecutado el archivo inicial. Como veremos en las siguientes secciones, los programas Node son a menudo asíncronos y se basan en callbacks y manejadores de eventos. Los programas Node no salen hasta que han terminado de ejecutar el archivo inicial y hasta que todas las llamadas de retorno han sido llamadas y no hay más eventos pendientes. Un programa servidor basado en Node que escucha las conexiones de red entrantes teóricamente funcionará para siempre porque siempre estará esperando más eventos.</p>
    <p>Un programa puede forzarse a salir llamando a <codeinline>process.exit()</codeinline>. Por lo general, los usuarios pueden terminar un programa Node escribiendo Ctrl-C en la ventana de terminal donde se está ejecutando el programa. Un programa puede ignorar Ctrl-C registrando una función manejadora de señales con <codeinline>process.on("SIGINT", ()=>&lbrace;})</codeinline>.</p>
    <p>Si el código de tu programa lanza una excepción y ninguna cláusula <codeinline>catch</codeinline> la atrapa, el programa imprimirá un stack trace y saldrá. Debido a la naturaleza asíncrona de Node, las excepciones que ocurren en callbacks o manejadores de eventos deben ser manejados localmente o no manejados en absoluto, lo que significa que el manejo de las excepciones que se producen en las partes asíncronas de su programa puede ser un problema difícil. Si no quieres que estas excepciones hagan que tu programa se bloquee completamente, registra una función manejadora global que será invocada en lugar de bloquearse:</p>
    <pre>
    <code class="language-js">process.setUncaughtExceptionCaptureCallback(e => &lbrace;
      console.error("Uncaught exception:", e);
    });</code></pre>
    <p>Una situación similar se presenta si una Promise creada por su programa es rechazada y no hay una invocación <codeinline>.catch()</codeinline> para manejarla. A partir de Node 13, esto no es un error fatal que cause la salida del programa, pero imprime un mensaje de error verboso en la consola. En alguna versión futura de Node, se espera que los rechazos de Promise no manejados se conviertan en errores fatales. Si no desea que los rechazos no manejados, impriman mensajes de error o terminen su programa, registre una función manejadora global:</p>
    <pre>
    <code class="language-js">process.on("unhandledRejection", (reason, promise) => &lbrace;
      // reason is whatever value would have been passed to a .catch() function
      // promise is the Promise object that rejected
    });</code></pre>
  </section>
  <section id="1-4" class="py-4 xs:py-5 sm:py-6">
    <h2>16.1.4 Módulos de nodo</h2>
    <p>El <a href="capitulo-10">Capítulo 10</a> documentó los sistemas de módulos de JavaScript, cubriendo tanto los módulos de Node como los de ES6. Como Node fue creado antes de que JavaScript tuviera un sistema de módulos, Node tuvo que crear el suyo propio. El sistema de módulos de Node utiliza la función <codeinline>require()</codeinline> para importar valores a un módulo y el objeto <codeinline>exports</codeinline> o la propiedad <codeinline>module.exports</codeinline> para exportar valores desde un módulo. Estos son una parte fundamental del modelo de programación de Node, y se cubren en detalle en <a href="capitulo-10-2">§10.2</a>.</p>
    <p>Node 13 añade soporte para módulos ES6 estándar así como módulos basados en require (que Node llama "módulos CommonJS"). Los dos sistemas de módulos no son totalmente compatibles, por lo que esto es algo complicado de hacer. Node necesita saber -antes de cargar un módulo- si ese módulo usará <codeinline>require()</codeinline> y <codeinline>module.exports</codeinline> o si usará <codeinline>import</codeinline> y <codeinline>export</codeinline>. Cuando Node carga un archivo de código JavaScript como un módulo CommonJS, define automáticamente la función <codeinline>require()</codeinline> junto con los identificadores <codeinline>exports</codeinline> y <codeinline>module</codeinline>, y no habilita las palabras clave <codeinline>import</codeinline> y <codeinline>export</codeinline>. Por otro lado, cuando Node carga un archivo de código como un módulo ES6, debe habilitar las declaraciones <codeinline>import</codeinline> y <codeinline>export</codeinline>, y <em>no</em> debe definir identificadores extra como <codeinline>require</codeinline>, <codeinline>module</codeinline> y <codeinline>exports</codeinline>.</p>
    <p>La forma más sencilla de decirle a Node qué tipo de módulo está cargando es codificar esta información en la extensión del archivo. Si guarda su código JavaScript en un archivo que termina con <em>.mjs</em>, entonces Node siempre lo cargará como un módulo ES6, esperará que use <codeinline>import</codeinline> y <codeinline>export</codeinline>, y no proporcionará una función <codeinline>require()</codeinline>. Y si guardas tu código en un archivo que termina con <em>.cjs</em>, entonces Node siempre lo tratará como un módulo CommonJS, proveerá una función <codeinline>require()</codeinline>, y arrojará un SyntaxError si usas declaraciones <codeinline>import</codeinline> o <codeinline>export</codeinline>.</p>
    <p>Para los archivos que no tienen una extensión explícita <em>.mjs</em> o <em>.cjs</em>, Node busca un archivo llamado <em>package.json</em> en el mismo directorio que el archivo y luego en cada uno de los directorios que lo contienen. Una vez encontrado el archivo <em>package.json</em> más cercano, Node busca una propiedad type de nivel superior en el objeto JSON. Si el valor de la propiedad type es "module", entonces Node carga el archivo como un módulo ES6. Si el valor de esa propiedad es "commonjs", entonces Node carga el archivo como un módulo CommonJS. Tenga en cuenta que no es necesario tener un archivo <em>package.json</em> para ejecutar programas Node: cuando no se encuentra tal archivo (o cuando se encuentra el archivo pero no tiene una propiedad de <codeinline>type</codeinline>), Node utiliza por defecto módulos CommonJS. Este truco de <em>package.json</em> sólo se hace necesario si quieres usar módulos ES6 con Node y no quieres usar la extensión de archivo <em>.mjs</em>.</p>
    <p>Debido a que existe una enorme cantidad de código Node escrito usando el formato de módulo Com- monJS, Node permite a los módulos ES6 cargar módulos CommonJS usando la palabra clave <codeinline>import</codeinline>. Sin embargo, lo contrario no es cierto: un módulo CommonJS no puede usar <codeinline>require()</codeinline> para cargar un módulo ES6.</p>
  </section>
  <section id="1-5">
    <h2>16.1.5 El gestor de paquetes Node</h2>
    <p>Cuando instalas Node, normalmente obtienes también un programa llamado npm. Este es el gestor de paquetes de Node, y le ayuda a descargar y gestionar las bibliotecas de las que depende su programa. npm mantiene un registro de esas dependencias (así como otra información sobre su programa) en un archivo llamado <em>package.json</em> en el directorio raíz de su proyecto. Este archivo <em>package.json</em> creado por npm es donde añadirías <codeinline>"type": "module"</codeinline> si quisieras usar módulos ES6 para tu proyecto.</p>
    <p>Este capítulo no cubre npm en detalle (pero vea <a href="capitulo-17#4">§17.4</a> para un poco más de profundidad). Lo menciono aquí porque a menos que escriba programas que no usen ninguna librería externa, es casi seguro que usará npm o una herramienta similar. Supongamos, por ejemplo, que vas a desarrollar un servidor web y planeas utilizar el framework Express (<a href="https://expressjs.com">https://expressjs.com</a>) para simplificar la tarea. Para empezar, puedes crear un directorio para tu proyecto, y entonces, en ese directorio escribe <codeinline>npm init</codeinline>. npm te preguntará por el nombre de tu proyecto, número de versión, etc., y entonces creará un archivo <em>package.json</em> inicial basado en tus respuestas.</p>
    <p>Ahora, para empezar a usar Express, escribe <codeinline>npm install express</codeinline>. Esto le dice a npm que descargue la librería Express junto con todas sus dependencias e instale todos los paquetes en un directorio local <em>node_modules/</em>:</p>
    <pre class="language-js">
    $ npm install express
    npm notice created a lockfile as package-lock.json. You should commit this file.
    npm WARN my-server@1.0.0 No description
    npm WARN my-server@1.0.0 No repository field.

    + express@4.17.1
    added 50 packages from 37 contributors and audited 126 packages in 3.058s
    found 0 vulnerabilities</pre>
    <p>Cuando instalas un paquete con npm, npm registra esta dependencia -que tu proyecto depende de Express- en el archivo <em>package.json</em>. Con esta dependencia registrada en <em>package.json</em>, usted podría dar a otro programador una copia de su código y su <em>package.json</em>, y podrían simplemente escribir <codeinline>npm install</codeinline> para descargar automáticamente e instalar en todas las librerías que su programa necesita para ejecutarse.</p>
  </section>
  <section id="2" class="py-4 xs:py-5 sm:py-6">
    <h2>16.2 Node es asíncrono por defecto </h2>
    <p>JavaScript es un lenguaje de programación de propósito general, por lo que es perfectamente posible escribir programas intensivos en CPU que multipliquen grandes matrices o realicen complicados análisis estadísticos. Pero Node se diseñó y optimizó para programas -como los servidores de red- que hacen un uso intensivo de la E/S. Y, en particular, Node fue diseñado para hacer posible la implementación sencilla de servidores altamente concurrentes que puedan manejar muchas peticiones al mismo tiempo.</p>
    <p>Sin embargo, a diferencia de muchos lenguajes de programación, Node no logra la concurrencia con hilos. La programación multihilo es notoriamente difícil de hacer correctamente, y difícil de depurar. Además, los hilos son una abstracción relativamente pesada y si desea escribir un servidor que pueda manejar cientos de solicitudes simultáneas, el uso de cientos de hilos puede requerir una cantidad prohibitiva de memoria. Así que Node adopta el modelo de programación JavaScript de un solo hilo que utiliza la web, y esto resulta ser una gran simplificación que hace que la creación de servidores de red sea una habilidad rutinaria en lugar de arcana.</p>
    <article>
      <p class="title-article">Paralelismo real con Node</p>
      <p>Los programas Node pueden ejecutar múltiples procesos del sistema operativo, y Node 10 y posteriores soportan objetos Worker (<a href="#11">§16.11</a>), que son un tipo de hilo prestado de los navegadores web. Si utiliza múltiples procesos o crea uno o más hilos Worker y ejecuta su programa en un sistema con más de una CPU, entonces su programa ya no será single-threaded y su programa realmente estará ejecutando múltiples flujos de código en paralelo. Estas técnicas pueden ser valiosas para operaciones intensivas de CPU pero no son comúnmente usadas para programas intensivos de E/S como los servidores.</p>
      <p>Cabe destacar, sin embargo, que los procesos y trabajadores de Node evitan la complejidad típica de la programación multihilo, ya que la comunicación entre procesos y trabajadores se realiza mediante el paso de mensajes y no pueden compartir fácilmente la memoria entre ellos.</p>
    </article>
    <p>Node alcanza altos niveles de concurrencia mientras mantiene un modelo de programación de un solo hilo haciendo que su API sea asíncrona y no bloqueante por defecto. Node se toma muy en serio su enfoque no bloqueante y llega a un extremo que puede sorprenderte. Probablemente esperes que las funciones que leen y escriben en la red sean asíncronas, pero Node va más allá y define funciones asíncronas no bloqueantes para leer y escribir archivos del sistema de archivos local. Esto tiene sentido si lo piensas: la API de Node se diseñó en la época en la que los discos duros giraban sobre sí mismos. todavía eran la norma y realmente había milisegundos de "tiempo de búsqueda" de bloqueo mientras se esperaba a que el disco girara antes de que pudiera comenzar una operación de archivo. Y en los centros de datos modernos, el sistema de archivos "local" puede estar en algún lugar de la red, con latencias de red además de las latencias del disco. Pero incluso si leer un archivo de forma asíncrona le parece normal, Node va más allá: las funciones por defecto para iniciar una conexión de red o buscar la hora de modificación de un archivo, por ejemplo, también son no bloqueantes.</p>
    <p>Algunas funciones de la API de Node son síncronas pero no bloqueantes: se ejecutan hasta el final y vuelven sin necesidad de bloquearse. Pero la mayoría de las funciones interesantes realizan algún tipo de entrada o salida, y éstas son funciones asíncronas para evitar el más mínimo bloqueo. Node fue creado antes de que JavaScript tuviera una clase Promise, por lo que las APIs asíncronas de Node están basadas en callbacks. (Si aún no has leído o ya has olvidado el <a href="capitulo-13">Capítulo 13</a>, éste sería un buen momento para volver a ese capítulo). Generalmente, el último argumento que se pasa a una función asíncrona de Node es un callback. Node utiliza devoluciones de <em>llamada de error primero</em>, que normalmente se invocan con dos argumentos. El primer argumento es normalmente <codeinline>null</codeinline> en el caso de que no se haya producido ningún error, y el segundo argumento es cualquier dato o respuesta producida por la función asíncrona original a la que se ha llamado. La razón de poner el argumento de error en primer lugar es para que sea imposible omitirlo, y siempre se debe comprobar si hay un valor no nulo en este argumento. Si es un objeto Error, o incluso un código de error entero o un mensaje de error de cadena, entonces algo ha ido mal. En este caso, es probable que el segundo argumento de su función callback sea <codeinline>null</codeinline>.</p>
    <p>El siguiente código muestra cómo utilizar la función no bloqueante <codeinline>readFile()</codeinline> para leer un archivo de configuración, analizarlo como JSON y, a continuación, pasar el objeto de configuración analizado a otra llamada de retorno:</p>
    <pre>
    <code class="language-js">const fs = require("fs"); // Require the filesystem module

    // Read a config file, parse its contents as JSON, and pass the
    // resulting value to the callback. If anything goes wrong,
    // print an error message to stderr and invoke the callback with null
    function readConfigFile(path, callback) &lbrace;
      fs.readFile(path, "utf8", (err, text) => &lbrace;
        if (err) &lbrace; // Something went wrong reading the file
          console.error(err);
          callback(null);
          return;
        }
        let data = null;
        try &lbrace;
          data = JSON.parse(text);
        } catch(e) &lbrace; // Something went wrong parsing the file contents
          console.error(e);
        }
        callback(data);
      });
    }</code></pre>
    <p>Node es anterior a las promesas estandarizadas, pero dado que es bastante consistente con sus devoluciones de llamada basadas en errores, es fácil crear variantes basadas en promesas de sus APIs basadas en devoluciones de llamada utilizando la envoltura <codeinline>util.promisify()</codeinline>. Así es como podemos reescribir la función <codeinline>readConfigFile()</codeinline> para que devuelva una Promise:</p>
    <pre>
    <code class="language-js">const util = require("util");
    const fs = require("fs"); // Require the filesystem module
    const pfs = &lbrace; // Promise-based variants of some fs functions
      readFile: util.promisify(fs.readFile)
    };
    function readConfigFile(path) &lbrace;
      return pfs.readFile(path, "utf-8").then(text => &lbrace;
        return JSON.parse(text);
      });
    }</code></pre>
    <p>También podemos simplificar la función anterior basada en promesas utilizando <codeinline>async</codeinline> y <codeinline>await</codeinline> (de nuevo, si aún no has leído el <a href="capitulo-13">Capítulo 13</a>, este sería un buen momento para hacerlo):</p>
    <pre>
    <code class="language-js">
    async function readConfigFile(path) &lbrace;
      let text = await pfs.readFile(path, "utf-8");
      return JSON.parse(text);
    }</code></pre>
    <p>La envoltura <codeinline>util.promisify()</codeinline> puede producir una versión basada en promesas de muchas funciones de Node. En Node 10 y posteriores, el objeto <codeinline>fs.promises</codeinline> tiene una serie de funciones predefinidas basadas en promesas para trabajar con el sistema de archivos. Las discutiremos más adelante en este capítulo, pero tenga en cuenta que en el código anterior, podríamos reemplazar <codeinline>pfs.readFile()</codeinline> con <codeinline>fs.promises.readFile()</codeinline>.</p>
    <p>Hemos dicho que el modelo de programación de Node es asíncrono por defecto. Pero para comodidad del programador, Node define variantes síncronas bloqueantes de muchas de sus funciones, especialmente en el módulo del sistema de archivos. Estas funciones suelen tener nombres claramente etiquetados con <codeinline>Sync</codeinline> al final.</p>
    <p>Cuando un servidor está arrancando y está leyendo sus ficheros de configuración, no está recibiendo peticiones de red todavía, y poca o ninguna concurrencia es posible. Así que en esta situación, realmente no hay necesidad de evitar el bloqueo, y podemos utilizar con seguridad funciones de bloqueo como <codeinline>fs.readFileSync()</codeinline>. Podemos eliminar <codeinline>async</codeinline> y <codeinline>await</codeinline> de este código y escribir una versión puramente síncrona de nuestra función <codeinline>readConfigFile()</codeinline>. En lugar de invocar un callback o devolver una Promise, esta función simplemente devuelve el valor JSON analizado o lanza una excepción:</p>
    <pre>
    <code class="language-js">const fs = require("fs");
    function readConfigFileSync(path) &lbrace;
      let text = fs.readFileSync(path, "utf-8");
      return JSON.parse(text);
    }</code></pre>
    <p>Además de sus devoluciones de llamada de dos argumentos en caso de error, Node también tiene una serie de APIs que utilizan la asincronía basada en eventos, normalmente para manejar el flujo de datos. Cubriremos los eventos de Node con más detalle más adelante.</p>
    <p>Ahora que hemos discutido la agresiva API no bloqueante de Node, volvamos al tema de la concurrencia. Las funciones no bloqueantes incorporadas en Node funcionan usando la versión del sistema operativo de callbacks y manejadores de eventos. Cuando se llama a una de estas funciones, Node toma medidas para iniciar la operación, luego registra algún tipo de controlador de eventos con el sistema operativo para que se le notifique cuando la operación se haya completado. La llamada de retorno que pasaste a la función Node se almacena internamente para que Node pueda invocar tu llamada de retorno cuando el sistema operativo envíe el evento apropiado a Node.</p>
    <p>Este tipo de concurrencia suele denominarse concurrencia basada en eventos. En su núcleo, Node tiene un único hilo que ejecuta un "bucle de eventos". Cuando se inicia un programa Node, ejecuta cualquier código que le hayas dicho que ejecute. Este código presumiblemente llama al menos a una función no bloqueante que causa una llamada de retorno o un manejador de eventos a ser registrado con el sistema operativo. (Si no, entonces has escrito un programa Node síncrono, y Node simplemente sale cuando llega al final). Cuando Node llega al final de tu programa, se bloquea hasta que ocurre un evento, momento en el que el SO lo pone en marcha de nuevo. Node mapea el evento del SO a la llamada de retorno JavaScript que registraste y luego invoca esa función. Tu función callback puede invocar más funciones Node no bloqueantes, haciendo que se registren más manejadores de eventos OS. Una vez que tu función callback termina de ejecutarse, Node vuelve a dormir y el ciclo se repite.</p>
    <p>Para los servidores web y otras aplicaciones de E/S intensivas que pasan la mayor parte de su tiempo esperando entradas y salidas, este estilo de concurrencia basada en eventos es eficiente y eficaz. Un servidor web puede manejar simultáneamente peticiones de 50 clientes diferentes sin necesidad de 50 hilos diferentes, siempre que utilice APIs no bloqueantes y exista algún tipo de mapeo interno desde los sockets de red a las funciones JavaScript para invocar cuando se produce actividad en esos sockets.</p>
  </section>
  <section id="3">
    <h2>16.3 Búferes</h2>
    <p>Uno de los tipos de datos que probablemente utilices con frecuencia en Node -especialmente al leer datos de archivos o de la red- es la clase Buffer. Un Buffer es muy parecido a una cadena, excepto que es una secuencia de bytes en lugar de una secuencia de caracteres. Node se creó antes de que JavaScript soportara arrays tipados (véase <a href="capitulo-11-2">§11.2</a>) y no existiera Uint8Array para representar un array de bytes sin signo. Node definió la clase Buffer para cubrir esa necesidad. Ahora que Uint8Array es parte del lenguaje JavaScript, la clase Buffer de Node es una subclase de Uint8Array.</p>
    <p>Lo que distingue a Buffer de su superclase Uint8Array es que está diseñado para interoperar con cadenas JavaScript: los bytes de un buffer pueden inicializarse a partir de cadenas de caracteres o convertirse en cadenas de caracteres. Una codificación de caracteres asigna cada carácter de un conjunto de caracteres a un número entero. Dada una cadena de texto y una codificación de caracteres, podemos <em>codificar</em> los caracteres de la cadena en una secuencia de bytes. Y dada una secuencia (correctamente codificada) de bytes y una codificación de caracteres, podemos decodificar esos bytes en una secuencia de caracteres. La clase Buffer de Node tiene métodos que realizan tanto la codificación como la decodificación, y puedes reconocer estos métodos porque esperan un argumento de codificación que especifica la codificación a utilizar.</p>
    <p>Las codificaciones en Node se especifican por nombre, como cadenas. Las codificaciones admitidas son:</p>
    <p><codeinline>"utf8"</codeinline></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Este es el valor predeterminado cuando no se especifica ninguna codificación, y es la codificación Unicode que es más probable que utilice.</p>
    <p><codeinline>"utf16le"</codeinline></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Caracteres Unicode de dos bytes, con orden little-endian. Puntos de código por encima de <codeinline>\uffff</codeinline> se codifican como un par de secuencias de dos bytes. La codificación <codeinline>"ucs2"</codeinline> es un alias.</p>
    <p><codeinline>"latin1"</codeinline></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">La codificación ISO-8859-1 de un byte por carácter define un conjunto de caracteres adecuado para muchos idiomas de Europa Occidental. Dado que existe una correspondencia uno a uno entre bytes y caracteres latinos-1, esta codificación también se conoce como <codeinline>"binary"</codeinline>.</p>
    <p><codeinline>"ascii"</codeinline></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">La codificación ASCII de 7 bits sólo en inglés, un subconjunto estricto de la codificación <codeinline>"utf8"</codeinline>.</p>
    <p><codeinline>"hex"</codeinline></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Esta codificación convierte cada byte en un par de dígitos hexadecimales ASCII.</p>
    <p><codeinline>"base64"</codeinline></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Esta codificación convierte cada secuencia de tres bytes en una secuencia de cuatro caracteres ascii.</p>
    <p>A continuación se muestra un código de ejemplo que demuestra cómo trabajar con Buffers y cómo convertir a y desde cadenas:</p>
    <pre>
    <code class="language-js">let b = Buffer.from([0x41, 0x42, 0x43]); // &lt;Buffer 41 42 43>
    b.toString()      // => "ABC"; default "utf8"
    b.toString("hex") // => "414243"

    let computer = Buffer.from("IBM3111", "ascii"); // Convert string to Buffer
    for(let i = 0; i &lt; computer.length; i++) &lbrace;      // Use Buffer as byte array
      computer[i]--;                                // Buffers are mutable
    }
    computer.toString("ascii")                    // => "HAL2000"
    computer.subarray(0,3).map(x=>x+1).toString() // => "IBM"

    // Create new "empty" buffers with Buffer.alloc()
    let zeros = Buffer.alloc(1024);     // 1024 zeros
    let ones = Buffer.alloc(128, 1);    // 128 ones
    let dead = Buffer.alloc(1024, "DEADBEEF", "hex"); // Repeating pattern of bytes

    // Buffers have methods for reading and writing multi-byte values
    // from and to a buffer at any specified offset.
    dead.readUInt32BE(0)    // => 0xDEADBEEF
    dead.readUInt32BE(1)    // => 0xADBEEFDE
    dead.readBigUInt64BE(6) // => 0xBEEFDEADBEEFDEADn
    dead.readUInt32LE(1020) // => 0xEFBEADDE</code></pre>
    <p>Si escribes un programa Node que realmente manipula datos binarios, puedes encontrarte usando la clase Buffer extensivamente. Por otro lado, si sólo estás trabajando con texto que se lee o se escribe en un archivo o en la red, entonces sólo encontrarás Buffer como una representación intermedia de tus datos. Varias APIs de Node pueden recibir datos de entrada o devolverlos como cadenas u objetos Buffer. Normalmente, si pasas una cadena, o esperas que se devuelva una cadena, desde una de estas APIs, tendrás que especificar el nombre de la codificación de texto que quieres usar. Y si haces esto, puede que no necesites usar un objeto Buffer.</p>
  </section>
  <section id="4" class="py-4 xs:py-5 sm:py-6">
    <h2>16.4 Eventos y EventEmitter</h2>
    <p>Como se ha descrito, todas las APIs de Node son asíncronas por defecto. Para muchas de ellas, esta asincronía toma la forma de devoluciones de llamada de dos argumentos que se invocan cuando la operación solicitada se ha completado. Pero algunas de las API más complicadas se basan en eventos. Este suele ser el caso cuando la API está diseñada en torno a un objeto en lugar de una función, o cuando una función de devolución de llamada debe ser invocada varias veces, o cuando hay varios tipos de funciones de devolución de llamada que pueden ser necesarias. Consideremos la clase <codeinline>net.Server</codeinline>, por ejemplo: un objeto de este tipo es un socket de servidor que se utiliza para aceptar conexiones entrantes de clientes. Emite un evento "listening" cuando empieza a escuchar conexiones, un evento "connection" cada vez que un cliente se conecta, y un evento "close" cuando se ha cerrado y ya no está escuchando.</p>
    <p>En Node, los objetos que emiten eventos son instancias de EventEmitter o una subclase de EventEmitter:</p>
    <pre>
    <code class="language-js">const EventEmitter = require("events"); // Module name does not match class name
    const net = require("net");
    let server = new net.Server();          // create a Server object
    server instanceof EventEmitter          // => true: Servers are EventEmitters</code></pre>
    <p>La principal característica de los EventEmitters es que permiten registrar funciones manejadoras de eventos con el método <codeinline>on()</codeinline>. Los EventEmitters pueden emitir múltiples tipos de eventos, y los tipos de eventos se identifican por su nombre. Para registrar un manejador de eventos, llame al método <codeinline>on()</codeinline>, pasando el nombre del tipo de evento y la función que debe invocarse cuando se produce un evento de ese tipo. Los EventEmitters pueden invocar funciones manejadoras con cualquier número de argumentos, y necesitas leer la documentación para un tipo específico de evento de un EventEmitter específico para saber qué argumentos deberías esperar que se pasen:</p>
    <pre>
    <code class="language-js">const net = require("net");
    let server = new net.Server();      // create a Server object
    server.on("connection", socket => &lbrace; // Listen for "connection" events
      // Server "connection" events are passed a socket object
      // for the client that just connected. Here we send some data
      // to the client and disconnect.
      socket.end("Hello World", "utf8");
    });</code></pre>
    <p>Si prefieres nombres de métodos más explícitos para registrar escuchadores de eventos, también puedes utilizar <codeinline>addListener()</codeinline>. Y puedes eliminar un receptor de eventos previamente registrado con <codeinline>off()</codeinline> o <codeinline>removeListener()</codeinline>. Como caso especial, puedes registrar un escuchador de eventos que se eliminará automáticamente después de que se active por primera vez llamando a <codeinline>once()</codeinline> en lugar de <codeinline>on()</codeinline>.</p>
    <p>Cuando ocurre un evento de un tipo particular para un objeto EventEmitter en particular, Node invoca todas las funciones manejadoras que están actualmente registradas en ese EventEmitter para eventos de ese tipo. Se invocan en orden desde el primero registrado hasta el último. Si hay más de una función manejadora, se invocan secuencialmente en un único hilo: recuerda que no hay paralelismo en Node. Y, lo que es más importante, las funciones manejadoras de eventos se invocan de forma sincrónica, no asincrónica. Lo que esto significa es que el método <codeinline>emit()</codeinline> no pone en cola los manejadores de eventos para ser invocados en algún momento posterior. <codeinline>emit()</codeinline> invoca todos los manejadores registrados, uno tras otro, y no retorna hasta que el último manejador de eventos haya retornado.</p>
    <p>Lo que esto significa, en efecto, es que cuando una de las APIs incorporadas de Node emite un evento, esa API está básicamente bloqueando tus manejadores de eventos. Si escribes un manejador de eventos que llama a una función bloqueante como <codeinline>fs.readFileSync()</codeinline>, no ocurrirá ningún otro manejo de eventos hasta que tu lectura sincrónica de archivos esté completa. Si tu programa es uno -como un servidor de red- que necesita responder, entonces es importante que mantengas tus funciones manejadoras de eventos no bloqueantes y rápidas. Si necesitas hacer muchos cálculos cuando ocurre un evento, a menudo es mejor usar el manejador para programar esos cálculos asíncronamente usando <codeinline>setTimeout()</codeinline> (ver <a href="capitulo-11#10">§11.10</a> ). Node también define <codeinline>setImmediate()</codeinline>, que programa una función para ser invocada inmediatamente después de que todas las llamadas de retorno y eventos pendientes hayan sido manejados.</p>
    <p>La clase EventEmitter también define un método <codeinline>emit()</codeinline> que hace que se invoquen las funciones manejadoras de eventos registradas. Esto es útil si usted está definiendo su propia API basada en eventos, pero no se utiliza comúnmente cuando sólo está programando con APIs existentes. <codeinline>emit()</codeinline> debe ser invocado con el nombre del tipo de evento como su primera argumento. Cualquier argumento adicional que se pase a <codeinline>emit()</codeinline> se convierte en argumento de las funciones manejadoras de eventos registradas. Las funciones manejadoras también son invocadas con el valor this establecido al propio objeto EventEmitter, lo que a menudo es conveniente. (Recuerde, sin embargo, que las funciones de flecha siempre utilizan el valor <codeinline>this</codeinline> del contexto en el que se definen, y no pueden ser invocadas con cualquier otro valor <codeinline>this</codeinline>. No obstante, las funciones de flecha son a menudo la forma más conveniente de escribir manejadores de eventos).</p>
    <p>Cualquier valor devuelto por una función manejadora de eventos es ignorado. Sin embargo, si una función manejadora de eventos lanza una excepción, ésta se propaga desde la llamada a <codeinline>emit()</codeinline> y previene la ejecución de cualquier función manejadora que haya sido registrada después de la que lanzó la excepción.</p>
    <p>Recuerda que las APIs basadas en callbacks de Node utilizan callbacks "error-first", y es importante que siempre compruebes el primer argumento del callback para ver si se ha producido un error. Con las APIs basadas en eventos, el equivalente son los eventos "error". Dado que las APIs basadas en eventos se utilizan a menudo para redes y otras formas de flujo de E/S, son vulnerables a errores asíncronos impredecibles, y la mayoría de los EventEmitters definen un evento "error" que emiten cuando se produce un error. Siempre que utilices una API basada en eventos, deberías tener la costumbre de registrar un manejador para los eventos "error". Los eventos "error" reciben un tratamiento especial por parte de la clase EventEmitter. Si se llama a <codeinline>emit()</codeinline> para emitir un evento de "error" y no hay ningún controlador registrado para ese tipo de evento, se lanzará una excepción. Dado que esto ocurre de forma asíncrona, no hay manera de manejar la excepción en un bloque <codeinline>catch</codeinline>, por lo que este tipo de error suele provocar la salida del programa.</p>
  </section>
  <section id="5">
    <h2>16.5 Arroyos</h2>
    <p>Cuando se implementa un algoritmo para procesar datos, casi siempre es más fácil leer todos los datos en la memoria, hacer el procesamiento, y luego escribir los datos. Por ejemplo, podrías escribir una función de Nodo para copiar un archivo como esta.<sup>1</sup></p>
    <pre>
    <code class="language-js">const fs = require("fs");

    // An asynchronous but nonstreaming (and therefore inefficient) function.
    function copyFile(sourceFilename, destinationFilename, callback) &lbrace;
      fs.readFile(sourceFilename, (err, buffer) => &lbrace;
        if (err) &lbrace;
          callback(err);
        } else &lbrace;
          fs.writeFile(destinationFilename, buffer, callback);
        }
      });
    }</code></pre>
    <p>Esta función <codeinline>copyFile()</codeinline> utiliza funciones asíncronas y callbacks, por lo que no se bloquea y es adecuada para su uso en programas concurrentes como servidores. Pero note que debe asignar suficiente memoria para mantener todo el contenido del archivo en memoria a la vez. Esto puede estar bien en algunos casos de uso, pero empieza a fallar si los ficheros a copiar son muy grandes, o si su programa es altamente concurrente y puede haber muchos ficheros siendo copiados al mismo tiempo. Otro defecto de esta implementación de <codeinline>copyFile()</codeinline> es que no puede comenzar a escribir el nuevo archivo hasta que haya terminado de leer el archivo antiguo.</p>
    <p>La solución a estos problemas es utilizar algoritmos de flujo en los que los datos "fluyen" hacia el programa, se procesan y luego salen de él. La idea es que el algoritmo procese los datos en pequeños fragmentos y que el conjunto completo de datos no se almacene en memoria de una sola vez. Cuando las soluciones de streaming son posibles, son más eficientes en memoria y también pueden ser más rápidas. Las APIs de red de Node están basadas en streaming y el módulo de sistema de archivos de Node define APIs de streaming para leer y escribir archivos, por lo que es probable que utilices una API de streaming en muchos de los programas Node que escribas. Veremos una versión streaming de la función <codeinline>copyFile()</codeinline> en <a href="#modo-flujo">"Modo Flujo"</a>.</p>
    <p>Node admite cuatro tipos básicos de flujo:</p>
    <p><em>Readable</em></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Los flujos legibles son fuentes de datos. El flujo devuelto por <codeinline>fs.createReadStream()</codeinline>, por ejemplo, es un flujo del que se puede leer el contenido de un archivo especificado. <codeinline>process.stdin</codeinline> es otro flujo legible que devuelve datos de la entrada estándar.</p>
    <p><em>Writable</em></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Los flujos de escritura son sumideros o destinos de datos. El valor de retorno de <codeinline>fs.createWriteStream()</codeinline>, por ejemplo, es un flujo escribible: permite que los datos se escriban en él en trozos, y envía todos esos datos a un archivo especificado.</p>
    <p><em>Duplex</em></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Los flujos dúplex combinan un flujo legible y un flujo escribible en un solo objeto. Los objetos Socket devueltos por <codeinline>net.connect()</codeinline> y otras APIs de red de Node, por ejemplo, son flujos Duplex. Si escribe en un socket, sus datos se envían a través de la red a cualquier ordenador al que esté conectado el socket. Y si lees desde un socket, accedes a los datos escritos por ese otro ordenador.</p>
    <p><em>Transform</em></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Los flujos Transform también se pueden leer y escribir, pero difieren de los flujos Duplex en un aspecto importante: los datos escritos en un flujo Transform se leen, normalmente en alguna forma transformada, desde el mismo flujo. La función <codeinline>zlib.creaGzip()</codeinline>, por ejemplo, devuelve un flujo Transform que comprime (con el algoritmo <em>gzip</em>) los datos escritos en él. De forma similar, la función <codeinline>crypto.createCipheriv()</codeinline> devuelve un flujo Transform que encripta o desencripta los datos que se escriben en él.</p>
    <p>Por defecto, los flujos leen y escriben buffers. Si llamas al método <codeinline>setEncoding()</codeinline> de un stream Readable, te devolverá cadenas decodificadas en lugar de objetos Buffer. Y si escribes una cadena en un buffer Writable, se codificará automáticamente usando la codificación por defecto del buffer o cualquier codificación que especifiques. La API de flujos de Node también soporta un "modo objeto" en el que los flujos leen y escriben objetos más complejos que buffers y cadenas. Ninguna de las APIs del núcleo de Node utiliza este modo objeto, pero puede encontrarlo en otras bibliotecas.</p>
    <p>Los flujos legibles tienen que leer sus datos de alguna parte, y los flujos escribibles tienen que escribir sus datos en alguna parte, por lo que cada flujo tiene dos extremos: una entrada y una salida o una fuente y un destino. Lo complicado de las APIs basadas en flujos es que l o s dos extremos del flujo casi siempre fluyen a velocidades diferentes. Puede que el código que lee de un flujo quiera leer y procesar los datos más rápido de lo que se escriben en el flujo. O al revés: tal vez los datos se escriben en un flujo más rápido de lo que pueden leerse y extraerse del flujo en el otro extremo. Las implementaciones de flujos casi siempre incluyen un búfer interno para almacenar los datos que se han escrito pero que aún no se han leído. El almacenamiento en búfer ayuda a garantizar que hay datos disponibles para leer cuando se solicitan, y que hay espacio para mantener los datos cuando se escriben. Pero ninguna de estas cosas puede garantizarse nunca, y es la naturaleza de la programación basada en flujos que los lectores a veces tendrán que esperar a que los datos se escriban (porque el búfer del flujo está vacío), y los escritores a veces tendrán que esperar a que los datos se lean (porque el búfer del flujo está lleno).</p>
    <p>En entornos de programación que utilizan concurrencia basada en hilos, las APIs de flujo normalmente tienen llamadas de bloqueo: una llamada para leer datos no vuelve hasta que los datos llegan al flujo y una llamada para escribir datos se bloquea hasta que hay suficiente espacio en el búfer interno del flujo para acomodar los nuevos datos. Sin embargo, con un modelo de concurrencia basado en eventos, las llamadas de bloqueo no tienen sentido, y las APIs de flujo de Node están basadas en eventos y callbacks. A diferencia de otras APIs de Node, no hay versiones "Sync" de los métodos que se describirán más adelante en este capítulo.</p>
    <p>La necesidad de coordinar la legibilidad del flujo (búfer no vacío) y la escritura (búfer no lleno) a través de eventos hace que las APIs de flujo de Node sean algo complicadas. Esto se ve agravado por el hecho de que estas APIs han evolucionado y cambiado a lo largo de los años: para flujos legibles, hay dos APIs completamente distintas que puedes usar. A pesar de la complejidad, vale la pena entender y dominar las APIs de streaming de Node porque permiten una E/S de alto rendimiento en tus programas.</p>
    <p>Las subsecciones siguientes muestran cómo leer y escribir desde las clases de flujo de Node.</p>
  </section>
  <section id="5-1" class="py-4 xs:py-5 sm:py-6">
    <h2>16.5.1 Tuberías</h2>
    <p>A veces, es necesario leer datos de un flujo para luego escribir esos mismos datos en otro flujo. Imagina, por ejemplo, que estás escribiendo un simple archivo Servidor HTTP que sirve un directorio de archivos estáticos. En este caso, necesitarás leer datos de un archivo de entrada y escribirlos en un socket de red. Pero en lugar de escribir tu propio código para manejar la lectura y escritura, puedes simplemente conectar los dos sockets juntos como una "tubería" y dejar que Node maneje las complejidades por ti. Simplemente pasa el flujo Writable al método <codeinline>pipe()</codeinline> del flujo Readable:</p>
    <pre>
    <code class="language-js">const fs = require("fs");

    function pipeFileToSocket(filename, socket) &lbrace;
      fs.createReadStream(filename).pipe(socket);
    }</code></pre>
    <p>La siguiente función de utilidad canaliza un flujo a otro e invoca una llamada de retorno cuando termina o cuando se produce un error:</p>
    <pre>
    <code class="language-js">function pipe(readable, writable, callback) &lbrace;
      // First, set up error handling
      function handleError(err) &lbrace;
        readable.close();
        writable.close();
        callback(err);
      }

      // Next define the pipe and handle the normal termination case
      readable
        .on("error", handleError)
        .pipe(writable)
        .on("error", handleError)
        .on("finish", callback);
    }</code></pre>
    <p>Los flujos de transformación son particularmente útiles con las tuberías, y crean tuberías que implican más de dos flujos. He aquí una función de ejemplo que comprime un archivo:</p>
    <pre>
    <code class="language-js">const fs = require("fs");
    const zlib = require("zlib");

    function gzip(filename, callback) &lbrace;
      // Create the streams
      let source = fs.createReadStream(filename);
      let destination = fs.createWriteStream(filename + ".gz");
      let gzipper = zlib.createGzip();

      // Set up the pipeline
      source
        .on("error", callback)    // call callback on read error
        .pipe(gzipper)
        .pipe(destination)
        .on("error", callback)    // call callback on write error
        .on("finish", callback);  // call callback when writing is complete
    }</code></pre>
    <p>Usar el método <codeinline>pipe()</codeinline> para copiar datos de un flujo Legible a un flujo Legible es fácil, pero en la práctica, a menudo necesitas procesar los datos de alguna manera mientras fluyen a través de tu programa. Una forma de hacer esto es implementar su propio flujo Transform para hacer ese procesamiento, y este enfoque le permite evitar la lectura y escritura manual de los flujos. Aquí, por ejemplo, hay una función que funciona como la utilidad <codeinline>grep</codeinline> de Unix: lee líneas de texto de un flujo de entrada, pero escribe sólo las líneas que coinciden con una expresión regular especificada:</p>
    <pre>
    <code class="language-js">const stream = require("stream");

    class GrepStream extends stream.Transform &lbrace;
      constructor(pattern) &lbrace;
        super(&lbrace;decodeStrings: false}); // Don't convert strings back to buffers
        this.pattern = pattern;        // The regular expression we want to match
        this.incompleteLine = "";      // Any remnant of the last chunk of data
      }

      // This method is invoked when there is a string ready to be
      // transformed. It should pass transformed data to the specified
      // callback function. We expect string input so this stream should
      // only be connected to readable streams that have had
      // setEncoding() called on them.
      _transform(chunk, encoding, callback) &lbrace;
        if (typeof chunk !== "string") &lbrace;
          callback(new Error("Expected a string but got a buffer"));
          return;
        }
        // Add the chunk to any previously incomplete line and break
        // everything into lines
        let lines = (this.incompleteLine + chunk).split("\n");

        // The last element of the array is the new incomplete line
        this.incompleteLine = lines.pop();

        // Find all matching lines
        let output = lines          // Start with all complete lines,
          .filter(l => this.pattern.test(l)) // filter them for matches,
          .join("\n");              // and join them back up.

        // If anything matched, add a final newline
        if (output) &lbrace;
          output += "\n";
        }
        // Always call the callback even if there is no output
        callback(null, output);
      }
      // This is called right before the stream is closed.
      // It is our chance to write out any last data.
      _flush(callback) &lbrace;
        // If we still have an incomplete line, and it matches
        // pass it to the callback
        if (this.pattern.test(this.incompleteLine)) &lbrace;
          callback(null, this.incompleteLine + "\n");
        }
      }
    }

    // Now we can write a program like 'grep' with this class.
    let pattern = new RegExp(process.argv[2]); // Get a RegExp from command line.
    process.stdin                         // Start with standard input,
      .setEncoding("utf8")                // read it as Unicode strings,
      .pipe(new GrepStream(pattern))      // pipe it to our GrepStream,
      .pipe(process.stdout)               // and pipe that to standard out.
      .on("error", () => process.exit()); // Exit gracefully if stdout closes.</code></pre>
  </section>
  <section id="5-2">
    <h2>16.5.2 Iteración asíncrona</h2>
    <p>En Nodo 12 y posteriores, los flujos legibles son iteradores asíncronos, lo que significa que dentro de una función <codeinline>async</codeinline> puedes usar un bucle <codeinline>for/await</codeinline> para leer trozos de cadena o Buffer de un flujo usando código que está estructurado como lo estaría el código síncrono. (Ver <a href="capitulo-13#4">§13.4</a> para más información sobre iteradores asíncronos y bucles <codeinline>for/await</codeinline>).</p>
    <p>Usar un iterador asíncrono es casi tan fácil como usar el método <codeinline>pipe()</codeinline>, y es probablemente más fácil cuando necesitas procesar cada trozo que lees de alguna manera. Así es como podríamos reescribir el programa <codienline>grep</codienline> de la sección anterior usando una función <codeinline>async</codeinline> y un bucle <codeinline>for/await</codeinline>:</p>
    <pre>
    <code class="language-js">// Read lines of text from the source stream, and write any lines
    // that match the specified pattern to the destination stream.
    async function grep(source, destination, pattern, encoding="utf8") &lbrace;
      // Set up the source stream for reading strings, not Buffers
      source.setEncoding(encoding);

      // Set an error handler on the destination stream in case standard
      // output closes unexpectedly (when piping output to `head`, e.g.)
      destination.on("error", err => process.exit());

      // The chunks we read are unlikely to end with a newline, so each will
      // probably have a partial line at the end. Track that here
      let incompleteLine = "";

      // Use a for/await loop to asynchronously read chunks from the input stream
      for await (let chunk of source) &lbrace;
        // Split the end of the last chunk plus this one into lines
        let lines = (incompleteLine + chunk).split("\n");
        // The last line is incomplete
        incompleteLine = lines.pop();
        // Now loop through the lines and write any matches to the destination
        for(let line of lines) &lbrace;
          if (pattern.test(line)) &lbrace;
            destination.write(line + "\n", encoding);
          }
        }
      }
      // Finally, check for a match on any trailing text.
      if (pattern.test(incompleteLine)) &lbrace;
        destination.write(incompleteLine + "\n", encoding);
      }
    }

    let pattern = new RegExp(process.argv[2]);    // Get a RegExp from command line.
    grep(process.stdin, process.stdout, pattern)  // Call the async grep() function.
      .catch(err => &lbrace; // Handle asynchronous exceptions.
        console.error(err);
        process.exit();
      });</code></pre>
  </section>
  <section id="5-3" class="py-4 xs:py-5 sm:py-6">
    <h2>16.5.3 Escribir en Streams y manejar la contrapresión</h2>
    <p>La función async <codeinline>grep()</codeinline> en el ejemplo de código anterior demostró cómo usar un flujo Readable como un iterador asíncrono, pero también demostró que puedes escribir datos a un flujo Writable simplemente pasándolo al método <codeinline>write()</codeinline>. El método <codeinline>write()</codeinline> toma un buffer o cadena como primer argumento. (Los flujos de objetos esperan otros tipos de objetos, pero están fuera del alcance de este capítulo). Si pasas un buffer, los bytes de ese buffer serán escritos directamente. Si pasas una cadena, será codificada en un buffer de bytes antes de ser escrita. Los flujos escribibles tienen una codificación por defecto que se utiliza cuando se pasa una cadena como único argumento a <codeinline>write()</codeinline>. La codificación por defecto es típicamente "utf8", pero puedes establecerla explícitamente llamando a <codeinline>setDefaultEncoding()</codeinline> en el flujo Writable. Alternativamente, cuando se pasa una cadena como primer argumento a <codeinline>write()</codeinline> se puede pasar un nombre de codificación como segundo argumento.</p>
    <p><codeinline>write()</codeinline> toma opcionalmente una función callback como tercer argumento. Esta será invocada cuando los datos hayan sido realmente escritos y ya no se encuentren en el buffer interno del flujo Writable. (Esta llamada de retorno también puede ser invocada si se produce un error, pero esto no está garantizado. Deberías registrar un manejador de eventos "error" en el flujo Writable para detectar errores).</p>
    <p>El método <codeinline>write()</codeinline> tiene un valor de retorno muy importante. Cuando llamas a <codeinline>write()</codeinline> en un flujo, siempre aceptará y almacenará en el buffer el trozo de datos que le has pasado. Entonces devuelve <codeinline>true</codeinline> si el buffer interno aún no está lleno. O, si el buffer está lleno o sobre-lleno, devuelve <codeinline>false</codeinline>. Este valor de retorno es consultivo, y puede ignorarlo: los flujos escribibles ampliarán su búfer interno tanto como sea necesario si sigue llamando a <codeinline>write()</codeinline>. Pero recuerde que la razón para utilizar una API de flujo en primer lugar es evitar el coste de mantener muchos datos en memoria a la vez.</p>
    <p>Un valor de retorno <codeinline>false</codeinline> del método <codeinline>write()</codeinline> es una forma de <em>contrapresión</em>: una señal del flujo de que has escrito datos más rápido de lo que pueden ser manejados.</p>
    <p>La respuesta adecuada a este tipo de contrapresión es dejar de llamar a <codeinline>write()</codeinline> hasta que el flujo emita un evento "drain", indicando que de nuevo hay espacio en el buffer. Aquí, por ejemplo, hay una función que escribe en un flujo, y luego invoca una llamada de retorno cuando está bien escribir más datos en el flujo:</p>
    <pre>
    <code class="language-js">function write(stream, chunk, callback) &lbrace;
      // Write the specified chunk to the specified stream
      let hasMoreRoom = stream.write(chunk);

      // Check the return value of the write() method:
      if (hasMoreRoom) &lbrace;        // If it returned true, then
        setImmediate(callback); // invoke callback asynchronously.
      } else &lbrace;                  // If it returned false, then
        stream.once("drain", callback); // invoke callback on drain event.
      }
    }</code></pre>
    <p>El hecho de que a veces esté bien llamar a <codeinline>write()</codeinline> varias veces seguidas y algunas veces tengas que esperar un evento entre escrituras hace que los algoritmos sean incómodos. Esta es una de las razones por las que usar el método <codeinline>pipe()</codeinline> es tan atractivo: cuando usas <codeinline>pipe()</codeinline>, Node maneja la contrapresión por ti automáticamente.</p>
    <p>Si estás usando <codeinline>await</codeinline> y <codeinline>async</codeinline> en tu programa, y estás tratando flujos legibles como iteradores asíncronos, es sencillo implementar una versión basada en Promise de la función de utilidad <codeinline>write()</codeinline> varias veces seguidas y algunas veces tengas que esperar un evento entre escrituras hace que los algoritmos sean incómodos. Esta es una de las razones por las que usar el método <codeinline>pipe()</codeinline> es tan atractivo: cuando usas <codeinline>pipe()</codeinline>, Node maneja la contrapresión por ti automáticamente.</p>anterior para manejar adecuadamente la contrapresión. En la función asíncrona <codeinline>grep()</codeinline> que acabamos de ver, no manejamos la contrapresión. La función async <codeinline>copy()</codeinline> del siguiente ejemplo demuestra cómo hacerlo correctamente. Ten en cuenta que esta función sólo copia trozos de un flujo de origen a un flujo de destino y llamar a <codeinline>copy(source, destination)</codeinline> es como llamar a <codeinline>source.pipe(destination)</codeinline>:</p>
    <pre>
    <code class="language-js">
    // This function writes the specified chunk to the specified stream and
    // returns a Promise that will be fulfilled when it is OK to write again.
    // Because it returns a Promise, it can be used with await.
    function write(stream, chunk) &lbrace;
      // Write the specified chunk to the specified stream
      let hasMoreRoom = stream.write(chunk);

      if (hasMoreRoom) &lbrace;                 // If buffer is not full, return
        return Promise.resolve(null);    // an already resolved Promise object
      } else &lbrace;
        return new Promise(resolve => &lbrace;  // Otherwise, return a Promise that
          stream.once("drain", resolve); // resolves on the drain event.
        });
      }
    }
    
    // Copy data from the source stream to the destination stream
    // respecting backpressure from the destination stream.
    // This is much like calling source.pipe(destination).
    async function copy(source, destination) &lbrace;
      // Set an error handler on the destination stream in case standard
      // output closes unexpectedly (when piping output to `head`, e.g.)
      destination.on("error", err => process.exit());

      // Use a for/await loop to asynchronously read chunks from the input stream
      for await (let chunk of source) &lbrace;
        // Write the chunk and wait until there is more room in the buffer.
        await write(destination, chunk);
      }
    }

    // Copy standard input to standard output
    copy(process.stdin, process.stdout);</code></pre>
    <p>Antes de concluir esta discusión sobre la escritura en flujos, ten en cuenta de nuevo que no responder a la contrapresión puede hacer que tu programa use más memoria de la que debería cuando el buffer interno de un flujo escribible se desborde y crezca más y más. Si estás escribiendo un servidor de red, esto puede ser un problema de seguridad explotable remotamente. Supongamos que escribes un servidor HTTP que entrega archivos a través de la red, pero no usas <codeinline>pipe()</codeinline> y no te has tomado el tiempo de manejar la contrapresión del método <codeinline>write()</codeinline>. Un atacante podría escribir un cliente HTTP que inicie peticiones de archivos grandes (como imágenes) pero que nunca lea el cuerpo de la petición. Dado que el cliente no está leyendo los datos a través de la red, y el servidor no está respondiendo a la contrapresión, los buffers en el servidor se desbordarán. Con suficientes conexiones concurrentes del atacante, esto puede convertirse en un ataque de denegación de servicio que ralentice tu servidor o incluso lo bloquee.</p>
  </section>
  <section id="5-4">
    <h2>16.5.4 Lectura de flujos con eventos</h2>
    <p>Los flujos legibles de Node tienen dos modos, cada uno de los cuales tiene su propia API para la lectura. Si no puedes usar tuberías o iteración asíncrona en tu programa, tendrás que elegir una de estas dos APIs basadas en eventos para manejar los flujos. Es importante que utilices sólo una u otra y no mezcles las dos APIs.</p>
    <p id="modo-flujo" class="title-article text-left">Modo de flujo</p>
    <p>En <em>modo flujo</em>, cuando llegan datos legibles, se emiten inmediatamente en forma de evento "datos" . Para leer de un flujo en este modo, simplemente registre un manejador de eventos para eventos "datos", y el flujo le enviará trozos de datos (buffers o cadenas) tan pronto como estén disponibles. Tenga en cuenta que no hay necesidad de llamar al método <codeinline>read()</codeinline> en modo flujo: sólo necesita manejar los eventos "data". Tenga en cuenta que los flujos recién creados no se inician en modo flujo. Registrar un manejador de eventos "data" cambia un flujo al modo de flujo. Convenientemente, esto significa que un flujo no emite eventos "datos" hasta que registras el primer manejador de eventos "datos".</p>
    <p>Si está utilizando el modo de flujo para leer datos de un flujo Legible, procesarlos y luego escribirlos en un flujo Legible, entonces puede que necesite manejar la contrapresión del flujo Legible. Si el método <codeinline>write()</codeinline> devuelve <codeinline>false</codeinline> para indicar que el buffer de escritura está lleno, puedes llamar a <codeinline>pause()</codeinline> en el flujo Legible para detener temporalmente los eventos <codeinline>data</codeinline>. Entonces, cuando recibas un evento de "drenaje" del flujo escribible, puedes llamar a <codeinline>resume()</codeinline> en el flujo legible para que los eventos de "datos" comiencen a fluir de nuevo.</p>
    <p>Un flujo en modo flujo emite un evento "fin" cuando se alcanza el final del flujo. Este evento indica que no se emitirán más eventos "datos". Y, como en todos los flujos, se emite un evento "error" si se produce un error.</p>
    <p>Al principio de esta sección sobre flujos, mostramos una función <codeinline>copyFile()</codeinline> sin flujo y prometimos que vendría una versión mejor. El siguiente código muestra cómo implementar una función <codeinline>copyFile()</codeinline> de flujo que utiliza la API de modo de flujo y maneja la contrapresión. Esto habría sido más fácil de implementar con una llamada a <codeinline>pipe()</codeinline>, pero sirve aquí como una demostración útil de los múltiples manejadores de eventos que se utilizan para coordinar el flujo de datos de un flujo a otro.</p>
    <pre>
    <code class="language-js">const fs = require("fs");

    // A streaming file copy function, using "flowing mode".
    // Copies the contents of the named source file to the named destination file.
    // On success, invokes the callback with a null argument. On error,
    // invokes the callback with an Error object.
    function copyFile(sourceFilename, destinationFilename, callback) &lbrace;
      let input = fs.createReadStream(sourceFilename);
      let output = fs.createWriteStream(destinationFilename);

      input.on("data", (chunk) => &lbrace;        // When we get new data,
        let hasRoom = output.write(chunk); // write it to the output stream.
        if (!hasRoom) &lbrace;  // If the output stream is full
          input.pause(); // then pause the input stream.
        }
      });
      input.on("end", () => &lbrace;     // When we reach the end of input,
        output.end();   // tell the output stream to end.
      });
      input.on("error", err => &lbrace;  // If we get an error on the input,
        callback(err);  // call the callback with the error
        process.exit(); // and quit.
      });
      output.on("drain", () => &lbrace;  // When the output is no longer full,
        input.resume(); // resume data events on the input
      });
      output.on("error", err => &lbrace; // If we get an error on the output,
        callback(err);  // call the callback with the error
        process.exit(); // and quit.
      });
      output.on("finish", () => &lbrace; // When output is fully written
        callback(null); // call the callback with no error.
      });
    }
    // Here's a simple command-line utility to copy files
    let from = process.argv[2], to = process.argv[3];
    console.log(`Copying file $&lbrace;from} to $&lbrace;to}...`);
    copyFile(from, to, err => &lbrace;
      if (err) &lbrace;
        console.error(err);
      } else &lbrace;
        console.log("done.");
      }
    });</code></pre>
    <p class="title-article text-left">Modo pausa</p>
    <p>El otro modo para los flujos legibles es el "modo pausado". Este es el modo en el que comienzan los flujos. Si nunca registras un manejador de eventos "data" y nunca llamas al método <codeinline>pipe()</codeinline>, entonces un flujo Legible permanece en modo pausado. En modo pausado, el flujo no envía datos en forma de eventos "data". En su lugar, usted extrae datos del flujo llamando explícitamente a su método <codeinline>read()</codeinline>. Esta no es una llamada de bloqueo, y si no hay datos disponibles para leer en el flujo, devolverá <codeinline>null</codeinline>. Dado que no existe una API sincrónica para esperar datos, la API del modo pausado también se basa en eventos. Un flujo legible en modo pausado emite eventos "legibles" cuando hay datos disponibles para leer en el flujo. En respuesta, tu código debe llamar al método <codeinline>read()</codeinline> para leer esos datos. Debes hacer esto en un bucle, llamando a <codeinline>read()</codeinline> repetidamente hasta que devuelva <codeinline>null</codeinline>. Es necesario vaciar completamente el buffer del stream de esta manera para poder disparar un nuevo evento "readable" en el futuro. Si dejas de llamar a <codeinline>read()</codeinline> mientras todavía hay datos legibles, no obtendrás otro evento "legible" y es probable que tu programa se cuelgue.</p>
    <p>Los flujos en modo pausado emiten eventos de "fin" y "error" al igual que los flujos en modo continuo. Si estás escribiendo un programa que lee datos de un flujo legible y los escribe en un flujo escribible, entonces el modo pausado puede no ser una buena opción. Para manejar adecuadamente la contrapresión, sólo querrá leer cuando el flujo de entrada sea legible y el flujo de salida no esté respaldado. En el modo pausado, esto significa leer y escribir hasta que <codeinline>read()</codeinline> devuelva <codeinline>null</codeinline> o <codeinline>write()</codeinline> devuelva <codeinline>false</codeinline>, y entonces comenzar a leer o escribir de nuevo en un evento de <codeinline>readable</codeinline> o <codeinline>drain</codeinline>. Esto es poco elegante, y usted puede encontrar que el modo de flujo (o tuberías) es más fácil en este caso.</p>
    <p>El siguiente código demuestra cómo se puede calcular un hash SHA256 para los contenidos de un archivo especificado. Utiliza un flujo legible en modo pausado para leer el contenido de un archivo en trozos, luego pasa cada trozo al objeto que calcula el hash. (Tenga en cuenta que en Node 12 y posteriores, sería más sencillo escribir esta función utilizando un bucle <codeinline>for/await</codeinline>).</p>
    <pre>
    <code class="language-js">const fs = require("fs");
    const crypto = require("crypto");

    // Compute a sha256 hash of the contents of the named file and pass the
    // hash (as a string) to the specified error-first callback function.
    function sha256(filename, callback) &lbrace;
      let input = fs.createReadStream(filename); // The data stream.
      let hasher = crypto.createHash("sha256");  // For computing the hash.

      input.on("readable", () => &lbrace;    // When there is data ready to read
        let chunk;
        while(chunk = input.read()) &lbrace; // Read a chunk, and if non-null,
          hasher.update(chunk);       // pass it to the hasher,
        } // and keep looping until not readable
      });
      input.on("end", () => &lbrace;         // At the end of the stream,
        let hash = hasher.digest("hex"); // compute the hash,
        callback(null, hash);         // and pass it to the callback.
      });
      input.on("error", callback);    // On error, call callback
    }

    // Here's a simple command-line utility to compute the hash of a file
    sha256(process.argv[2], (err, hash) => &lbrace; // Pass filename from command line.
      if (err) &lbrace;                      // If we get an error
        console.error(err.toString());// print it as an error.
      } else &lbrace;                        // Otherwise,
        console.log(hash);            // print the hash string.
      }
    });</code></pre>
  </section>
  <section id="6" class="py-4 xs:py-5 sm:py-6">
    <h2>16.6 Detalles del proceso, la CPU y el sistema operativo</h2>
    <p>El objeto global Process tiene una serie de propiedades y funciones útiles que generalmente se relacionan con el estado del proceso Node que se está ejecutando en ese momento. Consulte la documentación de Node para más detalles, pero aquí hay algunas propiedades y funciones que debe conocer:</p>
    <pre>
    <code class="language-js">process.argv            // An array of command-line arguments.
    process.arch            // The CPU architecture: "x64", for example.
    process.cwd()           // Returns the current working directory.
    process.chdir()         // Sets the current working directory.
    process.cpuUsage()      // Reports CPU usage.
    process.env             // An object of environment variables.
    process.execPath        // The absolute filesystem path to the node executable.
    process.exit()          // Terminates the program.
    process.exitCode        // An integer code to be reported when the program exits.
    process.getuid()        // Return the Unix user id of the current user.
    process.hrtime.bigint() // Return a "high-resolution" nanosecond timestamp.
    process.kill()          // Send a signal to another process.
    process.memoryUsage()   // Return an object with memory usage details.
    process.nextTick()      // Like setImmediate(), invoke a function soon.
    process.pid             // The process id of the current process.
    process.ppid            // The parent process id.
    process.platform        // The OS: "linux", "darwin", or "win32", for example.
    process.resourceUsage() // Return an object with resource usage details.
    process.setuid()        // Sets the current user, by id or name.
    process.title           // The process name that appears in `ps` listings.
    process.umask()         // Set or return the default permissions for new files.
    process.uptime()        // Return Node's uptime in seconds.
    process.version         // Node's version string.
    process.versions        // Version strings for the libraries Node depends on.</code></pre>
    <p>El módulo "os" (que, a diferencia de <codeinline>process</codeinline>, necesita ser cargado explícitamente con <codeinline>require()</codeinline>) proporciona acceso a detalles de bajo nivel similares sobre el ordenador y el sistema operativo en el que se está ejecutando Node. Puede que nunca necesites usar ninguna de estas características, pero vale la pena saber que Node las pone a tu disposición:</p>
    <pre>
    <code class="language-js">const os = require("os");
    os.arch()         // Returns CPU architecture. "x64" or "arm", for example.
    os.constants      // Useful constants such as os.constants.signals.SIGINT.
    os.cpus()         // Data about system CPU cores, including usage times.
    os.endianness()   // The CPU's native endianness "BE" or "LE".
    os.EOL            // The OS native line terminator: "\n" or "\r\n".
    os.freemem()      // Returns the amount of free RAM in bytes.
    os.getPriority()  // Returns the OS scheduling priority of a process.
    os.homedir()      // Returns the current user's home directory.
    os.hostname()     // Returns the hostname of the computer.
    os.loadavg()      // Returns the 1, 5, and 15-minute load averages.
    os.networkInterfaces() // Returns details about available network. connections.
    os.platform()     // Returns OS: "linux", "darwin", or "win32", for example.
    os.release()      // Returns the version number of the OS.
    os.setPriority()  // Attempts to set the scheduling priority for a process.
    os.tmpdir()       // Returns the default temporary directory.
    os.totalmem()     // Returns the total amount of RAM in bytes.
    os.type()         // Returns OS: "Linux", "Darwin", or "Windows_NT", e.g.
    os.uptime()       // Returns the system uptime in seconds.
    os.userInfo()     // Returns uid, username, home, and shell of current user.</code></pre>
  </section>
  <section id="7">
    <h2>16.7 Trabajar con archivos</h2>
    <p>El módulo "fs" de Node es una completa API para trabajar con archivos y directorios. Se complementa con el módulo "path", que define funciones de utilidad para trabajar con nombres de archivos y directorios. El módulo "fs" contiene un puñado de funciones de alto nivel para leer, escribir y copiar archivos fácilmente. Pero la mayoría de las funciones del módulo son enlaces JavaScript de bajo nivel a llamadas del sistema Unix (y sus equivalentes en Windows). Si ha trabajado antes con llamadas de bajo nivel al sistema de archivos (en C u otros lenguajes), la API de Node le resultará familiar. Si no, puede que algunas partes de l a API "fs" le resulten concisas y poco intuitivas. La función para borrar un archivo, por ejemplo, se llama <codeinline>unlink()</codeinline>.</p>
    <p>El módulo "fs" define una gran API, principalmente porque suele haber múltiples variants de cada operación fundamental. Como se discutió al principio del capítulo, la mayoría de las funciones como <codeinline>fs.readFile()</codeinline> son no bloqueantes, basadas en callback y asíncronas. Típicamente, sin embargo, cada una de estas funciones tiene una variable de bloqueo síncrono, como <codeinline>fs.readFileSync()</codeinline>. En Node 10 y posteriores, muchas de estas funciones también tienen una variante asíncrona basada en promesas, como <codeinline>fs.promises.readFile()</codeinline>. La mayoría de las funciones "fs" toman una cadena como primer argumento, especificando la ruta (nombre de archivo más nombres de directorio opcionales) al archivo sobre el que se va a operar. Pero algunas de estas funciones también admiten una variante que toma un "descriptor de fichero" entero como primer argumento en lugar de una ruta. Estas variantes tienen nombres que empiezan por la letra "f". Por ejemplo, <codeinline>fs.truncate()</codeinline> trunca un archivo especificado por la ruta, y <codeinline>fs.ftruncate()</codeinline> trunca un archivo especificado por el descriptor de archivo. Existe una <codeinline>fs.promises.truncate()</codeinline> basada en promesas que espera una ruta y otra versión basada en promesas que se implementa como un método de un objeto FileHandle. (La clase FileHandle es el equivalente de un descriptor de archivo en la API basada en promesas). Finalmente, hay un puñado de funciones en el módulo "fs" que tienen variantes cuyos nombres están prefijados con la letra "l". Estas variantes "l" son como la función base, pero no siguen los enlaces simbólicos en el sistema de ficheros, sino que operan directamente sobre los propios enlaces simbólicos.</p>
  </section>
  <section id="7-1" class="py-4 xs:py-5 sm:py-6">
    <h2>16.7.1 Rutas, descriptores de archivos y FileHandles</h2>
    <p>Para poder utilizar el módulo "fs" para trabajar con ficheros, primero tienes que poder nombrar el fichero con el que quieres trabajar. La mayoría de las veces, los ficheros se especifican por <em>path</em>, lo que significa el nombre del propio fichero, más la jerarquía de directorios en la que aparece el fichero. Si una ruta es <em>absoluta</em>, significa que se especifican todos los directorios hasta la raíz del sistema de archivos. En caso contrario, la ruta es <em>relativa</em> y sólo tiene sentido en relación con otra ruta, normalmente el <em>directorio de trabajo actual</em>. Trabajar con rutas puede ser un poco complicado porque los diferentes sistemas operativos utilizan diferentes caracteres para separar los nombres de los directorios, es fácil duplicar accidentalmente esos caracteres separadores al concatenar rutas, y porque los segmentos de ruta del directorio padre <codeinline>../</codeinline> necesitan un tratamiento especial. El módulo "path" de Node y un par de otras características importantes de Node ayudan:</p>
    <pre>
    <code class="language-js">// Some important paths
    process.cwd() // Absolute path of the current working directory.
    __filename    // Absolute path of the file that holds the current code.
    __dirname     // Absolute path of the directory that holds __filename.
    os.homedir()  // The user's home directory.

    const path = require("path");
    
    path.sep      // Either "/" or "\" depending on your OS
    
    // The path module has simple parsing functions
    let p = "src/pkg/test.js";       // An example path
    path.basename(p)                 // => "test.js"
    path.extname(p)                  // => ".js"
    path.dirname(p)                  // => "src/pkg"
    path.basename(path.dirname(p))   // => "pkg"
    path.dirname(path.dirname(p))    // => "src"
    
    // normalize() cleans up paths:
    path.normalize("a/b/c/../d/")    // => "a/b/d/": handles ../ segments
    path.normalize("a/./b")          // => "a/b": strips "./" segments
    path.normalize("//a//b//")       // => "/a/b/": removes duplicate /
    
    // join() combines path segments, adding separators, then normalizes
    path.join("src", "pkg", "t.js")  // => "src/pkg/t.js"
    
    // resolve() takes one or more path segments and returns an absolute
    // path. It starts with the last argument and works backward, stopping
    // when it has built an absolute path or resolving against process.cwd().
    path.resolve()                   // => process.cwd()
    path.resolve("t.js")             // => path.join(process.cwd(), "t.js")
    path.resolve("/tmp", "t.js")     // => "/tmp/t.js"
    path.resolve("/a", "/b", "t.js") // => "/b/t.js"</code></pre>
    <p>Tenga en cuenta que <codeinline>path.normalize()</codeinline> es simplemente una función de manipulación de cadenas que no tiene acceso al sistema de archivos real. Las funciones <codeinline>fs.realpath()</codeinline> y <codeinline>fs.realpathSync()</codeinline> realizan una canonización consciente del sistema de archivos: resuelven enlaces simbólicos e interpretan rutas relativas al directorio de trabajo actual.</p>
    <p>En los ejemplos anteriores, asumimos que el código se está ejecutando en un SO basado en Unix y <codeinline>path.sep</codeinline> es "/". Si desea trabajar con rutas al estilo Unix aunque esté en un sistema Win- dows, utilice <codeinline>path.posix</codeinline> en lugar de <codeinline>path</codeinline>. Y a la inversa, si desea trabajar con rutas Windows incluso en un sistema Unix, utilice <codeinline>path.win32</codeinline>. <codeinline>path.posix</codeinline> y <codeinline>path.win32</codeinline> definen las mismas propiedades y funciones que <codeinline>path</codeinline>.</p>
    <p>Algunas de las funciones "fs" que veremos en las próximas secciones esperan un <em>descriptor de fichero</em> en lugar de un nombre de fichero. Los descriptores de archivo son números enteros que se utilizan como referencias a nivel de sistema operativo para los archivos "abiertos". Se obtiene un descriptor para un nombre dado llamando a la función <codeinline>fs.open()</codeinline> (o <codeinline>fs.openSync()</codeinline>). A los procesos sólo se les permite tener un número limitado de archivos abiertos al mismo tiempo, por lo que es importante que llame a <codeinline>fs.close()</codeinline> en sus descriptores de archivo cuando haya terminado con ellos. Necesita abrir archivos si desea utilizar las funciones de bajo nivel <codeinline>fs.read()</codeinline> y <codeinline>fs.write()</codeinline> que le permiten saltar dentro de un archivo, leyendo y escribiendo partes de él en diferentes momentos. Hay otras funciones en el módulo "fs" que utilizan descriptores de archivo, pero todas tienen versiones basadas en nombres, y sólo tiene sentido utilizar las funciones basadas en descriptores si se va a abrir el archivo para leer o escribir de todos modos.</p>
    <p>Por último, en la API basada en promesas definida por <codeinline>fs.promises</codeinline>, el equivalente de <codeinline>fs.open()</codeinline> es <codeinline>fs.promises.open()</codeinline>, que devuelve una promesa que resuelve un objeto FileHandle. Este objeto FileHandle sirve para el mismo propósito que un descriptor de archivo. De nuevo, sin embargo, a menos que necesites usar los métodos de bajo nivel <codeinline>read()</codeinline> y <codeinline>write()</codeinline> de un FileHandle, realmente no hay razón para crear uno. Y si creas un FileHandle, debes recordar llamar a su método <codeinline>close()</codeinline> una vez que hayas terminado con él.</p>
  </section>
  <section id="7-2">
    <h2>16.7.2 Archivos de lectura</h2>
    <p>Node permite leer el contenido de los archivos de una sola vez, a través de un stream o con la API de bajo nivel.</p>
    <p>Si sus archivos son pequeños, o si el uso de memoria y el rendimiento no son la prioridad más alta, entonces a menudo es más fácil de leer todo el contenido de un archivo con una sola llamada. Usted puede hacer esto de forma sincrónica, con una devolución de llamada, o con una promesa. Por defecto, obtendrá los bytes del archivo como un buffer, pero si especifica una codificación, obtendrá una cadena decodificada en su lugar.</p>
    <pre>
    <code class="language-js">const fs = require("fs");
    let buffer = fs.readFileSync("test.data");      // Synchronous, returns buffer
    let text = fs.readFileSync("data.csv", "utf8"); // Synchronous, returns string

    // Read the bytes of the file asynchronously
    fs.readFile("test.data", (err, buffer) => &lbrace;
      if (err) &lbrace;
        // Handle the error here
      } else &lbrace;
        // The bytes of the file are in buffer
      }
    });

    // Promise-based asynchronous read
    fs.promises
      .readFile("data.csv", "utf8")
      .then(processFileText)
      .catch(handleReadError);

    // Or use the Promise API with await inside an async function
    async function processText(filename, encoding="utf8") &lbrace;
      let text = await fs.promises.readFile(filename, encoding);
      // ... process the text here...
    }</code></pre>
    <p>Si puedes procesar el contenido de un fichero secuencialmente y no necesitas tener todo el contenido del fichero en memoria al mismo tiempo, entonces leer un fichero a través de un stream puede ser el enfoque más eficiente. Hemos cubierto los flujos extensamente: aquí está cómo usted podría utilizar un flujo y el método <codeinline>pipe()</codeinline> para escribir el contenido de un archivo a la salida estándar:</p>
    <pre>
    <code class="language-js">function printFile(filename, encoding="utf8") &lbrace;
      fs.createReadStream(filename, encoding).pipe(process.stdout);
    }</code></pre>
    <p>Por último, si necesita un control de bajo nivel sobre qué bytes lee exactamente de un archivo y cuándo los lee, puede abrir un archivo para obtener un descriptor de archivo y, a continuación, utilizar <codeinline>fs.read()</codeinline>, <codeinline>fs.readSync()</codeinline> o <codeinline>fs.promises.read()</codeinline> para leer un número especificado de bytes desde una ubicación de origen especificada del archivo en un búfer especificado en la posición de destino especificada:</p>
    <pre>
    <code class="language-js">const fs = require("fs");

    // Reading a specific portion of a data file
    fs.open("data", (err, fd) => &lbrace;
      if (err) &lbrace;
        // Report error somehow
        return;
      }
      try &lbrace;
        // Read bytes 20 through 420 into a newly allocated buffer.
        fs.read(fd, Buffer.alloc(400), 0, 400, 20, (err, n, b) => &lbrace;
          // err is the error, if any.
          // n is the number of bytes actually read
          // b is the buffer that they bytes were read into.
        });
      }
      finally &lbrace;       // Use a finally clause so we always
        fs.close(fd); // close the open file descriptor
      }
    });</code></pre>
    <p>La API <codeinline>read()</codeinline> basada en callback es incómoda de usar si necesitas leer más de un trozo de datos de un archivo. Si puede utilizar la API sincrónica (o la API basada en promesas con <codeinline>await</codeinline>), resulta fácil leer varios fragmentos de un archivo:</p>
    <pre>
    <code class="language-js">const fs = require("fs");

    function readData(filename) &lbrace;
      let fd = fs.openSync(filename);
      try &lbrace;
        // Read the file header
        let header = Buffer.alloc(12); // A 12 byte buffer
        fs.readSync(fd, header, 0, 12, 0);
        
        // Verify the file's magic number
        let magic = header.readInt32LE(0);
        if (magic !== 0xDADAFEED) &lbrace;
          throw new Error("File is of wrong type");
        }

        // Now get the offset and length of the data from the header
        let offset = header.readInt32LE(4);
        let length = header.readInt32LE(8);

        // And read those bytes from the file
        let data = Buffer.alloc(length);
        fs.readSync(fd, data, 0, length, offset);
        return data;
      } finally &lbrace;
        // Always close the file, even if an exception is thrown above
        fs.closeSync(fd);
      }
    }</code></pre>
  </section>
  <section id="7-3" class="py-4 xs:py-5 sm:py-6">
    <h2>16.7.3 Archivos de escritura</h2>
    <p>Escribir archivos en Node es muy parecido a leerlos, con algunos detalles extra que debes conocer. Uno de estos detalles es que la forma de crear un nuevo archivo es simplemente escribiendo en un nombre de archivo que aún no existe.</p>
    <p>Al igual que con la lectura, hay tres formas básicas de escribir archivos en Node. Si tienes todo el contenido del archivo en una cadena o un buffer, puedes escribirlo todo en una llamada con <codeinline>fs.writeFile()</codeinline> (basado en callback), <codeinline>fs.writeFileSync()</codeinline> (síncrono), o <codeinline>fs.promises.writeFile()</codeinline> (basado en promesas):</p>
    <pre>
    <code class="language-js">fs.writeFileSync(path.resolve(__dirname, "settings.json"),
                JSON.stringify(settings));</code></pre>
    <p>Si los datos que está escribiendo en el archivo son una cadena y desea utilizar una codificación distinta de "utf8", pase la codificación como tercer argumento opcional.</p>
    <p>Las funciones relacionadas <codeinline>fs.appendFile()</codeinline>, <codeinline>fs.appendFileSync()</codeinline> y <codeinline>fs.promises.appendFile()</codeinline> son similares, pero cuando el archivo especificado ya existe, añaden sus datos al final en lugar de sobrescribir el contenido del archivo existente.</p>
    <p>Si los datos que quieres escribir en un fichero no están todos en un trozo, o si no están todos en la memoria al mismo tiempo, entonces usar un flujo escribible es un buen enfoque, asumiendo que planeas escribir los datos de principio a fin sin saltarte nada en el fichero:</p>
    <pre>
    <code class="language-js">const fs = require("fs");
    let output = fs.createWriteStream("numbers.txt");
    for(let i = 0; i &lt; 100; i++) &lbrace;
      output.write(`$&lbrace;i}\n`);
    }
    output.end();</code></pre>
    <p>Por último, si desea escribir datos en un archivo en varios trozos, y desea poder controlar la posición exacta dentro del archivo en la que se escribe cada trozo, entonces puede abrir el archivo con <codeinline>fs.open()</codeinline>, <codeinline>fs.openSync()</codeinline>, o <codeinline>fs.promises.open()</codeinline> y luego utilizar el descriptor de archivo resultante con las funciones <codeinline>fs.write()</codeinline> o <codeinline>fs.writeSync()</codeinline>. Estas funciones vienen en diferentes formas para cadenas y buffers. La variante de cadena toma un descriptor de archivo, una cadena y la posición de archivo en la que escribir esa cadena (con una codificación como cuarto argumento opcional). La variante buffer toma un descriptor de fichero, un buffer, un offset y una longitud que especifican un trozo de datos dentro del buffer, y una posición de fichero en la que escribir los bytes de ese trozo. Y si tiene una matriz de Los objetos buffer que desee escribir, puede hacerlo con una sola <codeinline>fs.writev()</codeinline> o <codeinline>fs.writevSync()</codeinline>. Existen funciones de bajo nivel similares para escribir buffers y cadenas usando <codeinline>fs.promises.open()</codeinline> y el objeto FileHandle que produce.</p>
    <article>
      <p class="title-article">Cadenas de modo de archivo</p>
      <p>Vimos los métodos <codeinline>fs.open()</codeinline> y <codeinline>fs.openSync()</codeinline> antes cuando usamos la API de bajo nivel para leer archivos. En ese caso, bastaba con pasar el nombre del archivo a la función open. Sin embargo, cuando se desea escribir un archivo, también se debe especificar un segundo argumento de cadena que especifique cómo se pretende utilizar el descriptor de archivo. Algunas de las cadenas de banderas disponibles son las siguientes:</p>
      <p><codeinline>"w"</codeinline></p>
      <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Abrir el archivo para escribir</p>
      <p><codeinline>"w+"</codeinline></p>
      <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Abierto a la escritura y la lectura</p>
      <p><codeinline>"wx"</codeinline></p>
      <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Abrir para crear un nuevo archivo; falla si el archivo nombrado ya existe</p>
      <p><codeinline>"wx+"</codeinline></p>
      <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Abrir para creación, y también permitir lectura; falla si el archivo nombrado ya existe</p>
      <p><codeinline>"a"</codeinline></p>
      <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Abrir el archivo para añadirlo; el contenido existente no se sobrescribirá.</p>
      <p><codeinline>"a+"</codeinline></p>
      <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Abierto para añadir, pero también permite leer</p>
      <p>Si no pasa uno de estos indicadores a <codeinline>fs.open()</codeinline> o <codeinline>fs.openSync()</codeinline>, éstos utilizarán el indicador "r" por defecto, haciendo que el descriptor de fichero sea de sólo lectura. Tenga en cuenta que también puede ser útil pasar estos indicadores a otros métodos de escritura de archivos:</p>
      <pre>
      <code class="language-js">// Write to a file in one call, but append to anything that is already there.
      // This works like fs.appendFileSync()
      fs.writeFileSync("messages.log", "hello", &lbrace; flag: "a" });

      // Open a write stream, but throw an error if the file already exists.
      // We don't want to accidentally overwrite something!
      // Note that the option above is "flag" and is "flags" here
      fs.createWriteStream("messages.log", &lbrace; flags: "wx" });</code></pre>
    </article>
    <p>Puede cortar el final de un archivo con <codeinline>fs.truncate()</codeinline>, <codeinline>fs.truncateSync()</codeinline> o <codeinline>fs.promises.truncate()</codeinline>. Estas funciones toman una ruta como primer argumento y una longitud como segundo, y modifican el archivo para que tenga la longitud especificada. Si se omite la longitud, se utiliza cero y el fichero queda vacío. A pesar del nombre de estas funciones también pueden utilizarse para ampliar un archivo: si se especifica una longitud mayor que el tamaño actual del archivo, éste se amplía con cero bytes hasta el nuevo tamaño. Si ya ha abierto el fichero que desea modificar, puede utilizar <codeinline>ftruncate()</codeinline> o <codeinline>ftruncateSync()</codeinline> con el descriptor de fichero o FileHandle</p>
    <p>Las diversas funciones de escritura de archivos descritas aquí devuelven o invocan su callback o resuelven su Promise cuando los datos han sido "escritos" en el sentido de que Node los ha entregado al sistema operativo. Pero esto no significa necesariamente que los datos se hayan escrito realmente en el almacenamiento persistente: al menos algunos de sus datos pueden estar todavía almacenados en algún lugar del sistema operativo o en un controlador de dispositivo a la espera de ser escritos en el disco. Si llama a <codeinline>fs.writeSync()</codeinline> para escribir de forma sincrónica algunos datos en un archivo, y si se produce un corte de energía inmediatamente después de que la función retorne, aún puede perder datos. Si desea forzar la salida de sus datos al disco para saber con certeza que se han guardado de forma segura, utilice <codeinline>fs.fsync()</codeinline> o <codeinline>fs.fsyncSync()</codeinline>. Estas funciones sólo funcionan con descriptores de fichero: no existe una versión basada en rutas.</p>
  </section>
  <section id="7-4">
    <h2>16.7.4 Operaciones de archivo</h2>
    <p>La discusión anterior sobre las clases stream de Node incluyó dos ejemplos de funciones <codeinline>copyFile()</codeinline>. Estas no son utilidades prácticas que usted usaría realmente porque el módulo "fs" define su propio método <codeinline>fs.copyFile()</codeinline> (y también <codeinline>fs.copyFileSync()</codeinline> y <codeinline>fs.promises.copyFile()</codeinline>, por supuesto).</p>
    <p>Estas funciones toman el nombre del archivo original y el nombre de la copia como sus dos primeros argumentos. Éstos pueden especificarse como cadenas o como objetos URL o Buffer. Un tercer argumento opcional es un número entero cuyos bits especifican indicadores que controlan los detalles de la operación de <codeinline>copy</codeinline>. Y para la función <codeinline>fs.copyFile()</codeinline> basada en callback, el argumento final es una función callback que será llamada sin argumentos cuando la copia se haya completado, o que será llamada con un argumento de error si algo falla. A continuación se muestran algunos ejemplos:</p>
    <pre>
    <code class="language-js">// Basic synchronous file copy.
    fs.copyFileSync("ch15.txt", "ch15.bak");

    // The COPYFILE_EXCL argument copies only if the new file does not already
    // exist. It prevents copies from overwriting existing files.
    fs.copyFile("ch15.txt", "ch16.txt", fs.constants.COPYFILE_EXCL, err => &lbrace;
      // This callback will be called when done. On error, err will be non-null.
    });

    // This code demonstrates the Promise-based version of the copyFile function.
    // Two flags are combined with the bitwise OR opeartor |. The flags mean that
    // existing files won't be overwritten, and that if the filesystem supports
    // it, the copy will be a copy-on-write clone of the original file, meaning
    // that no additional storage space will be required until either the original
    // or the copy is modified.
    fs.promises.copyFile("Important data",
        `Important data $&lbrace;new Date().toISOString()}"
        fs.constants.COPYFILE_EXCL | fs.constants.COPYFILE_FICLONE)
      .then(() => &lbrace;
        console.log("Backup complete");
      });
      .catch(err => &lbrace;
        console.error("Backup failed", err);
      });</code></pre>
    <p>La función <codeinline>fs.rename()</codeinline> (junto con las variantes síncronas y basadas en promesas) mueve y/o renombra un archivo. Llámela con la ruta actual al archivo y la nueva ruta deseada al archivo. No hay argumento flags, pero la versión basada en callback toma un callback como tercer argumento:</p>
    <pre>
    <code class="language-js">fs.renameSync("ch15.bak", "backups/ch15.bak");</code></pre>
    <p>Tenga en cuenta que no hay ningún indicador que impida que el cambio de nombre sobrescriba un archivo existente. También hay que tener en cuenta que los archivos sólo se pueden renombrar dentro de un sistema de archivos.</p>
    <p>Las funciones <codeinline>fs.link()</codeinline> y <codeinline>fs.symlink()</codeinline> y sus variantes tienen los mismos signos que <codeinline>fs.rename()</codeinline> y se comportan como <codeinline>fs.copyFile()</codeinline> excepto que crean enlaces duros y enlaces simbólicos, respectivamente, en lugar de crear una copia.</p>
    <p>Finalmente, <codeinline>fs.unlink()</codeinline>, <codeinline>fs.unlinkSync()</codeinline>, y <codeinline>fs.promises.unlink()</codeinline> son las funciones de Node para borrar un archivo. (La denominación poco intuitiva se hereda de Unix, donde borrar un archivo es básicamente lo contrario de crear un enlace duro a él). Llame a esta función con la cadena, buffer o ruta URL del archivo a borrar, y pase una llamada de retorno si está usando la versión basada en llamadas de retorno:</p>
    <pre>
    <code class="language-js">fs.unlinkSync("backups/ch15.bak");</code></pre>
  </section>
  <section id="7-5" class="py-4 xs:py-5 sm:py-6">
    <h2>16.7.5 Metadatos de archivos</h2>
    <p>Las funciones <codeinline>fs.stat()</codeinline>, <codeinline>fs.statSync()</codeinline> y <codeinline>fs.promises.stat()</codeinline> permiten obtener metadatos de un archivo o directorio especificado. Por ejemplo:</p>
    <pre>
    <code class="language-js">const fs = require("fs");
    let stats = fs.statSync("book/ch15.md");
    stats.isFile()          // => true: this is an ordinary file
    stats.isDirectory()     // => false: it is not a directory
    stats.size              // file size in bytes
    stats.atime             // access time: Date when it was last read
    stats.mtime             // modification time: Date when it was last written
    stats.uid               // the user id of the file's owner
    stats.gid               // the group id of the file's owner
    stats.mode.toString(8)  // the file's permissions, as an octal string</code></pre>
    <p>El objeto Stats devuelto contiene otras propiedades y métodos más oscuros, pero este código muestra los que es más probable que utilice.</p>
    <p><codeinline>fs.lstat()</codeinline> y sus variantes funcionan igual que <codeinline>fs.stat()</codeinline>, excepto que si el archivo especificado es un enlace simbólico, Node devolverá metadatos para el propio enlace en lugar de seguir el enlace.</p>
    <p>Si ha abierto un archivo para producir un descriptor de archivo o un objeto FileHandle, puede utilizar <codeinline>fs.fstat()</codeinline> o sus variantes para obtener información de metadatos del archivo abierto sin tener que especificar de nuevo el nombre del archivo.</p>
    <p>Además de consultar metadatos con <codeinline>fs.stat()</codeinline> y todas sus variantes, también existen funciones para modificar metadatos.</p>
    <p><codeinline>fs.chmod()</codeinline>, <codeinline>fs.lchmod()</codeinline> y <codeinline>fs.fchmod()</codeinline> (junto con las versiones sincrónicas y basadas en promesas) establecen el "modo" o los permisos de un archivo o directorio. Los valores de modo son enteros en los que cada bit tiene un significado específico y es más fácil pensar en ellos en notación octal. Por ejemplo, para hacer que un archivo sea de sólo lectura para su propietario e inaccesible para todos los demás, utilice <codeinline>0o400</codeinline>:</p>
    <pre>
    <code class="language-js">fs.chmodSync("ch15.md", 0o400); // Don't delete it accidentally!</code></pre>
    <p><codeinline>fs.chown()</codeinline>, <codeinline>fs.lchown()</codeinline>, y <codeinline>fs.fchown()</codeinline> (junto con las versiones sincrónicas y basadas en promesas) establecen el propietario y el grupo (como IDs) para un archivo o directorio. (Estos importan porque interactúan con los permisos de archivo establecidos por <codeinline>fs.chmod()</codeinline>.)</p>
    <p>Por último, puede establecer el tiempo de acceso y modificación de un archivo o directorio con <codeinline>fs.utimes()</codeinline> y <codeinline>fs.futimes()</codeinline> y sus variantes.</p>
  </section>
  <section id="7-6">
    <h2>16.7.6 Trabajar con directorios</h2>
    <p>Para crear un nuevo directorio en Node, utilice <codeinline>fs.mkdir()</codeinline>, <codeinline>fs.mkdirSync()</codeinline>, o <codeinline>fs.promises.mkdir()</codeinline>. El primer argumento es la ruta del directorio que se va a crear. El segundo argumento opcional puede ser un entero que especifica el modo (bits de permisos) para el nuevo directorio. O puede pasar un objeto con las propiedades opcionales <codeinline>mode</codeinline> y <codeinline>recursive</codeinline>. Si <codeinline>recursive</codeinline> es <codeinline>true</codeinline>, entonces esta función creará cualquier directorio en la ruta que no exista ya:</p>
    <pre>
    <code class="language-js">// Ensure that dist/ and dist/lib/ both exist.
    fs.mkdirSync("dist/lib", &lbrace; recursive: true });</code></pre>
    <p><codeinline>fs.mkdtemp()</codeinline> y sus variantes toman un prefijo de ruta que usted proporciona, le añaden algunos caracteres aleatorios (esto es importante por seguridad), crean un directorio con ese nombre y le devuelven (o pasan a una llamada de retorno) la ruta del directorio.</p>
    <p>Para borrar un directorio, utilice <codeinline>fs.rmdir()</codeinline> o una de sus variantes. Tenga en cuenta que los directorios deben estar vacíos antes de poder ser borrados:</p>
    <pre>
    <code class="language-js">// Create a random temporary directory and get its path, then
    // delete it when we are done
    let tempDirPath;
    try &lbrace;
      tempDirPath = fs.mkdtempSync(path.join(os.tmpdir(), "d"));
      // Do something with the directory here
    } finally &lbrace;
      // Delete the temporary directory when we're done with it
      fs.rmdirSync(tempDirPath);
    }</code></pre>
    <p>El módulo "fs" proporciona dos API distintas para listar el contenido de un directorio. En primer lugar, <codeinline>fs.readdir()</codeinline>, <codeinline>fs.readdirSync()</codeinline> y <codeinline>fs.promises.readdir()</codeinline> leen todo el directorio a la vez y proporcionan una matriz de cadenas o una matriz de objetos Dirent que especifican los nombres y tipos (archivo o directorio) de cada elemento. Los nombres de archivo devueltos por estas funciones son sólo el nombre local del archivo, no la ruta completa. He aquí algunos ejemplos:</p>
    <pre>
    <code class="language-js">let tempFiles = fs.readdirSync("/tmp"); // returns an array of strings

    // Use the Promise-based API to get a Dirent array, and then
    // print the paths of subdirectories
    fs.promises.readdir("/tmp", &lbrace;withFileTypes: true})
      .then(entries => &lbrace;
        entries.filter(entry => entry.isDirectory())
          .map(entry => entry.name)
          .forEach(name => console.log(path.join("/tmp/", name)));
      })
      .catch(console.error);</code></pre>
    <p>Si anticipa que necesitará listar directorios que pueden tener miles de entradas, puede que prefiera el enfoque de <codeinline>fs.opendir()</codeinline> y sus variantes. Estas funciones devuelven un objeto Dir que representa el directorio especificado. Puede utilizar los métodos <codeinline>read()</codeinline> o <codeinline>readSync()</codeinline> del objeto Dir para leer un Dirent cada vez. Si pasa una función de llamada de retorno a <codeinline>read()</codeinline>, ésta llamará a la llamada de retorno. Y si omite el argumento callback, devolverá una Promise. Cuando no haya más entradas de directorio, obtendrá <codeinline>null</codeinline> en lugar de un objeto Dirent.</p>
    <p>La forma más sencilla de utilizar objetos Dir es como iteradores asíncronos con un bucle <codeinline>for/await</codeinline>. Aquí, por ejemplo, hay una función que utiliza la API de streaming para listar entradas de directorio, llama a <codeinline>stat()</codeinline> en cada entrada, e imprime nombres y tamaños de archivos y directorios:</p>
    <pre>
    <code class="language-js">const fs = require("fs");
    const path = require("path");

    async function listDirectory(dirpath) &lbrace;
      let dir = await fs.promises.opendir(dirpath);
      for await (let entry of dir) &lbrace;
        let name = entry.name;
        if (entry.isDirectory()) &lbrace;
          name += "/"; // Add a trailing slash to subdirectories
        }
        let stats = await fs.promises.stat(path.join(dirpath, name));
        let size = stats.size;
        console.log(String(size).padStart(10), name);
      }
    }</code></pre>
  </section>
  <section id="8" class="py-4 xs:py-5 sm:py-6">
    <h2>16.8 Clientes y servidores HTTP</h2>
    <p>Los módulos "http", "https" y "http2" de Node son implementaciones completas pero de nivel relativamente bajo de los protocolos HTTP. Definen API completas para implementar clientes y servidores HTTP. Debido a que las APIs son relativamente de bajo nivel, no hay espacio en este capítulo para cubrir todas las características. Pero los ejemplos que siguen demuestran cómo escribir clientes y servidores básicos.</p>
    <p>La forma más sencilla de realizar una petición HTTP GET básica es con http.get() o https.get(). El primer argumento de estas funciones es la URL que se desea obtener. (Si es una URL http://, debe utilizar el módulo "http", y si es una URL https:// debe utilizar el módulo "https"). El segundo argumento es un callback que será invocado con un objeto IncomingMessage cuando la respuesta del servidor haya empezado a llegar. Cuando se llama al callback, el estado HTTP y las cabeceras están disponibles, pero el cuerpo puede no estar listo todavía. El objeto IncomingMessage es un flujo Readable, y puede utilizar las técnicas demostradas anteriormente en este capítulo para leer el cuerpo de la respuesta desde él.</p>
    <p>La función getJSON() al final de §13.2.6 usaba la función http.get() como parte de una demostración del constructor Promise(). Ahora que conoces los streams de Node y el modelo de programación de Node en general, vale la pena revisar ese ejemplo para ver cómo se usa http.get().</p>
    <p>http.get() y https.get() son variantes ligeramente simplificadas de las funciones más generales http.request() y https.request(). La siguiente función postJSON() demuestra cómo utilizar https.request() para realizar una solicitud HTTPS POST que incluya un cuerpo de solicitud JSON. Al igual que la función getJSON() del Capítulo 13, espera una respuesta JSON y devuelve una Promise que cumple con la versión analizada de esa respuesta:</p>
    <pre>
    <code class="language-js">const https = require("https");

    /*
    * Convert the body object to a JSON string then HTTPS POST it to the
    * specified API endpoint on the specified host. When the response arrives,
    * parse the response body as JSON and resolve the returned Promise with
    * that parsed value.
    */
    function postJSON(host, endpoint, body, port, username, password) &lbrace;
      // Return a Promise object immediately, then call resolve or reject
      // when the HTTPS request succeeds or fails.
      return new Promise((resolve, reject) => &lbrace;
        // Convert the body object to a string
        let bodyText = JSON.stringify(body);

        // Configure the HTTPS request
        let requestOptions = &lbrace;
          method: "POST",     // Or "GET", "PUT", "DELETE", etc.
          host: host,         // The host to connect to
          path: endpoint,     // The URL path
          headers: &lbrace;          // HTTP headers for the request
            "Content-Type": "application/json",
            "Content-Length": Buffer.byteLength(bodyText)
          }
        };

        if (port) &lbrace;                   // If a port is specified,
          requestOptions.port = port; // use it for the request.
        }
        // If credentials are specified, add an Authorization header.
        if (username && password) &lbrace;
          requestOptions.auth = `$&lbrace;username}:$&lbrace;password}`;
        }

        // Now create the request based on the configuration object
        let request = https.request(requestOptions);

        // Write the body of the POST request and end the request.
        request.write(bodyText);
        request.end();

        // Fail on request errors (such as no network connection)
        request.on("error", e => reject(e));

        // Handle the response when it starts to arrive.
        request.on("response", response => &lbrace;
          if (response.statusCode !== 200) &lbrace;
            reject(new Error(`HTTP status $&lbrace;response.statusCode}`));
            // We don't care about the response body in this case, but
            // we don't want it to stick around in a buffer somewhere, so
            // we put the stream into flowing mode without registering
            // a "data" handler so that the body is discarded.
            response.resume();
            return;
          }

          // We want text, not bytes. We're assuming the text will be
          // JSON-formatted but aren't bothering to check the
          // Content-Type header.
          response.setEncoding("utf8");

          // Node doesn't have a streaming JSON parser, so we read the
          // entire response body into a string.
          let body = "";
          response.on("data", chunk => &lbrace; body += chunk; });

          // And now handle the response when it is complete.
          response.on("end", () => &lbrace;     // When the response is done,
            try &lbrace;                        // try to parse it as JSON
              resolve(JSON.parse(body)); // and resolve the result.
            } catch(e) &lbrace;                 // Or, if anything goes wrong,
              reject(e);                 // reject with the error
            }
          });
        });
      });
    }</code></pre>
    <p>Además de realizar peticiones HTTP y HTTPS, los módulos "http" y "https" también permiten escribir servidores que respondan a esas peticiones. El planteamiento básico es el siguiente:</p>
    <ul>
      <li class="font-normal">Crea un nuevo objeto Servidor.</li>
      <li class="font-normal">Llama a su método listen() para comenzar a escuchar peticiones en un puerto especificado.</li>
      <li class="font-normal">Registra un manejador de eventos para eventos "request", usa ese manejador para leer la petición del cliente (particularmente la propiedad request.url), y escribe tu respuesta.</li>
    </ul>
    <p>El código que sigue crea un servidor HTTP simple que sirve archivos estáticos desde el sistema de archivos local y también implementa un punto final de depuración que responde a la solicitud de un cliente haciendo eco de esa solicitud.</p>
    <pre>
    <code class="language-js">// This is a simple static HTTP server that serves files from a specified
    // directory. It also implements a special /test/mirror endpoint that
    // echoes the incoming request, which can be useful when debugging clients.
    const http = require("http"); // Use "https" if you have a certificate
    const url = require("url");   // For parsing URLs
    const path = require("path"); // For manipulating filesystem paths
    const fs = require("fs");     // For reading files

    // Serve files from the specified root directory via an HTTP server that
    // listens on the specified port.
    function serve(rootDirectory, port) &lbrace;
      let server = new http.Server(); // Create a new HTTP server
      server.listen(port);       // Listen on the specified port
      console.log("Listening on port", port);

      // When requests come in, handle them with this function
      server.on("request", (request, response) => &lbrace;
        // Get the path portion of the request URL, ignoring
        // any query parameters that are appended to it.
        let endpoint = url.parse(request.url).pathname;

        // If the request was for "/test/mirror", send back the request
        // verbatim. Useful when you need to see the request headers and body.
        if (endpoint === "/test/mirror") &lbrace;

          // Set response header
          response.setHeader("Content-Type", "text/plain; charset=UTF-8");

          // Specify response status code
          response.writeHead(200); // 200 OK
          
          // Begin the response body with the request
          response.write(`$&lbrace;request.method} $&lbrace;request.url} HTTP/$&lbrace;
          request.httpVersion
          }\r\n`);

          // Output the request headers
          let headers = request.rawHeaders;
          for(let i = 0; i &lt; headers.length; i += 2) &lbrace;
          response.write(`$&lbrace;headers[i]}: $&lbrace;headers[i+1]}\r\n`);
          }

          // End headers with an extra blank line
          response.write("\r\n");

          // Now we need to copy any request body to the response body
          // Since they are both streams, we can use a pipe
          request.pipe(response);
        }
        // Otherwise, serve a file from the local directory.
        else &lbrace;
          // Map the endpoint to a file in the local filesystem
          let filename = endpoint.substring(1); // strip leading /
          // Don't allow "../" in the path because it would be a security
          // hole to serve anything outside the root directory.
          filename = filename.replace(/\.\.\//g, "");
          // Now convert from relative to absolute filename
          filename = path.resolve(rootDirectory, filename);

          // Now guess the type file's content type based on extension
          let type;
          switch(path.extname(filename)) &lbrace;
          case ".html":
          case ".htm": type = "text/html"; break;
          case ".js": type = "text/javascript"; break;
          case ".css": type = "text/css"; break;
          case ".png": type = "image/png"; break;
          case ".txt": type = "text/plain"; break;
          default: type = "application/octet-stream"; break;
          }

          let stream = fs.createReadStream(filename);
          stream.once("readable", () => &lbrace;
            // If the stream becomes readable, then set the
            // Content-Type header and a 200 OK status. Then pipe the
            // file reader stream to the response. The pipe will
            // automatically call response.end() when the stream ends.
            response.setHeader("Content-Type", type);
            response.writeHead(200);
            stream.pipe(response);
          });
            
          stream.on("error", (err) => &lbrace;
            // Instead, if we get an error trying to open the stream
            // then the file probably does not exist or is not readable.
            // Send a 404 Not Found plain-text response with the
            // error message.
            response.setHeader("Content-Type", "text/plain; charset=UTF-8");
            response.writeHead(404);
            response.end(err.message);
          });
        }
      });
    }

    // When we're invoked from the command line, call the serve() function
    serve(process.argv[2] || "/tmp", parseInt(process.argv[3]) || 8000);</code></pre>
    <p>Los módulos integrados de Node son todo lo que necesitas para escribir servidores HTTP y HTTPS sencillos. Ten en cuenta, sin embargo, que los servidores de producción no suelen construirse directamente sobre estos módulos. En su lugar, la mayoría de los servidores no triviales se implementan utilizando librerías externas - como el framework Express- que proporcionan "middleware" y otras utilidades de alto nivel que los desarrolladores web esperan.</p>
  </section>
  <section id="9">
    <h2>16.9 Servidores y clientes de red no HTTP </h2>
    <p>Los servidores y clientes web se han vuelto tan omnipresentes que es fácil olvidar que es posible escribir clientes y servidores que no utilicen HTTP. Aunque Node tiene la reputación de ser un buen entorno para escribir servidores web, Node también tiene soporte completo para escribir otros tipos de servidores y clientes de red.</p>
    <p>Si te sientes cómodo trabajando con flujos, entonces la conexión en red es relativamente sencilla, porque los sockets de red son simplemente una clase de flujo dúplex. El módulo "net" define las clases Server y Socket. Para crear un servidor, llame a net.createServer(), luego llame al método listen() del objeto resultante para decirle al servidor en qué puerto debe escuchar las conexiones. El objeto Servidor generará eventos de "conexión" cuando un cliente se conecte en ese puerto, y el valor pasado al escuchador de eventos será un objeto Socket. El objeto Socket es un stream Duplex, y puedes usarlo para leer datos del cliente y escribir datos al cliente. Llame a end() en el Socket para desconectarse.</p>
    <p>Escribir un cliente es aún más fácil: pasa un número de puerto y nombre de host a net.createCon nection() para crear un socket para comunicarse con cualquier servidor que se esté ejecutando en ese host y escuchando en ese puerto. A continuación, utilice ese socket para leer y escribir datos desde y hacia el servidor.</p>
    <p>El siguiente código demuestra cómo escribir un servidor con el módulo "net". Cuando el cliente se conecta, el servidor cuenta un chiste de toc-toc:</p>
    <pre>
    <code class="language-js">// A TCP server that delivers interactive knock-knock jokes on port 6789.
    // (Why is six afraid of seven? Because seven ate nine!)
    const net = require("net");
    const readline = require("readline");

    // Create a Server object and start listening for connections
    let server = net.createServer();
    server.listen(6789, () => console.log("Delivering laughs on port 6789"));

    // When a client connects, tell them a knock-knock joke.
    server.on("connection", socket => &lbrace;
      tellJoke(socket)
        .then(() => socket.end()) // When the joke is done, close the socket.
        .catch((err) => &lbrace;
          console.error(err);     // Log any errors that occur,
          socket.end();           // but still close the socket!
        });
    });

    // These are all the jokes we know.
    const jokes = &lbrace;
      "Boo": "Don't cry...it's only a joke!",
      "Lettuce": "Let us in! It's freezing out here!",
      "A little old lady": "Wow, I didn't know you could yodel!"
    };

    // Interactively perform a knock-knock joke over this socket, without blocking.
    async function tellJoke(socket) &lbrace;
      // Pick one of the jokes at random
      let randomElement = a => a[Math.floor(Math.random() * a.length)];
      let who = randomElement(Object.keys(jokes));
      let punchline = jokes[who];

      // Use the readline module to read the user's input one line at a time.
      let lineReader = readline.createInterface(&lbrace;
        input: socket,
        output: socket,
        prompt: ">> "
      });

      // A utility function to output a line of text to the client
      // and then (by default) display a prompt.
      function output(text, prompt=true) &lbrace;
        socket.write(`$&lbrace;text}\r\n`);
        if (prompt) lineReader.prompt();
      }

      // Knock-knock jokes have a call-and-response structure.
      // We expect different input from the user at different stages and
      // take different action when we get that input at different stages.
      let stage = 0;

      // Start the knock-knock joke off in the traditional way.
      output("Knock knock!");

      // Now read lines asynchronously from the client until the joke is done.
      for await (let inputLine of lineReader) &lbrace;
        if (stage === 0) &lbrace;
          if (inputLine.toLowerCase() === "who's there?") &lbrace;
            // If the user gives the right response at stage 0
            // then tell the first part of the joke and go to stage 1.
            output(who);
            stage = 1;
          } else &lbrace;
            // Otherwise teach the user how to do knock-knock jokes.
            output('Please type "Who\'s there?".');
          }
        } else if (stage === 1) &lbrace;
          if (inputLine.toLowerCase() === `$&lbrace;who.toLowerCase()} who?`) &lbrace;
            // If the user's response is correct at stage 1, then
            // deliver the punchline and return since the joke is done.
            output(`$&lbrace;punchline}`, false);
            return;
          } else &lbrace;
            // Make the user play along.
            output(`Please type "$&lbrace;who} who?".`);
          }
        }
      }
    }</code></pre>
    <p>Los servidores sencillos basados en texto como éste no suelen necesitar un cliente personalizado. Si la utilidad nc ("netcat") está instalada en su sistema, puede utilizarla para comunicarse con este servidor de la siguiente manera:</p>
    <pre class="language-js">
    $ nc localhost 6789
    Knock knock!
    >> Who's there?
    A little old lady
    >> A little old lady who?
    Wow, I didn't know you could yodel!</pre>
    <p>Por otro lado, escribir un cliente personalizado para el servidor de bromas es fácil en Node. Simplemente nos conectamos al servidor, luego canalizamos la salida del servidor a stdout y canalizamos stdin a la entrada del servidor:</p>
    <pre>
    <code class="language-js">// Connect to the joke port (6789) on the server named on the command line
    let socket = require("net").createConnection(6789, process.argv[2]);
    socket.pipe(process.stdout);    // Pipe data from the socket to stdout
    process.stdin.pipe(socket);     // Pipe data from stdin to the socket
    socket.on("close", () => process.exit()); // Quit when the socket closes.</code></pre>
    <p>Además de soportar servidores basados en TCP, el módulo "net" de Node también soporta la comunicación entre procesos a través de "sockets de dominio Unix" que se identifican por una ruta del sistema de ficheros en lugar de por un número de puerto. No vamos a cubrir ese tipo de socket en este capítulo, pero la documentación de Node tiene más detalles. Otras características de Node que no tenemos espacio para cubrir aquí incluyen el módulo "dgram" para clientes y servidores basados en UDP y el módulo "tls" que es a "net" como "https" es a "http". Las clases "tls.Server" y "tls.TLSSocket" permiten la creación de servidores TCP (como el servidor de chistes "knock-knock") que utilizan conexiones cifradas SSL como lo hacen los servidores HTTPS.</p>
  </section>
  <section id="10" class="py-4 xs:py-5 sm:py-6">
    <h2>16.10 Trabajar con procesos infantiles</h2>
    <p>Además de escribir servidores altamente concurrentes, Node también funciona bien para escribir scripts que ejecutan otros programas. En Node, el módulo "child_process" define una serie de funciones para ejecutar otros programas como procesos hijo. Esta sección muestra algunas de esas funciones, empezando por las más sencillas y siguiendo por las más complicadas.</p>
  </section>
  <section id="10-1">
    <h2>16.10.1 execSync() y execFileSync()</h2>
    <p>La forma más sencilla de ejecutar otro programa es con child_process.execSync(). Esta función toma el comando a ejecutar como primer argumento. Crea un proceso hijo, ejecuta una shell en ese proceso, y utiliza la shell para ejecutar el comando que le pasaste. Luego se bloquea hasta que el comando (y el shell) salen. Si el comando sale con un error, execSync() lanza una excepción. De lo contrario, execSync() devuelve la salida que el comando escriba en su flujo stdout. Por defecto, este valor de retorno es un buffer, pero puede especificar una codificación en un segundo argumento opcional para obtener una cadena en su lugar. Si el comando escribe cualquier salida a stderr, esa salida simplemente se pasa al flujo stderr del proceso padre.</p>
    <p>Así, por ejemplo, si está escribiendo un script y el rendimiento no es una preocupación, puede utilizar child_process.execSync() para listar un directorio con un comando de shell Unix familiar en lugar de utilizar la función fs.readdirSync():</p>
    <pre>
    <code class="language-js">const child_process = require("child_process");
    let listing = child_process.execSync("ls -l web/*.html", &lbrace;encoding: "utf8"});</code></pre>
    <p>El hecho de que execSync() invoque un shell Unix completo significa que la cadena que se le pasa puede incluir múltiples órdenes separadas por punto y coma, y puede aprovechar características del shell como comodines de nombre de archivo, tuberías y redirección de salida. Esto también significa que debe tener cuidado de no pasar nunca un comando a execSync() si alguna parte de ese comando es una entrada de usuario o proviene de una fuente similar no fiable. La compleja sintaxis de los comandos shell puede ser fácilmente subvertida para permitir a un atacante ejecutar código arbitrario.</p>
    <p>Si no necesita las características de un intérprete de órdenes, puede evitar la sobrecarga de iniciar un intérprete de órdenes utilizando child_process.execFileSync(). Esta función ejecuta un programa directamente, sin invocar una shell. Pero como no hay ningún intérprete de órdenes involucrado, no puede analizar una línea de órdenes, y debe pasar el ejecutable como primer argumento y una matriz de argumentos de línea de órdenes como segundo argumento:</p>
    <pre>
    <code class="language-js">let listing = child_process.execFileSync("ls", ["-l", "web/"],
                                &lbrace;encoding: "utf8"});</code></pre>
    <article>
      <p class="title-article">Opciones del proceso infantil</p>
      <p>execSync() y muchas otras funciones child_process tienen un segundo o tercer argumento opcional que especifica detalles adicionales sobre cómo se ejecutará el proceso hijo. La propiedad encoding de este objeto se utilizó anteriormente para especificar que deseamos que la salida del comando se entregue como una cadena en lugar de como un buffer. Otras propiedades importantes que puede especificar incluyen las siguientes (tenga en cuenta que no todas las opciones están disponibles para todas las funciones de proceso hijo):</p>
      <ul>
        <li class="font-normal">cwd especifica el directorio de trabajo para el proceso hijo. Si se omite, el proceso hijo hereda el valor de process.cwd().</li>
        <li class="font-normal">env especifica las variables de entorno a las que tendrá acceso el proceso hijo. Por defecto, los procesos hijos simplemente heredan process.env, pero puede especificar un objeto diferente si lo desea.</li>
        <li class="font-normal">input especifica una cadena o búfer de datos de entrada que debe utilizarse como entrada estándar del proceso hijo. Esta opción sólo está disponible para las funciones síncronas que no devuelven un objeto ChildProcess.</li>
        <li class="font-normal">maxBuffer especifica el número máximo de bytes de salida que serán recogidos por las funciones exec. (No se aplica a spawn() y fork(), que utilizan flujos). Si un proceso hijo produce más salida que esto, será matado y saldrá con un error.</li>
        <li class="font-normal">shell especifica la ruta a un ejecutable de shell o true. Para funciones de proceso hijo que normalmente ejecutan un comando shell, esta opción permite especificar qué shell utilizar. Para las funciones que normalmente no utilizan un intérprete de órdenes, esta opción permite especificar que se debe utilizar un intérprete de órdenes (estableciendo la propiedad en true) o especificar exactamente qué intérprete de órdenes se debe utilizar.</li>
        <li class="font-normal">timeout especifica el número máximo de milisegundos que se debe permitir ejecutar al proceso hijo. Si no ha salido antes de que transcurra este tiempo, será matado y saldrá con un error. (Esta opción se aplica a las funciones exec pero no a spawn() o fork().)</li>
        <li class="font-normal">uid especifica el ID de usuario (un número) bajo el cual debe ejecutarse el programa. Si el proceso padre se está ejecutando en una cuenta con privilegios, puede utilizar esta opción para ejecutar el proceso hijo con privilegios reducidos.</li>
      </ul>
    </article>
  </section>
  <section id="10-2" class="py-4 xs:py-5 sm:py-6">
    <h2>16.10.2 exec() y execFile()</h2>
    <p>Las funciones execSync() y execFileSync() son, como sus nombres indican, sincrónicas: se bloquean y no vuelven hasta que el proceso hijo sale. Utilizar estas funciones es muy parecido a escribir comandos Unix en una ventana de terminal: permiten ejecutar una secuencia de comandos de uno en uno. Pero si estás escribiendo un programa que necesita realizar una serie de tareas, y esas tareas no dependen unas de otras de ninguna manera, entonces es posible que desees paralelizarlas y ejecutar varios comandos al mismo tiempo. Puede hacerlo con las funciones asíncronas child_process.exec() y child_process.execFile().</p>
    <p>exec() y execFile() son como sus variantes síncronas, excepto que devuelven inmediatamente un objeto ChildProcess que representa el proceso hijo en ejecución, y toman una llamada de retorno de error como argumento final. La llamada de retorno se invoca cuando el proceso hijo sale, y en realidad se llama con tres argumentos. El primero es el error, si lo hay; será nulo si el proceso termina normalmente. El segundo argumento es la salida recolectada que fue enviada al flujo de salida estándar del proceso hijo. Y el tercer argumento es cualquier salida que haya sido enviada al flujo de error estándar del hijo.</p>
    <p>El objeto ChildProcess devuelto por exec() y execFile() le permite terminar el proceso hijo, y escribirle datos (que luego puede leer de su entrada estándar). Cubriremos ChildProcess con más detalle cuando hablemos de la función child_process.spawn().</p>
    <p>Si planea ejecutar múltiples procesos hijo al mismo tiempo, entonces puede ser más fácil usar la versión "prometida" de exec() que devuelve un objeto Promise que, si el proceso hijo sale sin error, resuelve a un objeto con propiedades stdout y stderr. Aquí, por ejemplo, hay una función que toma un array de comandos shell como entrada y devuelve un Promise que resuelve el resultado de todos esos comandos:</p>
    <pre>
    <code class="language-js">const child_process = require("child_process");
    const util = require("util");
    const execP = util.promisify(child_process.exec);

    function parallelExec(commands) &lbrace;
      // Use the array of commands to create an array of Promises
      let promises = commands.map(command => execP(command, &lbrace;encoding: "utf8"}));
      // Return a Promise that will fulfill to an array of the fulfillment
      // values of each of the individual promises. (Instead of returning objects
      // with stdout and stderr properties we just return the stdout value.)
      return Promise.all(promises)
        .then(outputs => outputs.map(out => out.stdout));
    }
    module.exports = parallelExec;</code></pre>
  </section>
  <section id="10-3">
    <h2>16.10.3 spawn()</h2>
    <p>Las diversas funciones exec descritas hasta ahora -tanto síncronas como asíncronas- están diseñadas para ser utilizadas con procesos hijo que se ejecutan rápidamente y no producen mucha salida. Incluso las funciones asíncronas exec() y execFile() no son de flujo continuo: devuelven la salida del proceso en un único lote, sólo después de que el proceso haya salido.</p>
    <p>La función child_process.spawn() le permite acceder a la salida del proceso hijo, mientras el proceso sigue en ejecución. También le permite escribir datos en el proceso hijo (que verá esos datos como entrada en su flujo de entrada estándar): esto significa que es posible interactuar dinámicamente con un proceso hijo, enviándole entrada basada en la salida que genera.</p>
    <p>spawn() no utiliza un intérprete de comandos por defecto, por lo que debe invocarlo como execFile() con el ejecutable a ejecutar y una matriz separada de argumentos de línea de comandos para pasarle. spawn() devuelve un objeto ChildProcess como hace execFile(), pero no toma un argumento de devolución de llamada. En lugar de utilizar una función de llamada de retorno, se escucha a los eventos en el objeto ChildProcess y en sus flujos.</p>
    <p>El objeto ChildProcess devuelto por spawn() es un emisor de eventos. Usted puede escuchar el evento "exit" para ser notificado cuando el proceso hijo sale. Un objeto ChildProcess también tiene tres propiedades de flujo. stdout y stderr son flujos legibles: cuando el proceso hijo escribe en sus flujos stdout y stderr, esa salida se vuelve legible a través de los flujos ChildProcess. Nótese la inversión de los nombres aquí. En el proceso hijo, "stdout" es un flujo de salida Writable, pero en el proceso padre, la propiedad stdout de un objeto ChildProcess es un flujo de entrada Readable.</p>
    <p>De forma similar, la propiedad stdin del objeto ChildProcess es un flujo Writeable: cualquier cosa que escriba en este flujo estará disponible para el proceso hijo en su entrada estándar.</p>
    <p>El objeto ChildProcess también define una propiedad pid que especifica el id del proceso hijo. Y define un método kill() que puedes usar para terminar un proceso hijo.</p>
  </section>
  <section id="10-4" class="py-4 xs:py-5 sm:py-6">
    <h2>16.10.4 bifurcarse()</h2>
    <p>child_process.fork() es una función especializada para ejecutar un módulo de código JavaScript en un proceso Node hijo. fork() espera los mismos argumentos que spawn(), pero el primer argumento debe especificar la ruta a un archivo de código JavaScript en lugar de un archivo binario ejecutable.</p>
    <p>Un proceso hijo creado con fork() puede comunicarse con el proceso padre a través de sus flujos de entrada y salida estándar, como se describe en la sección anterior para spawn(). Pero además, fork() permite otro canal de comunicación mucho más sencillo entre los procesos padre e hijo.</p>
    <p>Cuando creas un proceso hijo con fork(), puedes usar el método send() del objeto ChildProcess devuelto para enviar una copia de un objeto al proceso hijo. Y puedes escuchar el evento "message" en el ChildProcess para recibir mensajes de el hijo. El código que se ejecuta en el proceso hijo puede utilizar process.send() para enviar un mensaje al padre y puede escuchar los eventos "message" en process para recibir mensajes del padre.</p>
    <p>Aquí, por ejemplo, hay algo de código que usa fork() para crear un proceso hijo, luego envía a ese hijo un mensaje y espera una respuesta:</p>
    <pre>
    <code class="language-js">const child_process = require("child_process");

    // Start a new node process running the code in child.js in our directory
    let child = child_process.fork(`$&lbrace;__dirname}/child.js`);

    // Send a message to the child
    child.send(&lbrace;x: 4, y: 3});

    // Print the child's response when it arrives.
    child.on("message", message => &lbrace;
      console.log(message.hypotenuse); // This should print "5"
      // Since we only send one message we only expect one response.
      // After we receive it we call disconnect() to terminate the connection
      // between parent and child. This allows both processes to exit cleanly.
      child.disconnect();
    });</code></pre>
    <p>Y aquí está el código que se ejecuta en el proceso hijo:</p>
    <pre>
    <code class="language-js">// Wait for messages from our parent process
    process.on("message", message => &lbrace;
      // When we receive one, do a calculation and send the result
      // back to the parent.
      process.send(&lbrace;hypotenuse: Math.hypot(message.x, message.y)});
    });</code></pre>
    <p>Iniciar procesos hijo es una operación costosa, y el proceso hijo tendría que estar haciendo órdenes de magnitud más computacionales antes de que tuviera sentido usar fork() y la comunicación entre procesos de esta manera. Si está escribiendo un programa que necesita ser muy sensible a los eventos entrantes y también necesita realizar cálculos que consumen mucho tiempo, entonces podría considerar el uso de un proceso hijo separado para realizar los cálculos de manera que no bloqueen el bucle de eventos y reduzcan la capacidad de respuesta del proceso padre. (Aunque un hilo -ver §16.11- puede ser una mejor opción que un proceso hijo en este escenario).</p>
    <p>El primer argumento de send() será serializado con JSON.stringify() y deserializado en el proceso hijo con JSON.parse(), por lo que sólo debe incluir valores que sean soportados por el formato JSON. send() tiene un segundo argumento especial, sin embargo, que le permite transferir objetos Socket y Server (del módulo "net") a un proceso hijo. Los servidores de red tienden a estar ligados a la E/S más que a la computación, pero si ha escrito un servidor que necesita hacer más computación de la que una sola CPU puede manejar, y si está ejecutando ese servidor en una máquina con múltiples CPUs, entonces podría usar fork() para crear múltiples procesos hijo para manejar las peticiones. En el proceso par- ticular, podría escuchar eventos de "conexión" en su objeto Servidor, luego obtener el objeto Socket de ese evento de "conexión" y enviarlo() -usando el argumento especial sec- ond- a uno de los procesos hijos para ser manejado. (Tenga en cuenta que esta es una solución poco probable para un escenario poco común. En lugar de escribir un servidor que bifurque procesos hijo, probablemente sea más sencillo mantener tu servidor con un único hilo y desplegar múltiples instancias del mismo en producción para manejar la carga).</p>
  </section>
  <section id="11">
    <h2>16.11 Hilos de trabajo</h2>
    <p>Como se explicó al principio de este capítulo, el modelo de concurrencia de Node es monohilo y basado en eventos. Pero en la versión 10 y posteriores, Node permite una verdadera programación multihilo , con una API que se asemeja mucho a la API Web Workers definida por los navegadores web (§15.13). La programación multihilo tiene una merecida reputación de ser difícil. Esto se debe casi exclusivamente a la necesidad de sincronizar cuidadosamente el acceso de los hilos a la memoria compartida. Pero los hilos de JavaScript (tanto en Node como en los navegadores) no comparten memoria por defecto, así que los peligros y dificultades de usar hilos no se aplican a estos "trabajadores" en JavaScript.</p>
    <p>En lugar de utilizar memoria compartida, los subprocesos de trabajo de JavaScript se comunican mediante el paso de mensajes. El subproceso principal puede enviar un mensaje a un subproceso trabajador llamando al método postMessage() del objeto Worker que representa a ese subproceso. El subproceso trabajador puede recibir mensajes de su padre escuchando eventos "mensaje". Y los workers pueden enviar mensajes al hilo principal con su propia versión de postMes sage(), que el padre puede recibir con su propio manejador de eventos "message". El código de ejemplo de dejará claro cómo funciona esto.</p>
    <p>Hay tres razones por las que podrías querer utilizar hilos de trabajo en una aplicación Node:</p>
    <ul>
      <li class="font-normal">Si tu aplicación realmente necesita hacer más cálculos de los que un núcleo de CPU puede manejar, entonces los hilos te permiten distribuir el trabajo a través de los múltiples núcleos, que se han convertido en algo común en los ordenadores de hoy en día. Si estás haciendo computación científica o aprendizaje automático o procesamiento de gráficos en Node, entonces es posible que desees utilizar hilos simplemente para lanzar más potencia de cálculo a tu problema.</li>
      <li class="font-normal">Incluso si su aplicación no está utilizando toda la potencia de una CPU, es posible que desee utilizar hilos para mantener la capacidad de respuesta del hilo principal. Pensemos en un servidor que gestiona peticiones grandes pero relativamente infrecuentes. Supongamos que sólo recibe una petición por segundo, pero necesita emplear alrededor de medio segundo de cálculo (limitado a la CPU de bloqueo) para procesar cada petición. Por término medio, estará inactivo el 50% del tiempo. Pero cuando llegan dos peticiones con pocos milisegundos de diferencia, el servidor ni siquiera podrá empezar a responder a la segunda petición hasta que termine el cálculo de la primera respuesta. En cambio, si el servidor utiliza un subproceso de trabajo para realizar el cálculo, el servidor puede empezar a responder a ambas peticiones inmediatamente y proporcionar una mejor experiencia a los clientes del servidor. Suponiendo que el servidor tenga más de un núcleo de CPU, también puede calcular el cuerpo de ambas respuestas en paralelo, pero incluso si sólo hay un único núcleo, el uso de trabajadores mejora la capacidad de respuesta.</li>
      <li class="font-normal">En general, los workers nos permiten convertir operaciones síncronas bloqueantes en operaciones asíncronas no bloqueantes. Si estás escribiendo un programa que depende de código heredado que es inevitablemente síncrono, puedes utilizar workers para evitar el bloqueo cuando necesites llamar a ese código heredado.</li>
    </ul>
    <p>Los hilos de trabajo no son tan pesados como los procesos hijo, pero no son ligeros. Por lo general, no tiene sentido crear un trabajador a menos que tenga que realizar un trabajo significativo. Y, en términos generales, si su programa no está limitado por la CPU y no tiene problemas de respuesta, entonces probablemente no necesite hilos trabajadores.</p>
  </section>
  <section id="11-1" class="py-4 xs:py-5 sm:py-6">
    <h2>16.11.1 Creación de trabajadores y transmisión de mensajes</h2>
    <p>El módulo de Node que define los workers se conoce como "worker_threads". En esta sección nos referiremos a él con el identificador threads:</p>
    <pre>
    <code class="language-js">const threads = require("worker_threads");</code></pre>
    <p>Este módulo define una clase Worker para representar un hilo trabajador, y puedes crear un nuevo hilo con el constructor threads.Worker(). El siguiente código demuestra el uso de este constructor para crear un trabajador, y muestra cómo pasar mensajes del hilo principal al trabajador y del trabajador al hilo principal. También demuestra un truco que le permite poner el código del hilo principal y el código del hilo trabajador en el mismo archivo.<sup>2</sup></p>
    <pre>
    <code class="language-js">const threads = require("worker_threads");
    // The worker_threads module exports the boolean isMainThread property.
    // This property is true when Node is running the main thread and it is
    // false when Node is running a worker. We can use this fact to implement
    // the main and worker threads in the same file.
    if (threads.isMainThread) &lbrace;
      // If we're running in the main thread, then all we do is export
      // a function. Instead of performing a computationally intensive
      // task on the main thread, this function passes the task to a worker
      // and returns a Promise that will resolve when the worker is done.
      module.exports = function reticulateSplines(splines) &lbrace;
        return new Promise((resolve,reject) => &lbrace;
          // Create a worker that loads and runs this same file of code.
          // Note the use of the special __filename variable.
          let reticulator = new threads.Worker(__filename);

          // Pass a copy of the splines array to the worker
          reticulator.postMessage(splines);
          
          // And then resolve or reject the Promise when we get
          // a message or error from the worker.
          reticulator.on("message", resolve);
          reticulator.on("error", reject);
        });
      };
    } else &lbrace;
      // If we get here, it means we're in the worker, so we register a
      // handler to get messages from the main thread. This worker is designed
      // to only receive a single message, so we register the event handler
      // with once() instead of on(). This allows the worker to exit naturally
      // when its work is complete.
      threads.parentPort.once("message", splines => &lbrace;
        // When we get the splines from the parent thread, loop
        // through them and reticulate all of them.
        for(let spline of splines) &lbrace;
          // For the sake of example, assume that spline objects usually
          // have a reticulate() method that does a lot of computation.
          spline.reticulate ? spline.reticulate() : spline.reticulated = true;
        }

        // When all the splines have (finally!) been reticulated
        // pass a copy back to the main thread.
        threads.parentPort.postMessage(splines);
      });
    }</code></pre>
    <p>El primer argumento del constructor Worker() es la ruta a un archivo de código JavaScript que se ejecutará en el hilo. En el código anterior, hemos utilizado el identificador de nombre de archivo predefinido para crear un trabajador que carga y ejecuta el mismo archivo que el hilo principal. En general, sin embargo, se pasa una ruta de archivo. Tenga en cuenta que si especifica una ruta relativa, es relativa a process.cwd(), no relativa al módulo actualmente en ejecución. Si desea una ruta relativa al módulo actual, utilice algo como path.resolve( dirname, 'workers/reticulator.js').</p>
    <p>El constructor Worker() también puede aceptar un objeto como segundo argumento, y las propiedades de este objeto proporcionan una configuración opcional para el trabajador. Cubriremos algunas de estas opciones más adelante, pero por ahora ten en cuenta que si pasas &lbrace;eval: true} como segundo argumento, entonces el primer argumento de Worker() se interpreta como una cadena de código JavaScript a evaluar en lugar de un nombre de archivo:</p>
    <pre>
    <code class="language-js">new threads.Worker(`
      const threads = require("worker_threads");
      threads.parentPort.postMessage(threads.isMainThread);
      `, &lbrace;eval: true}).on("message", console.log); // This will print "false"</code></pre>
    <p>Node hace una copia del objeto pasado a postMessage() en lugar de compartirlo directamente con el hilo trabajador. Esto evita que la hebra del trabajador y la hebra principal compartan memoria. Se podría esperar que esta copia se hiciera con JSON.stringify() y JSON.parse() (§11.6). Pero de hecho, Node toma prestada una técnica más robusta conocida como el algoritmo de clonado estructurado de los navegadores web.</p>
    <p>El algoritmo de clonado estructurado permite la serialización de la mayoría de los tipos de JavaScript, incluyendo objetos Map, Set, Date y RegExp y arrays tipados, pero no puede, en general, copiar tipos definidos por el entorno anfitrión Node, como sockets y streams. Nótese, sin embargo, que los objetos Buffer están parcialmente soportados: si pasas un Buffer a postMes sage() será recibido como un Uint8Array, y puede ser convertido de nuevo en un Buffer con Buffer.from(). Más información sobre el algoritmo de clonación estructurada en "El algoritmo de clonación estructurada" en la página 513.</p>
  </section>
  <section id="11-2">
    <h2>16.11.2 Entorno de ejecución del trabajador</h2>
    <p>En su mayor parte, el código JavaScript en un subproceso de Node worker se ejecuta igual que en el subproceso principal de Node. Hay algunas diferencias que debes tener en cuenta, y algunas de estas diferencias implican propiedades del segundo argumento opcional del constructor Worker():</p>
    <ul>
      <li class="font-normal">Como hemos visto, threads.isMainThread es verdadero en el hilo principal pero siempre es false en cualquier hilo trabajador.</li>
      <li class="font-normal">En un subproceso trabajador, puedes utilizar threads.parentPort.postMessage() para enviar un mensaje al subproceso padre e threads.parentPort.on para registrar manejadores de eventos para mensajes del subproceso padre. En el hilo principal, threads.parentPort es siempre null.</li>
      <li class="font-normal">En un subproceso trabajador, threads.workerData se establece como una copia de la propiedad workerData del segundo argumento del constructor Worker(). En el hilo principal, esta propiedad es siempre nula. Puedes utilizar esta propiedad workerData para pasar una propiedad mensaje al trabajador que estará disponible tan pronto como se inicie para que el trabajador no tenga que esperar a un evento "mensaje" antes de que pueda empezar a hacer el trabajo.</li>
      <li class="font-normal">Por defecto, process.env en un subproceso trabajador es una copia de process.env en el subproceso padre. Pero el subproceso padre puede especificar un conjunto personalizado de variables de entorno estableciendo la propiedad env del segundo argumento del constructor Worker(). Como caso especial (y potencialmente peligroso), el subproceso padre puede establecer la propiedad env a threads.SHARE_ENV, lo que hará que los dos subprocesos compartan un único conjunto de variables de entorno de modo que un cambio en un subproceso sea visible en el otro.</li>
      <li class="font-normal">Por defecto, process.env en un subproceso trabajador es una copia de process.env en el subproceso padre. Pero el subproceso padre puede especificar un conjunto personalizado de variables de entorno estableciendo la propiedad env del segundo argumento del constructor Worker(). Como caso especial (y potencialmente peligroso), el subproceso padre puede establecer la propiedad env a threads.SHARE_ENV, lo que hará que los dos subprocesos compartan un único conjunto de variables de entorno de modo que un cambio en un subproceso sea visible en el otro.</li>
      <li class="font-normal">Por defecto, el flujo process.stdin de un trabajador nunca contiene datos legibles. Puedes cambiar este valor por defecto pasando stdin: true en el segundo argumento del constructor Worker(). Si lo haces, la propiedad stdin del objeto Worker será un flujo Writable. Cualquier dato que el padre escriba en worker.stdin se convierte en legible en process.stdin en el trabajador.</li>
      <li class="font-normal">Por defecto, los flujos process.stdout y process.stderr en el trabajador simplemente se canalizan a los flujos correspondientes en el hilo principal. Esto significa, por ejemplo, que console.log() y console.error() producen la salida exactamente de la misma manera en un hilo worker que en el hilo principal. Puede anular este valor por defecto pasando stdout:true o stderr:true en el segundo argumento del constructor Worker(). Si haces esto, entonces cualquier salida que el trabajador escriba en esos flujos será legible por el hilo padre en los hilos worker.stdout y worker.stderr. (Hay una inversión potencialmente confusa de las direcciones de los flujos aquí, y vimos lo mismo con los procesos hijo anteriormente en el capítulo: los flujos de salida de un hilo worker son flujos de entrada para el hilo par- ticular, y el flujo de entrada de un worker es un flujo de salida para el padre).</li>
      <li class="font-normal">Si un hilo trabajador llama a process.exit(), sólo sale el hilo, no todo el proceso.</li>
      <li class="font-normal">Los hilos de trabajo no pueden cambiar el estado compartido del proceso del que forman parte. Funciones como process.chdir() y process.setuid() lanzarán excepciones cuando sean invocadas desde un trabajador.</li>
      <li class="font-normal">Las señales del sistema operativo (como SIGINT y SIGTERM) sólo se envían al hilo principal; no pueden recibirse ni manejarse en los hilos trabajadores.</li>
    </ul>
  </section>
  <section id="11-3" class="py-4 xs:py-5 sm:py-6">
    <h2>16.11.3 Canales de comunicación y MessagePorts</h2>
    <p>Cuando se crea un nuevo hilo worker, se crea junto con él un canal de comunicación que permite pasar mensajes de ida y vuelta entre el worker y el hilo particular. Como hemos visto, el hilo worker utiliza threads.parentPort para enviar y recibir mensajes hacia y desde el subproceso padre, y el subproceso padre utiliza el objeto Worker para enviar y recibir mensajes hacia y desde el subproceso trabajador.</p>
    <p>La API de hilos de trabajo también permite la creación de canales de comunicación personalizados utilizando la API MessageChannel definida por los navegadores web y tratada en §15.13.5. Si has leído esa sección, mucho de lo que sigue te sonará familiar.</p>
    <p>Supongamos que un worker necesita manejar dos tipos diferentes de mensajes enviados por dos módulos diferentes en el hilo principal. Estos dos módulos diferentes podrían compartir el canal por defecto y enviar mensajes con worker.postMessage(), pero sería más limpio si cada módulo tiene su propio canal privado para enviar mensajes al trabajador. O consideremos el caso en el que el hilo principal crea dos trabajadores independientes. Un canal de comunicación personalizado puede permitir a los dos trabajadores comunicarse directamente entre sí en lugar de tener que enviar todos sus mensajes a través del hilo principal.</p>
    <p>Crea un nuevo canal de mensajes con el constructor MessageChannel(). Un objeto MessageChannel tiene dos propiedades, llamadas port1 y port2. Estas propiedades se refieren a un par de objetos MessagePort. Llamar a postMessage() en uno de los puertos hará que se genere un evento "mensaje" en el otro con un clon estructurado del objeto Message:</p>
    <pre>
    <code class="language-js">const threads = require("worker_threads");
    let channel = new threads.MessageChannel();
    channel.port2.on("message", console.log); // Log any messages we receive
    channel.port1.postMessage("hello"); // Will cause "hello" to be printed</code></pre>
    <p>También puede llamar a close() en cualquiera de los puertos para romper la conexión entre los dos puertos y señalar que no se intercambiarán más mensajes. Cuando se llama a close() en cualquiera de los puertos, se envía un evento "close" a ambos puertos.</p>
    <p>Observe que el ejemplo de código anterior crea un par de objetos MessagePort y luego utiliza esos objetos para transmitir un mensaje dentro del hilo principal. Para utilizar canales de comunicación personalizados con trabajadores, debemos transferir uno de los dos puertos desde el subproceso en el que se crea al subproceso en el que se utilizará. En la siguiente sección se explica cómo hacerlo.</p>
  </section>
  <section id="11-4">
    <h2>16.11.4 Transferencia de MessagePorts y matrices tipificadas</h2>
    <p>La función postMessage() utiliza el algoritmo de clonado estructurado, y como hemos señalado, no puede copiar objetos como SSockets y Streams. Puede manejar objetos MessagePort, pero sólo como un caso especial usando una técnica especial. El método postMessage() (de un objeto Worker, de threads.parentPort, o de cualquier objeto MessagePort) toma un segundo argumento opcional. Este argumento (llamado transferList) es un array de objetos que van a ser transferidos entre hilos en lugar de ser copiados.</p>
    <p>Un objeto MessagePort no puede ser copiado por el algoritmo de clonado estructurado, pero puede ser transferido. Si el primer argumento de postMessage() ha incluido uno o más objetos MessagePorts (anidados a una profundidad arbitraria dentro del objeto Message), entonces esos objetos Mes- sagePort también deben aparecer como miembros del array pasado como segundo argumento. Hacer esto le dice a Node que no necesita hacer una copia del MessagePort, y en su lugar puede dar el objeto existente al otro hilo. La clave para entender, sin embargo, sobre la transferencia de valores entre hilos es que una vez que un valor es transferido, ya no puede ser utilizado en el hilo que llamó a postMessage().</p>
    <p>Así es como se puede crear un nuevo MessageChannel y transferir uno de sus Message- Ports a un worker:</p>
    <pre>
    <code class="language-js">// Create a custom communication channel
    const threads = require("worker_threads");
    let channel = new threads.MessageChannel();

    // Use the worker's default channel to transfer one end of the new
    // channel to the worker. Assume that when the worker receives this
    // message it immediately begins to listen for messages on the new channel.
    worker.postMessage(&lbrace; command: "changeChannel", data: channel.port1 },
          [ channel.port1 ]);
    // Now send a message to the worker using our end of the custom channel
    channel.port2.postMessage("Can you hear me now?");

    // And listen for responses from the worker as well
    channel.port2.on("message", handleMessagesFromWorker);</code></pre>
    <p>Los objetos MessagePort no son los únicos que se pueden transferir. Si llamas a postMes sage() con un array tipado como mensaje (o con un mensaje que contiene uno o más arrays tipados anidados arbitrariamente dentro del mensaje), ese array tipado (o esos arrays tipados) simplemente serán copiados por el algoritmo de clonado estructurado. Pero las matrices tipadas pueden ser grandes; por ejemplo, si se está utilizando un hilo de trabajo para realizar el procesamiento de imágenes en millones de píxeles. Así que por eficiencia, postMessage() también nos da la opción de transferir matrices tipadas en lugar de copiarlas. (Los hilos comparten memoria por defecto. Los hilos de trabajo en JavaScript generalmente evitan la memoria compartida, pero cuando permitimos este tipo de transferencia controlada, se puede hacer de manera muy eficiente). Lo que hace que esto sea seguro es que cuando un array tipado se transfiere a otro hilo, se vuelve inutilizable en el hilo que lo transfirió. En el caso del procesamiento de imágenes, el subproceso principal podría transferir los píxeles de una imagen al subproceso trabajador, y luego el subproceso trabajador podría transferir los píxeles procesados de nuevo al subproceso principal cuando haya terminado. La memoria no necesitaría ser copiada, pero nunca sería accesible por dos hilos a la vez.</p>
    <p>Para transferir un array tipado en lugar de copiarlo, incluya el ArrayBuffer que respalda el array en el segundo argumento de postMessage():</p>
    <pre>
    <code class="language-js">let pixels = new Uint32Array(1024*1024); // 4 megabytes of memory

    // Assume we read some data into this typed array, and then transfer the
    // pixels to a worker without copying. Note that we don't put the array
    // itself in the transfer list, but the array's Buffer object instead.
    worker.postMessage(pixels, [ pixels.buffer ]);</code></pre>
    <p>Al igual que con los MessagePorts transferidos, un array tipado transferido se vuelve inutilizable una vez transferido. No se lanzan excepciones si se intenta utilizar un MessagePort o un array tipado que ha sido transferido; estos objetos simplemente dejan de hacer algo cuando se interactúa con ellos.</p>
  </section>
  <section id="11-5" class="py-4 xs:py-5 sm:py-6">
    <h2>16.11.5 Compartir matrices tipadas entre subprocesos</h2>
    <p>Además de transferir arrays tipados entre threads, es posible compartir un array tipado entre threads. Simplemente crea un SharedArrayBuffer del tamaño deseado y luego usa ese buffer para crear un array tipado. Cuando un array tipado que está respaldado por un SharedArrayBuffer se pasa a través de postMessage(), la memoria subyacente será compartida entre los hilos. En este caso, no se debe incluir el buffer compartido en el segundo argumento de postMessage().</p>
    <p>Sin embargo, no deberías hacer esto, porque JavaScript nunca fue diseñado pensando en la seguridad de los hilos y la programación multihilo es muy difícil de hacer bien. (Y esta es la razón por la que SharedArrayBuffer no fue cubierto en §11.2: es una característica de nicho que es difícil de hacer bien). Incluso el simple operador ++ no es seguro para los hilos porque necesita leer un valor, incrementarlo y escribirlo de vuelta. Si dos hilos están incrementando un valor al mismo tiempo, a menudo sólo se incrementará una vez, como demuestra el siguiente código:</p>
    <pre>
    <code class="language-js">const threads = require("worker_threads");

    if (threads.isMainThread) &lbrace;
      // In the main thread, we create a shared typed array with
      // one element. Both threads will be able to read and write
      // sharedArray[0] at the same time.
      let sharedBuffer = new SharedArrayBuffer(4);
      let sharedArray = new Int32Array(sharedBuffer);

      // Now create a worker thread, passing the shared array to it with
      // as its initial workerData value so we don't have to bother with
      // sending and receiving a message
      let worker = new threads.Worker(__filename, &lbrace; workerData: sharedArray });\

      // Wait for the worker to start running and then increment the
      // shared integer 10 million times.
      worker.on("online", () => &lbrace;
        for(let i = 0; i &lt; 10_000_000; i++) sharedArray[0]++;

        // Once we're done with our increments, we start listening for
        // message events so we know when the worker is done.
        worker.on("message", () => &lbrace;
          // Although the shared integer has been incremented
          // 20 million times, its value will generally be much less.
          // On my computer the final value is typically under 12 million.
          console.log(sharedArray[0]);
        });
      });
    } else &lbrace;
      // In the worker thread, we get the shared array from workerData
      // and then increment it 10 million times.
      let sharedArray = threads.workerData;
      for(let i = 0; i &lt; 10_000_000; i++) sharedArray[0]++;
      // When we're done incrementing, let the main thread know
      threads.parentPort.postMessage("done");
    }</code></pre>
    <p>Un escenario en el que podría ser razonable utilizar un SharedArrayBuffer es cuando los dos hilos operan en secciones completamente separadas de la memoria compartida. Se puede hacer esto creando dos matrices tipadas que sirvan como vistas de regiones no superpuestas del buffer compartido, y luego hacer que los dos subprocesos utilicen esas dos matrices tipadas separadas. Una ordenación merge paralela podría hacerse así: un subproceso ordena la mitad inferior de un array y el otro subproceso ordena la mitad superior, por ejemplo. O algunos tipos de algoritmos de procesamiento de imágenes también son adecuados para este enfoque: múltiples hilos trabajando en regiones separadas de la imagen.</p>
    <p>Si realmente debe permitir que varios subprocesos accedan a la misma región de una matriz compartida, puede dar un paso hacia la seguridad de los subprocesos con las funciones definidas por el objeto Atomics. Atomics se añadió a JavaScript con SharedArrayBuffer para definir operaciones atómicas sobre los elementos de una matriz compartida. Por ejemplo, la función Atomics.add() lee el elemento especificado de una matriz compartida, le añade un valor especificado y vuelve a escribir la suma en la matriz. Lo hace de forma atómica, como si se tratara de una sola operación, y se asegura de que ningún otro subproceso pueda leer o escribir el valor mientras se realiza la operación. Atomics.add() nos permite reescribir el código de incremento paralelo que acabamos de ver y obtener el resultado correcto de 20 millones de incrementos de un elemento de array compartido:</p>
    <pre>
    <code class="language-js">const threads = require("worker_threads");

    if (threads.isMainThread) &lbrace;
      let sharedBuffer = new SharedArrayBuffer(4);
      let sharedArray = new Int32Array(sharedBuffer);
      let worker = new threads.Worker(__filename, &lbrace; workerData: sharedArray });

      worker.on("online", () => &lbrace;
        for(let i = 0; i &lt; 10_000_000; i++) &lbrace;
          Atomics.add(sharedArray, 0, 1); // Threadsafe atomic increment
        }

        worker.on("message", (message) => &lbrace;
          // When both threads are done, use a threadsafe function
          // to read the shared array and confirm that it has the
          // expected value of 20,000,000.
          console.log(Atomics.load(sharedArray, 0));
        });
      });
    } else &lbrace;
      let sharedArray = threads.workerData;
      for(let i = 0; i &lt; 10_000_000; i++) &lbrace;
        Atomics.add(sharedArray, 0, 1); // Threadsafe atomic increment
      }
      threads.parentPort.postMessage("done");
    }</code></pre>
    <p>Esta nueva versión del código imprime correctamente el número 20.000.000. Pero es unas nueve veces más lenta que el código incorrecto al que sustituye. Pero es unas nueve veces más lenta que el código incorrecto al que sustituye. Sería mucho más sencillo y mucho más rápido hacer los 20 millones de incrementos en un único subproceso. También hay que tener en cuenta que las operaciones atómicas pueden garantizar la seguridad de los subprocesos en algoritmos de procesamiento de imágenes para los que cada elemento de la matriz es un valor totalmente independiente de todos los demás valores. Pero en la mayoría de los programas del mundo real, múltiples elementos del array están a menudo relacionados entre sí y se requiere algún tipo de sincronización de hilos de alto nivel. Las funciones de bajo nivel Atomics.wait() y Atomics.notify() pueden ayudar con esto, pero una discusión de su uso está fuera del alcance de este libro.</p>
  </section>
  <section id="12" class="pb-4 xs:pb-5 sm:pb-6">
    <h2>16.12 Resume</h2>
    <p>Aunque JavaScript se creó para ejecutarse en navegadores web, Node lo ha convertido en un lenguaje de programación de uso general. Es especialmente popular para implementar servidores web, pero sus profundos vínculos con el sistema operativo lo convierten también en una buena alternativa a los shell scripts.</p>
    <p>Los temas más importantes tratados en este largo capítulo son:</p>
    <ul>
      <li class="font-normal">Las API asíncronas por defecto de Node y su estilo de concurrencia basado en un único hilo, callback y eventos.</li>
      <li class="font-normal">Tipos de datos, buffers y streams fundamentales de Node.</li>
      <li class="font-normal">Módulos "fs" y "path" de Node para trabajar con el sistema de archivos.</li>
      <li class="font-normal">Módulos "http" y "https" de Node para escribir clientes y servidores HTTP.</li>
      <li class="font-normal">Módulo "net" de Node para escribir clientes y servidores no HTTP.</li>
      <li class="font-normal">Módulo "child_process" de Node para crear procesos hijo y comunicarse con ellos.</li>
      <li class="font-normal">Módulo "worker_threads" de Node para una verdadera programación multihilo utilizando el paso de mensajes en lugar de la memoria compartida.</li>
    </ul>
  </section>
  </Layoutjavascript>