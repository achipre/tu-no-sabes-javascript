---
import Navegation from "../../components/Navegation.astro";
import Layoutjavascript from "../../layouts/Layoutjavascript.astro";
---
<Layoutjavascript title="JavaScript: La guia definitiva">
  <Navegation capAnterior="capitulo-15" capSiguiente="capitulo-17" />
  <section class="fadeIn">
    <h1>JavaScript del lado del servidor con Node</h1>
    <p>Node es JavaScript con enlaces al sistema operativo subyacente, lo que permite escribir programas JavaScript que leen y escriben archivos, ejecutan procesos hijo y se comunican a través de la red. Esto hace que Node sea útil como:</p>
    <ul>
      <li class="font-normal">Alternativa moderna a los scripts de shell que no adolece de la sintaxis arcana de bash y otros shells de Unix.</li>
      <li class="font-normal">Lenguaje de programación de uso general para ejecutar programas fiables, no sujeto a las restricciones de seguridad impuestas por los navegadores web al código no fiable.</li>
      <li class="font-normal">Entorno popular para escribir servidores web eficientes y altamente concurrentes.</li>
    </ul>
    <p>La característica que define a Node es su concurrencia basada en eventos de un solo hilo, habilitada por una API asíncrona por defecto. Si has programado en otros lenguajes pero no has hecho mucho código JavaScript, o si eres un programador JavaScript experimentado acostumbrado a escribir código para navegadores web, usar Node será un poco de adaptación, como lo es cualquier lenguaje o entorno de programación nuevo. Este capítulo comienza explicando el modelo de programación de Node, con énfasis en la concurrencia, la API de Node para trabajar con datos en streaming y el tipo Buffer de Node para trabajar con datos binarios. Estas secciones iniciales son seguidas por secciones que resaltan y demuestran algunas de las APIs más importantes de Node, incluyendo aquellas para trabajar con archivos, redes, procesos e hilos.</p>
    <p>Un capítulo no es suficiente para documentar todas las APIs de Node, pero mi esperanza es que este capítulo explique lo suficiente de los fundamentos para hacerte productivo con Node, y confiado en que puedes dominar cualquier nueva API que necesites.</p>
    <article>
      <p class="title-article">Instalación del nodo</p>
      <p>Node es un software de código abierto. Visite https://nodejs.org para descargar e instalar Node para Windows y MacOS. En Linux, puede instalar Node con su gestor de paquetes nor- mal, o puede visitar https://nodejs.org/en/download para descargar los binarios directamente. Si trabajas con software en contenedores, puedes encontrar imágenes Docker oficiales de Node en https://hub.docker.com.</p>
      <p>Además del ejecutable de Node, una instalación de Node también incluye npm, un gestor de paquetes que permite acceder fácilmente a un vasto ecosistema de herramientas y librerías JavaScript. Los ejemplos de este capítulo utilizarán únicamente los paquetes integrados de Node y no requerirán npm ni ninguna librería externa</p>
      <p>Por último, no pases por alto la documentación oficial de Node, disponible en https:// nodejs.org/api y https://nodejs.org/docs/guides. La he encontrado bien organizada y bien escrita.</p>
    </article>
  </section>
  <section id="1" class="py-4 xs:py-5 sm:py-6">
    <h2>16.1 Conceptos básicos de programación de nodos</h2>
    <p>Comenzaremos este capítulo con un rápido vistazo a cómo están estructurados los programas Node y cómo interactúan con el sistema operativo.</p>
  </section>
  <section id="1-1">
    <h2>16.1.1 Salida de la consola</h2>
    <p>Si está acostumbrado a programar en JavaScript para navegadores web, una de las pequeñas sorpresas de Node es que console.log() no sólo sirve para depurar, sino que es la forma más sencilla de Node de mostrar un mensaje al usuario o, más en general, de enviar la salida al flujo stdout de . Aquí está el clásico programa "Hola Mundo" en Node:</p>
    <p>Hay formas más sencillas de escribir en stdout, pero ninguna más elegante u oficial que simplemente llamar a console.log().</p>
    <p>En los navegadores web, console.log(), console.warn() y console.error() suelen mostrar pequeños iconos junto a su salida en la consola del desarrollador para indicar la variedad del mensaje de registro. Node no hace esto, pero la salida mostrada con sole.error() se distingue de la salida mostrada con console.log() porque console.error() escribe en el flujo stderr. Si está utilizando Node para escribir un programa que está diseñado para tener stdout redirigido a un archivo o una tubería, puede utilizar console.error( ) para mostrar el texto a la consola donde el usuario lo verá, a pesar de que el texto impreso con console.log() está oculto.</p>
  </section>
  <section id="1-2" class="py-4 xs:py-5 sm:py-6">
    <h2>16.1.2 Argumentos de la línea de comandos y variables de entorno</h2>
    <p>Si ha escrito anteriormente programas de estilo Unix diseñados para ser invocados desde un terminal u otra interfaz de línea de comandos, sabrá que estos programas suelen obtener su entrada principalmente de argumentos de línea de comandos y, en segundo lugar, de variables de entorno.</p>
    <p>Node sigue estas convenciones de Unix. Un programa Node puede leer sus argumentos de línea de comandos de la matriz de cadenas process.argv. El primer elemento de este array es siempre la ruta al ejecutable de Node. El segundo argumento es la ruta al archivo de código JavaScript que Node está ejecutando. Cualquier elemento restante en este array son los argumentos separados por espacios que pasaste en la línea de comandos cuando invocaste a Node.</p>
    <p>Por ejemplo, supongamos que guardas este programa Node muy corto en el archivo argv.js:</p>
    <p>A continuación, puede ejecutar el programa y ver una salida como ésta:</p>
    <p>Hay que tener en cuenta un par de cosas:</p>
    <ul>
      <li class="font-normal">El primer y segundo elemento de process.argv serán rutas de sistema de archivos completamente cualificadas al ejecutable Node y al archivo de JavaScript que se está ejecutando, incluso si no los has escrito de esa forma.</li>
      <li class="font-normal">Los argumentos de línea de comandos que están destinados e interpretados por el propio ejecutable Node son consumidos por el ejecutable Node y no aparecen en pro cess.argv. (El argumento de línea de comandos --trace-uncaught en realidad no está haciendo nada útil en el ejemplo anterior; sólo está ahí para demostrar que no aparece en la salida). Cualquier argumento (como --arg1 y filename) que aparezca después del nombre del archivo JavaScript aparecerá en process.argv.</li>
    </ul>
    <p>Los programas Node también pueden tomar información de variables de entorno al estilo Unix. Node las hace disponibles a través del objeto process.env. Los nombres de las propiedades de este objeto son nombres de variables de entorno, y los valores de las propiedades (siempre cadenas) son los valores de esas variables.</p>
    <p>Aquí está una lista parcial de las variables de entorno en mi sistema:</p>
    <p>Puede utilizar node -h o node --help para averiguar qué hacen los argumentos de línea de comandos -p y -e. Sin embargo, como sugerencia, observe que podría reescribir la línea anterior como node --eval 'process.env' --print.</p>
  </section>
  <section id="1-3">
    <h2>16.1.3 Ciclo de vida del programa</h2>
    <p>El comando node espera un argumento de línea de comandos que especifique el archivo de código Java-Script que se va a ejecutar. Este archivo inicial suele importar otros módulos de código JavaScript, y también puede definir sus propias clases y funciones. Fundamentalmente, sin embargo, Node ejecuta el código JavaScript en el archivo especificado de arriba a abajo. Algunos programas Node salen cuando terminan de ejecutar la última línea de código en el archivo. A menudo, sin embargo, un programa Node seguirá ejecutándose mucho después de que se haya ejecutado el archivo inicial. Como veremos en las siguientes secciones, los programas Node son a menudo asíncronos y se basan en callbacks y manejadores de eventos. Los programas Node no salen hasta que han terminado de ejecutar el archivo inicial y hasta que todas las llamadas de retorno han sido llamadas y no hay más eventos pendientes. Un programa servidor basado en Node que escucha las conexiones de red entrantes teóricamente funcionará para siempre porque siempre estará esperando más eventos.</p>
    <p>Un programa puede forzarse a salir llamando a process.exit(). Por lo general, los usuarios pueden terminar un programa Node escribiendo Ctrl-C en la ventana de terminal donde se está ejecutando el programa. Un programa puede ignorar Ctrl-C registrando una función manejadora de señales con process.on("SIGINT", ()=>&lbrace;}).</p>
    <p>Si el código de tu programa lanza una excepción y ninguna cláusula catch la atrapa, el programa imprimirá un stack trace y saldrá. Debido a la naturaleza asíncrona de Node, las excepciones que ocurren en callbacks o manejadores de eventos deben ser manejados localmente o no manejados en absoluto, lo que significa que el manejo de las excepciones que se producen en las partes asíncronas de su programa puede ser un problema difícil. Si no quieres que estas excepciones hagan que tu programa se bloquee completamente, registra una función manejadora global que será invocada en lugar de bloquearse:</p>
    <p>Una situación similar se presenta si una Promise creada por su programa es rechazada y no hay una invocación .catch() para manejarla. A partir de Node 13, esto no es un error fatal que cause la salida del programa, pero imprime un mensaje de error verboso en la consola. En alguna versión futura de Node, se espera que los rechazos de Promise no manejados se conviertan en errores fatales. Si no desea que los rechazos no manejados, impriman mensajes de error o terminen su programa, registre una función manejadora global:</p>
  </section>
  <section id="1-4" class="py-4 xs:py-5 sm:py-6">
    <h2>16.1.4 Módulos de nodo</h2>
    <p>El Capítulo 10 documentó los sistemas de módulos de JavaScript, cubriendo tanto los módulos de Node como los de ES6. Como Node fue creado antes de que JavaScript tuviera un sistema de módulos, Node tuvo que crear el suyo propio. El sistema de módulos de Node utiliza la función require() para importar valores a un módulo y el objeto exports o la propiedad module.exports para exportar valores desde un módulo. Estos son una parte fundamental del modelo de programación de Node, y se cubren en detalle en §10.2.</p>
    <p>Node 13 añade soporte para módulos ES6 estándar así como módulos basados en require (que Node llama "módulos CommonJS"). Los dos sistemas de módulos no son totalmente compatibles, por lo que esto es algo complicado de hacer. Node necesita saber -antes de cargar un módulo- si ese módulo usará require() y module.exports o si usará import y export. Cuando Node carga un archivo de código JavaScript como un módulo CommonJS, define automáticamente la función require() junto con los identificadores exports y module, y no habilita las palabras clave import y export. Por otro lado, cuando Node carga un archivo de código como un módulo ES6, debe habilitar las declaraciones import y export, y no debe definir identificadores extra como require, module y exports.</p>
    <p>La forma más sencilla de decirle a Node qué tipo de módulo está cargando es codificar esta información en la extensión del archivo. Si guarda su código JavaScript en un archivo que termina con .mjs, entonces Node siempre lo cargará como un módulo ES6, esperará que use import y export, y no proporcionará una función require(). Y si guardas tu código en un archivo que termina con .cjs, entonces Node siempre lo tratará como un módulo CommonJS, proveerá una función require(), y arrojará un SyntaxError si usas declaraciones import o export.</p>
    <p>Para los archivos que no tienen una extensión explícita .mjs o .cjs, Node busca un archivo llamado package.json en el mismo directorio que el archivo y luego en cada uno de los directorios que lo contienen. Una vez encontrado el archivo package.json más cercano, Node busca una propiedad type de nivel superior en el objeto JSON. Si el valor de la propiedad type es "module", entonces Node carga el archivo como un módulo ES6. Si el valor de esa propiedad es "commonjs", entonces Node carga el archivo como un módulo CommonJS. Tenga en cuenta que no es necesario tener un archivo package.json para ejecutar programas Node: cuando no se encuentra tal archivo (o cuando se encuentra el archivo pero no tiene una propiedad de tipo), Node utiliza por defecto módulos CommonJS. Este truco de package.json sólo se hace necesario si quieres usar módulos ES6 con Node y no quieres usar la extensión de archivo .mjs.</p>
    <p>Debido a que existe una enorme cantidad de código Node escrito usando el formato de módulo Com- monJS, Node permite a los módulos ES6 cargar módulos CommonJS usando la palabra clave import. Sin embargo, lo contrario no es cierto: un módulo CommonJS no puede usar require() para cargar un módulo ES6.</p>
  </section>
  <section id="1-5">
    <h2>16.1.5 El gestor de paquetes Node</h2>
    <p>Cuando instalas Node, normalmente obtienes también un programa llamado npm. Este es el gestor de paquetes de Node, y le ayuda a descargar y gestionar las bibliotecas de las que depende su programa. npm mantiene un registro de esas dependencias (así como otra información sobre su programa) en un archivo llamado package.json en el directorio raíz de su proyecto. Este archivo package.json creado por npm es donde añadirías "type": "module" si quisieras usar módulos ES6 para tu proyecto.</p>
    <p>Este capítulo no cubre npm en detalle (pero vea §17.4 para un poco más de profundidad). Lo menciono aquí porque a menos que escriba programas que no usen ninguna librería externa, es casi seguro que usará npm o una herramienta similar. Supongamos, por ejemplo, que vas a desarrollar un servidor web y planeas utilizar el framework Express (https://expressjs.com) para simplificar la tarea. Para empezar, puedes crear un directorio para tu proyecto, y entonces, en ese directorio escribe npm init. npm te preguntará por el nombre de tu proyecto, número de versión, etc., y entonces creará un archivo pack- age.json inicial basado en tus respuestas.</p>
    <p>Ahora, para empezar a usar Express, escribe npm install express. Esto le dice a npm que descargue la librería Express junto con todas sus dependencias e instale todos los paquetes en un directorio local node_modules/:</p>
    <p>Cuando instalas un paquete con npm, npm registra esta dependencia -que tu proyecto depende de Express- en el archivo package.json. Con esta dependencia registrada en package.json, usted podría dar a otro programador una copia de su código y su package.json, y podrían simplemente escribir npm install para descargar automáticamente e instalar en todas las librerías que su programa necesita para ejecutarse.</p>
  </section>
  <section id="2" class="py-4 xs:py-5 sm:py-6">
    <h2>16.2 Node es asíncrono por defecto </h2>
    <p>JavaScript es un lenguaje de programación de propósito general, por lo que es perfectamente posible escribir programas intensivos en CPU que multipliquen grandes matrices o realicen complicados análisis estadísticos. Pero Node se diseñó y optimizó para programas -como los servidores de red- que hacen un uso intensivo de la E/S. Y, en particular, Node fue diseñado para hacer posible la implementación sencilla de servidores altamente concurrentes que puedan manejar muchas peticiones al mismo tiempo.</p>
    <p>Sin embargo, a diferencia de muchos lenguajes de programación, Node no logra la concurrencia con hilos. La programación multihilo es notoriamente difícil de hacer correctamente, y difícil de depurar. Además, los hilos son una abstracción relativamente pesada y si desea escribir un servidor que pueda manejar cientos de solicitudes simultáneas, el uso de cientos de hilos puede requerir una cantidad prohibitiva de memoria. Así que Node adopta el modelo de programación JavaScript de un solo hilo que utiliza la web, y esto resulta ser una gran simplificación que hace que la creación de servidores de red sea una habilidad rutinaria en lugar de arcana.</p>
    <article>
      <p class="title-article">Paralelismo real con Node</p>
      <p>Los programas Node pueden ejecutar múltiples procesos del sistema operativo, y Node 10 y posteriores soportan objetos Worker (§16.11), que son un tipo de hilo prestado de los navegadores web. Si utiliza múltiples procesos o crea uno o más hilos Worker y ejecuta su programa en un sistema con más de una CPU, entonces su programa ya no será single-threaded y su programa realmente estará ejecutando múltiples flujos de código en paralelo. Estas técnicas pueden ser valiosas para operaciones intensivas de CPU pero no son comúnmente usadas para programas intensivos de E/S como los servidores.</p>
      <p>Cabe destacar, sin embargo, que los procesos y trabajadores de Node evitan la complejidad típica de la programación multihilo, ya que la comunicación entre procesos y trabajadores se realiza mediante el paso de mensajes y no pueden compartir fácilmente la memoria entre ellos.</p>
    </article>
    <p>Node alcanza altos niveles de concurrencia mientras mantiene un modelo de programación de un solo hilo haciendo que su API sea asíncrona y no bloqueante por defecto. Node se toma muy en serio su enfoque no bloqueante y llega a un extremo que puede sorprenderte. Probablemente esperes que las funciones que leen y escriben en la red sean asíncronas, pero Node va más allá y define funciones asíncronas no bloqueantes para leer y escribir archivos del sistema de archivos local. Esto tiene sentido si lo piensas: la API de Node se diseñó en la época en la que los discos duros giraban sobre sí mismos. todavía eran la norma y realmente había milisegundos de "tiempo de búsqueda" de bloqueo mientras se esperaba a que el disco girara antes de que pudiera comenzar una operación de archivo. Y en los centros de datos modernos, el sistema de archivos "local" puede estar en algún lugar de la red, con latencias de red además de las latencias del disco. Pero incluso si leer un archivo de forma asíncrona le parece normal, Node va más allá: las funciones por defecto para iniciar una conexión de red o buscar la hora de modificación de un archivo, por ejemplo, también son no bloqueantes.</p>
    <p>Algunas funciones de la API de Node son síncronas pero no bloqueantes: se ejecutan hasta el final y vuelven sin necesidad de bloquearse. Pero la mayoría de las funciones interesantes realizan algún tipo de entrada o salida, y éstas son funciones asíncronas para evitar el más mínimo bloqueo. Node fue creado antes de que JavaScript tuviera una clase Promise, por lo que las APIs asíncronas de Node están basadas en callbacks. (Si aún no has leído o ya has olvidado el Capítulo 13, éste sería un buen momento para volver a ese capítulo). Generalmente, el último argumento que se pasa a una función asíncrona de Node es un callback. Node utiliza devoluciones de llamada de error primero, que normalmente se invocan con dos argumentos. El primer argumento es normalmente null en el caso de que no se haya producido ningún error, y el segundo argumento es cualquier dato o respuesta producida por la función asíncrona original a la que se ha llamado. La razón de poner el argumento de error en primer lugar es para que sea imposible omitirlo, y siempre se debe comprobar si hay un valor no nulo en este argumento. Si es un objeto Error, o incluso un código de error entero o un mensaje de error de cadena, entonces algo ha ido mal. En este caso, es probable que el segundo argumento de su función callback sea nulo.</p>
    <p>El siguiente código muestra cómo utilizar la función no bloqueante readFile() para leer un archivo de configuración, analizarlo como JSON y, a continuación, pasar el objeto de configuración analizado a otra llamada de retorno:</p>
    <p>Node es anterior a las promesas estandarizadas, pero dado que es bastante consistente con sus devoluciones de llamada basadas en errores, es fácil crear variantes basadas en promesas de sus APIs basadas en devoluciones de llamada utilizando la envoltura util.promisify(). Así es como podemos reescribir la función readCon figFile() para que devuelva una Promise:</p>
    <p>También podemos simplificar la función anterior basada en promesas utilizando async y await (de nuevo, si aún no has leído el capítulo 13, este sería un buen momento para hacerlo):</p>
    <p>La envoltura util.promisify() puede producir una versión basada en promesas de muchas funciones de Node. En Node 10 y posteriores, el objeto fs.promises tiene una serie de funciones predefinidas basadas en promesas para trabajar con el sistema de archivos. Las discutiremos más adelante en este capítulo, pero tenga en cuenta que en el código anterior, podríamos reemplazar pfs.readFile() con fs.promises.readFile().</p>
    <p>Hemos dicho que el modelo de programación de Node es asíncrono por defecto. Pero para comodidad del programador, Node define variantes síncronas bloqueantes de muchas de sus funciones, especialmente en el módulo del sistema de archivos. Estas funciones suelen tener nombres claramente etiquetados con Sync al final.</p>
    <p>Cuando un servidor está arrancando y está leyendo sus ficheros de configuración, no está recibiendo peticiones de red todavía, y poca o ninguna concurrencia es posible. Así que en esta situación, realmente no hay necesidad de evitar el bloqueo, y podemos utilizar con seguridad funciones de bloqueo como fs.readFileSync(). Podemos eliminar async y await de este código y escribir una versión puramente síncrona de nuestra función readConfigFile(). En lugar de invocar un callback o devolver una Promise, esta función simplemente devuelve el valor JSON analizado o lanza una excepción:</p>
    <p>Además de sus devoluciones de llamada de dos argumentos en caso de error, Node también tiene una serie de APIs que utilizan la asincronía basada en eventos, normalmente para manejar el flujo de datos. Cubriremos los eventos de Node con más detalle más adelante.</p>
    <p>Ahora que hemos discutido la agresiva API no bloqueante de Node, volvamos al tema de la concurrencia. Las funciones no bloqueantes incorporadas en Node funcionan usando la versión del sistema operativo de callbacks y manejadores de eventos. Cuando se llama a una de estas funciones, Node toma medidas para iniciar la operación, luego registra algún tipo de controlador de eventos con el sistema operativo para que se le notifique cuando la operación se haya completado. La llamada de retorno que pasaste a la función Node se almacena internamente para que Node pueda invocar tu llamada de retorno cuando el sistema operativo envíe el evento apropiado a Node.</p>
    <p>Este tipo de concurrencia suele denominarse concurrencia basada en eventos. En su núcleo, Node tiene un único hilo que ejecuta un "bucle de eventos". Cuando se inicia un programa Node, ejecuta cualquier código que le hayas dicho que ejecute. Este código presumiblemente llama al menos a una función no bloqueante que causa una llamada de retorno o un manejador de eventos a ser registrado con el sistema operativo. (Si no, entonces has escrito un programa Node síncrono, y Node simplemente sale cuando llega al final). Cuando Node llega al final de tu programa, se bloquea hasta que ocurre un evento, momento en el que el SO lo pone en marcha de nuevo. Node mapea el evento del SO a la llamada de retorno JavaScript que registraste y luego invoca esa función. Tu función callback puede invocar más funciones Node no bloqueantes, haciendo que se registren más manejadores de eventos OS. Una vez que tu función callback termina de ejecutarse, Node vuelve a dormir y el ciclo se repite.</p>
    <p>Para los servidores web y otras aplicaciones de E/S intensivas que pasan la mayor parte de su tiempo esperando entradas y salidas, este estilo de concurrencia basada en eventos es eficiente y eficaz. Un servidor web puede manejar simultáneamente peticiones de 50 clientes diferentes sin necesidad de 50 hilos diferentes, siempre que utilice APIs no bloqueantes y exista algún tipo de mapeo interno desde los sockets de red a las funciones JavaScript para invocar cuando se produce actividad en esos sockets.</p>
  </section>
  <section id="3">
    <h2>16.3 Búferes</h2>
    <p>Uno de los tipos de datos que probablemente utilices con frecuencia en Node -especialmente al leer datos de archivos o de la red- es la clase Buffer. Un Buffer es muy parecido a una cadena, excepto que es una secuencia de bytes en lugar de una secuencia de caracteres. Node se creó antes de que JavaScript soportara arrays tipados (véase §11.2) y no existiera Uint8Array para representar un array de bytes sin signo. Node definió la clase Buffer para cubrir esa necesidad. Ahora que Uint8Array es parte del lenguaje JavaScript, la clase Buffer de Node es una subclase de Uint8Array.</p>
    <p>Lo que distingue a Buffer de su superclase Uint8Array es que está diseñado para interoperar con cadenas JavaScript: los bytes de un buffer pueden inicializarse a partir de cadenas de caracteres o convertirse en cadenas de caracteres. Una codificación de caracteres asigna cada carácter de un conjunto de caracteres a un número entero. Dada una cadena de texto y una codificación de caracteres, podemos codificar los caracteres de la cadena en una secuencia de bytes. Y dada una secuencia (correctamente codificada) de bytes y una codificación de caracteres, podemos decodificar esos bytes en una secuencia de caracteres. La clase Buffer de Node tiene métodos que realizan tanto la codificación como la decodificación, y puedes reconocer estos métodos porque esperan un argumento de codificación que especifica la codificación a utilizar.</p>
    <p>Las codificaciones en Node se especifican por nombre, como cadenas. Las codificaciones admitidas son:</p>
    <p><codeinline>"utf8"</codeinline></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Este es el valor predeterminado cuando no se especifica ninguna codificación, y es la codificación Unicode que es más probable que utilice.</p>
    <p><codeinline>"utf16le"</codeinline></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Caracteres Unicode de dos bytes, con orden little-endian. Puntos de código por encima de \uffff se codifican como un par de secuencias de dos bytes. La codificación "ucs2" es un alias.</p>
    <p><codeinline>"latin1"</codeinline></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">La codificación ISO-8859-1 de un byte por carácter define un conjunto de caracteres adecuado para muchos idiomas de Europa Occidental. Dado que existe una correspondencia uno a uno entre bytes y caracteres latinos-1, esta codificación también se conoce como "binaria".</p>
    <p><codeinline>"ascii"</codeinline></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">La codificación ASCII de 7 bits sólo en inglés, un subconjunto estricto de la codificación "utf8".</p>
    <p><codeinline>"hex"</codeinline></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Esta codificación convierte cada byte en un par de dígitos hexadecimales ASCII.</p>
    <p><codeinline>"base64"</codeinline></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Esta codificación convierte cada secuencia de tres bytes en una secuencia de cuatro caracteres ascii.</p>
    <p>A continuación se muestra un código de ejemplo que demuestra cómo trabajar con Buffers y cómo convertir a y desde cadenas:</p>
    <p>Si escribes un programa Node que realmente manipula datos binarios, puedes encontrarte usando la clase Buffer extensivamente. Por otro lado, si sólo estás trabajando con texto que se lee o se escribe en un archivo o en la red, entonces sólo encontrarás Buffer como una representación intermedia de tus datos. Varias APIs de Node pueden recibir datos de entrada o devolverlos como cadenas u objetos Buffer. Normalmente, si pasas una cadena, o esperas que se devuelva una cadena, desde una de estas APIs, tendrás que especificar el nombre de la codificación de texto que quieres usar. Y si haces esto, puede que no necesites usar un objeto Buffer.</p>
  </section>
  <section id="4" class="py-4 xs:py-5 sm:py-6">
    <h2>16.4 Eventos y EventEmitter</h2>
    <p>Como se ha descrito, todas las APIs de Node son asíncronas por defecto. Para muchas de ellas, esta asincronía toma la forma de devoluciones de llamada de dos argumentos que se invocan cuando la operación solicitada se ha completado. Pero algunas de las API más complicadas se basan en eventos. Este suele ser el caso cuando la API está diseñada en torno a un objeto en lugar de una función, o cuando una función de devolución de llamada debe ser invocada varias veces, o cuando hay varios tipos de funciones de devolución de llamada que pueden ser necesarias. Consideremos la clase net.Server, por ejemplo: un objeto de este tipo es un socket de servidor que se utiliza para aceptar conexiones entrantes de clientes. Emite un evento "listening" cuando empieza a escuchar conexiones, un evento "connection" cada vez que un cliente se conecta, y un evento "close" cuando se ha cerrado y ya no está escuchando.</p>
    <p>En Node, los objetos que emiten eventos son instancias de EventEmitter o una subclase de EventEmitter:</p>
    <p>La principal característica de los EventEmitters es que permiten registrar funciones manejadoras de eventos con el método on(). Los EventEmitters pueden emitir múltiples tipos de eventos, y los tipos de eventos se identifican por su nombre. Para registrar un manejador de eventos, llame al m é todo on(), pasando el nombre del tipo de evento y la función que debe invocarse cuando se produce un evento de ese tipo. Los EventEmitters pueden invocar funciones manejadoras con cualquier número de argumentos, y necesitas leer la documentación para un tipo específico de evento de un EventEmitter específico para saber qué argumentos deberías esperar que se pasen:</p>
    <p>Si prefieres nombres de métodos más explícitos para registrar escuchadores de eventos, también puedes utilizar addListener(). Y puedes eliminar un receptor de eventos previamente registrado con off() o removeListener(). Como caso especial, puedes registrar un escuchador de eventos que se eliminará automáticamente después de que se active por primera vez llamando a once() en lugar de on().</p>
    <p>Cuando ocurre un evento de un tipo particular para un objeto EventEmitter en particular, Node invoca todas las funciones manejadoras que están actualmente registradas en ese EventEmitter para eventos de ese tipo. Se invocan en orden desde el primero registrado hasta el último. Si hay más de una función manejadora, se invocan secuencialmente en un único hilo: recuerda que no hay paralelismo en Node. Y, lo que es más importante, las funciones manejadoras de eventos se invocan de forma sincrónica, no asincrónica. Lo que esto significa es que el método emit() no pone en cola los manejadores de eventos para ser invocados en algún momento posterior. emit() invoca todos los manejadores registrados, uno tras otro, y no retorna hasta que el último manejador de eventos haya retornado.</p>
    <p>Lo que esto significa, en efecto, es que cuando una de las APIs incorporadas de Node emite un evento, esa API está básicamente bloqueando tus manejadores de eventos. Si escribes un manejador de eventos que llama a una función bloqueante como fs.readFileSync(), no ocurrirá ningún otro manejo de eventos hasta que tu lectura sincrónica de archivos esté completa. Si tu programa es uno -como un servidor de red- que necesita responder, entonces es importante que mantengas tus funciones manejadoras de eventos no bloqueantes y rápidas. Si necesitas hacer muchos cálculos cuando ocurre un evento, a menudo es mejor usar el manejador para programar esos cálculos asíncronamente usando setTimeout() (ver §11.10). Node también define setImmediate(), que programa una función para ser invocada inmediatamente después de que todas las llamadas de retorno y eventos pendientes hayan sido manejados.</p>
    <p>La clase EventEmitter también define un método emit() que hace que se invoquen las funciones manejadoras de eventos registradas. Esto es útil si usted está definiendo su propia API basada en eventos, pero no se utiliza comúnmente cuando sólo está programando con APIs existentes. emit() debe ser invocado con el nombre del tipo de evento como su primera argumento. Cualquier argumento adicional que se pase a emit() se convierte en argumento de las funciones manejadoras de eventos registradas. Las funciones manejadoras también son invocadas con el valor this establecido al propio objeto EventEmitter, lo que a menudo es conveniente. (Recuerde, sin embargo, que las funciones de flecha siempre utilizan el valor this del contexto en el que se definen, y no pueden ser invocadas con cualquier otro valor this. No obstante, las funciones de flecha son a menudo la forma más conveniente de escribir manejadores de eventos).</p>
    <p>Cualquier valor devuelto por una función manejadora de eventos es ignorado. Sin embargo, si una función manejadora de eventos lanza una excepción, ésta se propaga desde la llamada a emit() y previene la ejecución de cualquier función manejadora que haya sido registrada después de la que lanzó la excepción.</p>
    <p>Recuerda que las APIs basadas en callbacks de Node utilizan callbacks "error-first", y es importante que siempre compruebes el primer argumento del callback para ver si se ha producido un error. Con las APIs basadas en eventos, el equivalente son los eventos "error". Dado que las APIs basadas en eventos se utilizan a menudo para redes y otras formas de flujo de E/S, son vulnerables a errores asíncronos impredecibles, y la mayoría de los EventEmitters definen un evento "error" que emiten cuando se produce un error. Siempre que utilices una API basada en eventos, deberías tener la costumbre de registrar un manejador para los eventos "error". Los eventos "error" reciben un tratamiento especial por parte de la clase EventEmitter. Si se llama a emit() para emitir un evento de "error" y no hay ningún controlador registrado para ese tipo de evento, se lanzará una excepción. Dado que esto ocurre de forma asíncrona, no hay manera de manejar la excepción en un bloque catch, por lo que este tipo de error suele provocar la salida del programa.</p>
  </section>
  <section id="5">
    <h2>16.5 Arroyos</h2>
    <p>Cuando se implementa un algoritmo para procesar datos, casi siempre es más fácil leer todos los datos en la memoria, hacer el procesamiento, y luego escribir los datos. Por ejemplo, podrías escribir una función de Nodo para copiar un archivo como esta.1</p>
    <p>Esta función copyFile() utiliza funciones asíncronas y callbacks, por lo que no se bloquea y es adecuada para su uso en programas concurrentes como servidores. Pero note que debe asignar suficiente memoria para mantener todo el contenido del archivo en memoria a la vez. Esto puede estar bien en algunos casos de uso, pero empieza a fallar si los ficheros a copiar son muy grandes, o si su programa es altamente concurrente y puede haber muchos ficheros siendo copiados al mismo tiempo. Otro defecto de esta implementación de copyFile() es que no puede comenzar a escribir el nuevo archivo hasta que haya terminado de leer el archivo antiguo.</p>
    <p>La solución a estos problemas es utilizar algoritmos de flujo en los que los datos "fluyen" hacia el programa, se procesan y luego salen de él. La idea es que el algoritmo procese los datos en pequeños fragmentos y que el conjunto completo de datos no se almacene en memoria de una sola vez. Cuando las soluciones de streaming son posibles, son más eficientes en memoria y también pueden ser más rápidas. Las APIs de red de Node están basadas en streaming y el módulo de sistema de archivos de Node define APIs de streaming para leer y escribir archivos, por lo que es probable que utilices una API de streaming en muchos de los programas Node que escribas. Veremos una versión streaming de la función copyFile() en "Modo Flujo" en la página 598.</p>
    <p>Node admite cuatro tipos básicos de flujo:</p>
    <p><em>Readable</em></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Los flujos legibles son fuentes de datos. El flujo devuelto por fs.createRead Stream(), por ejemplo, es un flujo del que se puede leer el contenido de un archivo especificado. process.stdin es otro flujo legible que devuelve datos de la entrada estándar.</p>
    <p><em>Writable</em></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Los flujos de escritura son sumideros o destinos de datos. El valor de retorno de fs.crea teWriteStream(), por ejemplo, es un flujo escribible: permite que los datos se escriban en él en trozos, y envía todos esos datos a un archivo especificado.</p>
    <p><em>Duplex</em></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Los flujos dúplex combinan un flujo legible y un flujo escribible en un solo objeto. Los objetos Socket devueltos por net.connect() y otras APIs de red de Node, por ejemplo, son flujos Duplex. Si escribe en un socket, sus datos se envían a través de la red a cualquier ordenador al que esté conectado el socket. Y si lees desde un socket, accedes a los datos escritos por ese otro ordenador.</p>
    <p><em>Transform</em></p>
    <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Los flujos Transform también se pueden leer y escribir, pero difieren de los flujos Duplex en un aspecto importante: los datos escritos en un flujo Transform se leen, normalmente en alguna forma transformada, desde el mismo flujo. La función zlib.creaGzip(), por ejemplo, devuelve un flujo Transform que comprime (con el algoritmo gzip) los datos escritos en él. De forma similar, la función crypto.createCipheriv() devuelve un flujo Transform que encripta o desencripta los datos que se escriben en él.</p>
    <p>Por defecto, los flujos leen y escriben buffers. Si llamas al método setEncoding() de un stream Readable, te devolverá cadenas decodificadas en lugar de objetos Buffer. Y si escribes una cadena en un buffer Writable, se codificará automáticamente usando la codificación por defecto del buffer o cualquier codificación que especifiques. La API de flujos de Node también soporta un "modo objeto" en el que los flujos leen y escriben objetos más complejos que buffers y cadenas. Ninguna de las APIs del núcleo de Node utiliza este modo objeto, pero puede encontrarlo en otras bibliotecas.</p>
    <p>Los flujos legibles tienen que leer sus datos de alguna parte, y los flujos escribibles tienen que escribir sus datos en alguna parte, por lo que cada flujo tiene dos extremos: una entrada y una salida o una fuente y un destino. Lo complicado de las APIs basadas en flujos es que l o s dos extremos del flujo casi siempre fluyen a velocidades diferentes. Puede que el código que lee de un flujo quiera leer y procesar los datos más rápido de lo que se escriben en el flujo. O al revés: tal vez los datos se escriben en un flujo más rápido de lo que pueden leerse y extraerse del flujo en el otro extremo. Las implementaciones de flujos casi siempre incluyen un búfer interno para almacenar los datos que se han escrito pero que aún no se han leído. El almacenamiento en búfer ayuda a garantizar que hay datos disponibles para leer cuando se solicitan, y que hay espacio para mantener los datos cuando se escriben. Pero ninguna de estas cosas puede garantizarse nunca, y es la naturaleza de la programación basada en flujos que los lectores a veces tendrán que esperar a que los datos se escriban (porque el búfer del flujo está vacío), y los escritores a veces tendrán que esperar a que los datos se lean (porque el búfer del flujo está lleno).</p>
    <p>En entornos de programación que utilizan concurrencia basada en hilos, las APIs de flujo normalmente tienen llamadas de bloqueo: una llamada para leer datos no vuelve hasta que los datos llegan al flujo y una llamada para escribir datos se bloquea hasta que hay suficiente espacio en el búfer interno del flujo para acomodar los nuevos datos. Sin embargo, con un modelo de concurrencia basado en eventos, las llamadas de bloqueo no tienen sentido, y las APIs de flujo de Node están basadas en eventos y callbacks. A diferencia de otras APIs de Node, no hay versiones "Sync" de los métodos que se describirán más adelante en este capítulo.</p>
    <p>La necesidad de coordinar la legibilidad del flujo (búfer no vacío) y la escritura (búfer no lleno) a través de eventos hace que las APIs de flujo de Node sean algo complicadas. Esto se ve agravado por el hecho de que estas APIs han evolucionado y cambiado a lo largo de los años: para flujos legibles, hay dos APIs completamente distintas que puedes usar. A pesar de la complejidad, vale la pena entender y dominar las APIs de streaming de Node porque permiten una E/S de alto rendimiento en tus programas.</p>
    <p>Las subsecciones siguientes muestran cómo leer y escribir desde las clases de flujo de Node.</p>
  </section>
  <section id="5-1" class="py-4 xs:py-5 sm:py-6">
    <h2>16.5.1 Tuberías</h2>
    <p>A veces, es necesario leer datos de un flujo para luego escribir esos mismos datos en otro flujo. Imagina, por ejemplo, que estás escribiendo un simple archivo Servidor HTTP que sirve un directorio de archivos estáticos. En este caso, necesitarás leer datos de un archivo de entrada y escribirlos en un socket de red. Pero en lugar de escribir tu propio código para manejar la lectura y escritura, puedes simplemente conectar los dos sockets juntos como una "tubería" y dejar que Node maneje las complejidades por ti. Simplemente pasa el flujo Writable al método pipe() del flujo Readable:</p>
    <p>La siguiente función de utilidad canaliza un flujo a otro e invoca una llamada de retorno cuando termina o cuando se produce un error:</p>
    <p>Los flujos de transformación son particularmente útiles con las tuberías, y crean tuberías que implican más de dos flujos. He aquí una función de ejemplo que comprime un archivo:</p>
    <p>Usar el método pipe() para copiar datos de un flujo Legible a un flujo Legible es fácil, pero en la práctica, a menudo necesitas procesar los datos de alguna manera mientras fluyen a través de tu programa. Una forma de hacer esto es implementar su propio flujo Transform para hacer ese procesamiento, y este enfoque le permite evitar la lectura y escritura manual de los flujos. Aquí, por ejemplo, hay una función que funciona como la utilidad grep de Unix: lee líneas de texto de un flujo de entrada, pero escribe sólo las líneas que coinciden con una expresión regular especificada:</p>
  </section>
  <section id="5-2">
    <h2>16.5.2 Iteración asíncrona</h2>
    <p>En Nodo 12 y posteriores, los flujos legibles son iteradores asíncronos, lo que significa que dentro de una función asíncrona puedes usar un bucle for/await para leer trozos de cadena o Buffer de un flujo usando código que está estructurado como lo estaría el código síncrono. (Ver §13.4 para más información sobre iteradores asíncronos y bucles for/await).</p>
    <p>Usar un iterador asíncrono es casi tan fácil como usar el método pipe(), y es probablemente más fácil cuando necesitas procesar cada trozo que lees de alguna manera. Así es como podríamos reescribir el programa grep de la sección anterior usando una función asíncrona y un bucle for/await:</p>
  </section>
  <section id="5-3" class="py-4 xs:py-5 sm:py-6">
    <h2>16.5.3 Escribir en Streams y manejar la contrapresión</h2>
    <p>La función async grep() en el ejemplo de código anterior demostró cómo usar un flujo Readable como un iterador asíncrono, pero también demostró que puedes escribir datos a un flujo Writable simplemente pasándolo al método write(). El método write() toma un buffer o cadena como primer argumento. (Los flujos de objetos esperan otros tipos de objetos, pero están fuera del alcance de este capítulo). Si pasas un buffer, los bytes de ese buffer serán escritos directamente. Si pasas una cadena, será codificada en un buffer de bytes antes de ser escrita. Los flujos escribibles tienen una codificación por defecto que se utiliza cuando se pasa una cadena como único argumento a write(). La codificación por defecto es típicamente "utf8", pero puedes establecerla explícitamente llamando a setDefaultEncod ing() en el flujo Writable. Alternativamente, cuando se pasa una cadena como primer argumento a write() se puede pasar un nombre de codificación como segundo argumento.</p>
    <p>write() toma opcionalmente una función callback como tercer argumento. Esta será invocada cuando los datos hayan sido realmente escritos y ya no se encuentren en el buffer interno del flujo Writable. (Esta llamada de retorno también puede ser invocada si se produce un error, pero esto no está garantizado. Deberías registrar un manejador de eventos "error" en el flujo Writable para detectar errores).</p>
    <p>El método write() tiene un valor de retorno muy importante. Cuando llamas a write() en un flujo, siempre aceptará y almacenará en el buffer el trozo de datos que le has pasado. Entonces devuelve true si el buffer interno aún no está lleno. O, si el buffer está lleno o sobre-lleno, devuelve false. Este valor de retorno es consultivo, y puede ignorarlo: los flujos escribibles ampliarán su búfer interno tanto como sea necesario si sigue llamando a write(). Pero recuerde que la razón para utilizar una API de flujo en primer lugar es evitar el coste de mantener muchos datos en memoria a la vez.</p>
    <p>Un valor de retorno falso del método write() es una forma de contrapresión: una señal del flujo de que has escrito datos más rápido de lo que pueden ser manejados.</p>
    <p>La respuesta adecuada a este tipo de contrapresión es dejar de llamar a write() hasta que el flujo emita un evento "drain", indicando que de nuevo hay espacio en el buffer. Aquí, por ejemplo, hay una función que escribe en un flujo, y luego invoca una llamada de retorno cuando está bien escribir más datos en el flujo:</p>
    <p>El hecho de que a veces esté bien llamar a write() varias veces seguidas y algunas veces tengas que esperar un evento entre escrituras hace que los algoritmos sean incómodos. Esta es una de las razones por las que usar el método pipe() es tan atractivo: cuando usas pipe(), Node maneja la contrapresión por ti automáticamente.</p>
    <p>Si estás usando await y async en tu programa, y estás tratando flujos legibles como iteradores asíncronos, es sencillo implementar una versión basada en Promise de la función de utilidad write() anterior para manejar adecuadamente la contrapresión. En la función asíncrona grep() que acabamos de ver, no manejamos la contrapresión. La función async copy() del siguiente ejemplo demuestra cómo hacerlo correctamente. Ten en cuenta que esta función sólo copia trozos de un flujo de origen a un flujo de destino y llamar a copy(source, destination) es como llamar a source.pipe(destina tion):</p>
    <p>Antes de concluir esta discusión sobre la escritura en flujos, ten en cuenta de nuevo que no responder a la contrapresión puede hacer que tu programa use más memoria de la que debería cuando el buffer interno de un flujo escribible se desborde y crezca más y más. Si estás escribiendo un servidor de red, esto puede ser un problema de seguridad explotable remotamente. Supongamos que escribes un servidor HTTP que entrega archivos a través de la red, pero no usas pipe() y no te has tomado el tiempo de manejar la contrapresión del método write(). Un atacante podría escribir un cliente HTTP que inicie peticiones de archivos grandes (como imágenes) pero que nunca lea el cuerpo de la petición. Dado que el cliente no está leyendo los datos a través de la red, y el servidor no está respondiendo a la contrapresión, los buffers en el servidor se desbordarán. Con suficientes conexiones concurrentes del atacante, esto puede convertirse en un ataque de denegación de servicio que ralentice tu servidor o incluso lo bloquee.</p>
  </section>
  <section id="5-4">
    <h2>16.5.4 Lectura de flujos con eventos</h2>
    <p>Los flujos legibles de Node tienen dos modos, cada uno de los cuales tiene su propia API para la lectura. Si no puedes usar tuberías o iteración asíncrona en tu programa, tendrás que elegir una de estas dos APIs basadas en eventos para manejar los flujos. Es importante que utilices sólo una u otra y no mezcles las dos APIs.</p>
    <p class="title-article text-left">Modo de flujo</p>
    <p>En modo flujo, cuando llegan datos legibles, se emiten inmediatamente en forma de evento "datos" . Para leer de un flujo en este modo, simplemente registre un manejador de eventos para eventos "datos", y el flujo le enviará trozos de datos (buffers o cadenas) tan pronto como estén disponibles. Tenga en cuenta que no hay necesidad de llamar al método read() en modo flujo: sólo necesita manejar los eventos "data". Tenga en cuenta que los flujos recién creados no se inician en modo flujo. Registrar un manejador de eventos "data" cambia un flujo al modo de flujo. Convenientemente, esto significa que un flujo no emite eventos "datos" hasta que registras el primer manejador de eventos "datos".</p>
    <p>Si está utilizando el modo de flujo para leer datos de un flujo Legible, procesarlos y luego escribirlos en un flujo Legible, entonces puede que necesite manejar la contrapresión del flujo Legible. Si el método write() devuelve false para indicar que el buffer de escritura está lleno, puedes llamar a pause() en el flujo Legible para detener temporalmente los eventos de datos. Entonces, cuando recibas un evento de "drenaje" del flujo escribible, puedes llamar a resume() en el flujo legible para que los eventos de "datos" comiencen a fluir de nuevo.</p>
    <p>Un flujo en modo flujo emite un evento "fin" cuando se alcanza el final del flujo. Este evento indica que no se emitirán más eventos "datos". Y, como en todos los flujos, se emite un evento "error" si se produce un error.</p>
    <p>Al principio de esta sección sobre flujos, mostramos una función copyFile() sin flujo y prometimos que vendría una versión mejor. El siguiente código muestra cómo implementar una función copyFile() de flujo que utiliza la API de modo de flujo y maneja la contrapresión. Esto habría sido más fácil de implementar con una llamada a pipe(), pero sirve aquí como una demostración útil de los múltiples manejadores de eventos que se utilizan para coordinar el flujo de datos de un flujo a otro.</p>
    <p class="title-article text-left">Modo pausa</p>
    <p>El otro modo para los flujos legibles es el "modo pausado". Este es el modo en el que comienzan los flujos. Si nunca registras un manejador de eventos "data" y nunca llamas al método pipe(), entonces un flujo Legible permanece en modo pausado. En modo pausado, el flujo no envía datos en forma de eventos "data". En su lugar, usted extrae datos del flujo llamando explícitamente a su método read(). Esta no es una llamada de bloqueo, y si no hay datos disponibles para leer en el flujo, devolverá null. Dado que no existe una API sincrónica para esperar datos, la API del modo pausado también se basa en eventos. Un flujo legible en modo pausado emite eventos "legibles" cuando hay datos disponibles para leer en el flujo. En respuesta, tu código debe llamar al método read() para leer esos datos. Debes hacer esto en un bucle, llamando a read() repetidamente hasta que devuelva null. Es necesario vaciar completamente el buffer del stream de esta manera para poder disparar un nuevo evento "readable" en el futuro. Si dejas de llamar a read() mientras todavía hay datos legibles, no obtendrás otro evento "legible" y es probable que tu programa se cuelgue.</p>
    <p>Los flujos en modo pausado emiten eventos de "fin" y "error" al igual que los flujos en modo continuo. Si estás escribiendo un programa que lee datos de un flujo legible y los escribe en un flujo escribible, entonces el modo pausado puede no ser una buena opción. Para manejar adecuadamente la contrapresión, sólo querrá leer cuando el flujo de entrada sea legible y el flujo de salida no esté respaldado. En el modo pausado, esto significa leer y escribir hasta que read() devuelva null o write() devuelva false, y entonces comenzar a leer o escribir de nuevo en un evento de lectura o drenaje. Esto es poco elegante, y usted puede encontrar que el modo de flujo (o tuberías) es más fácil en este caso.</p>
    <p>El siguiente código demuestra cómo se puede calcular un hash SHA256 para los contenidos de un archivo especificado. Utiliza un flujo legible en modo pausado para leer el contenido de un archivo en trozos, luego pasa cada trozo al objeto que calcula el hash. (Tenga en cuenta que en Node 12 y posteriores, sería más sencillo escribir esta función utilizando un bucle for/await de ).</p>
  </section>
  <section id="6" class="py-4 xs:py-5 sm:py-6">
    <h2>16.6 Detalles del proceso, la CPU y el sistema operativo</h2>
    <p>El objeto global Process tiene una serie de propiedades y funciones útiles que generalmente se relacionan con el estado del proceso Node que se está ejecutando en ese momento. Consulte la documentación de Node para más detalles, pero aquí hay algunas propiedades y funciones que debe conocer:</p>
    <p>El módulo "os" (que, a diferencia de process, necesita ser cargado explícitamente con require()) proporciona acceso a detalles de bajo nivel similares sobre el ordenador y el sistema operativo en el que se está ejecutando Node. Puede que nunca necesites usar ninguna de estas características, pero vale la pena saber que Node las pone a tu disposición:</p>
  </section>
  <section id="7">
    <h2>16.7 Trabajar con archivos</h2>
    <p>El módulo "fs" de Node es una completa API para trabajar con archivos y directorios. Se complementa con el módulo "path", que define funciones de utilidad para trabajar con nombres de archivos y directorios. El módulo "fs" contiene un puñado de funciones de alto nivel para leer, escribir y copiar archivos fácilmente. Pero la mayoría de las funciones del módulo son enlaces JavaScript de bajo nivel a llamadas del sistema Unix (y sus equivalentes en Windows). Si ha trabajado antes con llamadas de bajo nivel al sistema de archivos (en C u otros lenguajes), la API de Node le resultará familiar. Si no, puede que algunas partes de l a A P I "fs" le resulten concisas y poco intuitivas. La función para borrar un archivo, por ejemplo, se llama unlink().</p>
    <p>El módulo "fs" define una gran API, principalmente porque suele haber múltiples var- iants de cada operación fundamental. Como se discutió al principio del capítulo, la mayoría de las funciones como fs.readFile() son no bloqueantes, basadas en callback y asíncronas. Típicamente, sin embargo, cada una de estas funciones tiene una variable de bloqueo síncrono, como fs.readFileSync(). En Node 10 y posteriores, muchas de estas funciones también tienen una variante asíncrona basada en promesas, como fs.promises.readFile(). La mayoría de las funciones "fs" toman una cadena como primer argumento, especificando la ruta (nombre de archivo más nombres de directorio opcionales) al archivo sobre el que se va a operar. Pero algunas de estas funciones también admiten una variante que toma un "descriptor de fichero" entero como primer argumento en lugar de una ruta. Estas variantes tienen nombres que empiezan por la letra "f". Por ejemplo, fs.truncate() trunca un archivo especificado por la ruta, y fs.ftruncate() trunca un archivo especificado por el descriptor de archivo. Existe una fs.promises.truncate() basada en promesas que espera una ruta y otra versión basada en promesas que se implementa como un método de un objeto FileHandle. (La clase FileHandle es el equivalente de un descriptor de archivo en la API basada en promesas). Finalmente, hay un puñado de funciones en el módulo "fs" que tienen variantes cuyos nombres están prefijados con la letra "l". Estas variantes "l" son como la función base, pero no siguen los enlaces simbólicos en el sistema de ficheros, sino que operan directamente sobre los propios enlaces simbólicos.</p>
  </section>
  <section id="7-1" class="py-4 xs:py-5 sm:py-6">
    <h2>16.7.1 Rutas, descriptores de archivos y FileHandles</h2>
    <p>Para poder utilizar el módulo "fs" para trabajar con ficheros, primero tienes que poder nombrar el fichero con el que quieres trabajar. La mayoría de las veces, los ficheros se especifican por ruta, lo que significa el nombre del propio fichero, más la jerarquía de directorios en la que aparece el fichero. Si una ruta es absoluta, significa que se especifican todos los directorios hasta la raíz del sistema de archivos. En caso contrario, la ruta es relativa y sólo tiene sentido en relación con otra ruta, normalmente el directorio de trabajo actual. Trabajar con rutas puede ser un poco complicado porque los diferentes sistemas operativos utilizan diferentes caracteres para separar los nombres de los directorios, es fácil duplicar accidentalmente esos caracteres separadores al concatenar rutas, y porque los segmentos de ruta del directorio padre ../ necesitan un tratamiento especial. El módulo "path" de Node y un par de otras características importantes de Node ayudan:</p>
    <p>Tenga en cuenta que path.normalize() es simplemente una función de manipulación de cadenas que no tiene acceso al sistema de archivos real. Las funciones fs.realpath() y fs.realpathSync() realizan una canonización consciente del sistema de archivos: resuelven enlaces simbólicos e interpretan rutas relativas al directorio de trabajo actual.</p>
    <p>En los ejemplos anteriores, asumimos que el código se está ejecutando en un SO basado en Unix y path.sep es "/". Si desea trabajar con rutas al estilo Unix aunque esté en un sistema Win- dows, utilice path.posix en lugar de path. Y a la inversa, si desea trabajar con rutas Windows incluso en un sistema Unix, utilice path.win32. path.posix y path.win32 definen las mismas propiedades y funciones que path.</p>
    <p>Algunas de las funciones "fs" que veremos en las próximas secciones esperan un descriptor de fichero en lugar de un nombre de fichero. Los descriptores de archivo son números enteros que se utilizan como referencias a nivel de sistema operativo para los archivos "abiertos". Se obtiene un descriptor para un nombre dado llamando a la función fs.open() (o fs.openSync()). A los procesos sólo se les permite tener un número limitado de archivos abiertos al mismo tiempo, por lo que es importante que llame a fs.close() en sus descriptores de archivo cuando haya terminado con ellos. Necesita abrir archivos si desea utilizar las funciones de bajo nivel fs.read() y fs.write() que le permiten saltar dentro de un archivo, leyendo y escribiendo partes de él en diferentes momentos. Hay otras funciones en el módulo "fs" que utilizan descriptores de archivo, pero todas tienen versiones basadas en nombres, y sólo tiene sentido utilizar las funciones basadas en descriptores si se va a abrir el archivo para leer o escribir de todos modos.</p>
    <p>Por último, en la API basada en promesas definida por fs.promises, el equivalente de fs.open() es fs.promises.open(), que devuelve una promesa que resuelve un objeto FileHandle. Este objeto FileHandle sirve para el mismo propósito que un descriptor de archivo. De nuevo, sin embargo, a menos que necesites usar los métodos de bajo nivel read() y write() de un FileHandle, realmente no hay razón para crear uno. Y si creas un FileHandle, debes recordar llamar a su método close() una vez que hayas terminado con él.</p>
  </section>
  <section id="7-2">
    <h2>16.7.2 Archivos de lectura</h2>
    <p>Node permite leer el contenido de los archivos de una sola vez, a través de un stream o con la API de bajo nivel.</p>
    <p>Si sus archivos son pequeños, o si el uso de memoria y el rendimiento no son la prioridad más alta, entonces a menudo es más fácil de leer todo el contenido de un archivo con una sola llamada. Usted puede hacer esto de forma sincrónica, con una devolución de llamada, o con una promesa. Por defecto, obtendrá los bytes del archivo como un buffer, pero si especifica una codificación, obtendrá una cadena decodificada en su lugar.</p>
    <p>Si puedes procesar el contenido de un fichero secuencialmente y no necesitas tener todo el contenido del fichero en memoria al mismo tiempo, entonces leer un fichero a través de un stream puede ser el enfoque más eficiente. Hemos cubierto los flujos extensamente: aquí está cómo usted podría utilizar un flujo y el método pipe() para escribir el contenido de un archivo a la salida estándar:</p>
    <p>Por último, si necesita un control de bajo nivel sobre qué bytes lee exactamente de un archivo y cuándo los lee, puede abrir un archivo para obtener un descriptor de archivo y, a continuación, utilizar fs.read(), fs.readSync() o fs.promises.read() para leer un número especificado de bytes desde una ubicación de origen especificada del archivo en un búfer especificado en la posición de destino especificada:</p>
    <p>Por último, si necesita un control de bajo nivel sobre qué bytes lee exactamente de un archivo y cuándo los lee, puede abrir un archivo para obtener un descriptor de archivo y, a continuación, utilizar fs.read(), fs.readSync() o fs.promises.read() para leer un número especificado de bytes desde una ubicación de origen especificada del archivo en un búfer especificado en la posición de destino especificada:</p>
    <p>La API read() basada en callback es incómoda de usar si necesitas leer más de un trozo de datos de un archivo. Si puede utilizar la API sincrónica (o la API basada en promesas con await), resulta fácil leer varios fragmentos de un archivo:</p>
  </section>
  <section id="7-3" class="py-4 xs:py-5 sm:py-6">
    <h2>16.7.3 Archivos de escritura</h2>
    <p>Escribir archivos en Node es muy parecido a leerlos, con algunos detalles extra que debes conocer. Uno de estos detalles es que la forma de crear un nuevo archivo es simplemente escribiendo en un nombre de archivo que aún no existe.</p>
    <p>Al igual que con la lectura, hay tres formas básicas de escribir archivos en Node. Si tienes todo el contenido del archivo en una cadena o un buffer, puedes escribirlo todo en una llamada con fs.writeFile() (basado en callback), fs.writeFileSync() (síncrono), o fs.promises.writeFile() (basado en promesas):</p>
    <p>Si los datos que está escribiendo en el archivo son una cadena y desea utilizar una codificación distinta de "utf8", pase la codificación como tercer argumento opcional.</p>
    <p>Las funciones relacionadas fs.appendFile(), fs.appendFileSync() y fs.promises.appendFile() son similares, pero cuando el archivo especificado ya existe, añaden sus datos al final en lugar de sobrescribir el contenido del archivo existente.</p>
    <p>Si los datos que quieres escribir en un fichero no están todos en un trozo, o si no están todos en la memoria al mismo tiempo, entonces usar un flujo escribible es un buen enfoque, asumiendo que planeas escribir los datos de principio a fin sin saltarte nada en el fichero:</p>
    <p>Por último, si desea escribir datos en un archivo en varios trozos, y desea poder controlar la posición exacta dentro del archivo en la que se escribe cada trozo, entonces puede abrir el archivo con fs.open(), fs.openSync(), o fs.promises.open() y luego utilizar el descriptor de archivo resultante con las funciones fs.write() o fs.writeSync(). Estas funciones vienen en diferentes formas para cadenas y buffers. La variante de cadena toma un descriptor de archivo, una cadena y la posición de archivo en la que escribir esa cadena (con una codificación como cuarto argumento opcional). La variante buffer toma un descriptor de fichero, un buffer, un offset y una longitud que especifican un trozo de datos dentro del buffer, y una posición de fichero en la que escribir los bytes de ese trozo. Y si tiene una matriz de Los objetos buffer que desee escribir, puede hacerlo con una sola fs.writev() o fs.writevSync(). Existen funciones de bajo nivel similares para escribir buffers y cadenas usando fs.promises.open() y el objeto FileHandle que produce.</p>
    <article>
      <p class="title-article">Cadenas de modo de archivo</p>
      <p>Vimos los métodos fs.open() y fs.openSync() antes cuando usamos la API de bajo nivel para leer archivos. En ese caso, bastaba con pasar el nombre del archivo a la función open. Sin embargo, cuando se desea escribir un archivo, también se debe especificar un segundo argumento de cadena que especifique cómo se pretende utilizar el descriptor de archivo. Algunas de las cadenas de banderas disponibles son las siguientes:</p>
      <p><codeinline>"w"</codeinline></p>
      <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Abrir el archivo para escribir</p>
      <p><codeinline>"w+"</codeinline></p>
      <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Abierto a la escritura y la lectura</p>
      <p><codeinline>"wx"</codeinline></p>
      <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Abrir para crear un nuevo archivo; falla si el archivo nombrado ya existe</p>
      <p><codeinline>"wx+"</codeinline></p>
      <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Abrir para creación, y también permitir lectura; falla si el archivo nombrado ya existe</p>
      <p><codeinline>"a"</codeinline></p>
      <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Abrir el archivo para añadirlo; el contenido existente no se sobrescribirá.</p>
      <p><codeinline>"a+"</codeinline></p>
      <p class="pl-6 xs:pl-7 sm:pl-8 md:pl-9">Abierto para añadir, pero también permite leer</p>
      <p>Si no pasa uno de estos indicadores a fs.open() o fs.openSync(), éstos utilizarán el indicador "r" por defecto, haciendo que el descriptor de fichero sea de sólo lectura. Tenga en cuenta que también puede ser útil pasar estos indicadores a otros métodos de escritura de archivos:</p>
    </article>
    <p>Puede cortar el final de un archivo con fs.truncate(), fs.truncateSync() o fs.promises.truncate(). Estas funciones toman una ruta como primer argumento y una longitud como segundo, y modifican el archivo para que tenga la longitud especificada. Si se omite la longitud, se utiliza cero y el fichero queda vacío. A pesar del nombre de estas funciones también pueden utilizarse para ampliar un archivo: si se especifica una longitud mayor que el tamaño actual del archivo, éste se amplía con cero bytes hasta el nuevo tamaño. Si ya ha abierto el fichero que desea modificar, puede utilizar ftruncate() o ftruncateSync() con el descriptor de fichero o FileHandle</p>
    <p>Las diversas funciones de escritura de archivos descritas aquí devuelven o invocan su callback o resuelven su Promise cuando los datos han sido "escritos" en el sentido de que Node los ha entregado al sistema operativo. Pero esto no significa necesariamente que los datos se hayan escrito realmente en el almacenamiento persistente: al menos algunos de sus datos pueden estar todavía almacenados en algún lugar del sistema operativo o en un controlador de dispositivo a la espera de ser escritos en el disco. Si llama a fs.writeSync() para escribir de forma sincrónica algunos datos en un archivo, y si se produce un corte de energía inmediatamente después de que la función retorne, aún puede perder datos. Si desea forzar la salida de sus datos al disco para saber con certeza que se han guardado de forma segura, utilice fs.fsync() o fs.fsyncSync(). Estas funciones sólo funcionan con descriptores de fichero: no existe una versión basada en rutas.</p>
  </section>
  <section id="7-4">
    <h2>16.7.4 Operaciones de archivo</h2>
    <p>La discusión anterior sobre las clases stream de Node incluyó dos ejemplos de funciones copy File(). Estas no son utilidades prácticas que usted usaría realmente porque el módulo "fs" define su propio método fs.copyFile() (y también fs.copyFile Sync() y fs.promises.copyFile(), por supuesto).</p>
    <p>Estas funciones toman el nombre del archivo original y el nombre de la copia como sus dos primeros argumentos. Éstos pueden especificarse como cadenas o como objetos URL o Buffer. Un tercer argumento opcional es un número entero cuyos bits especifican indicadores que controlan los detalles de la operación de copia. Y para la función fs.copyFile() basada en callback, el argumento final es una función callback que será llamada sin argumentos cuando la copia se haya completado, o que será llamada con un argumento de error si algo falla. A continuación se muestran algunos ejemplos:</p>
    <p>La función fs.rename() (junto con las variantes síncronas y basadas en promesas) mueve y/o renombra un archivo. Llámela con la ruta actual al archivo y la nueva ruta deseada al archivo. No hay argumento flags, pero la versión basada en callback toma un callback como tercer argumento:</p>
    <p>Tenga en cuenta que no hay ningún indicador que impida que el cambio de nombre sobrescriba un archivo existente. También hay que tener en cuenta que los archivos sólo se pueden renombrar dentro de un sistema de archivos.</p>
    <p>Las funciones fs.link() y fs.symlink() y sus variantes tienen los mismos signos que fs.rename() y se comportan como fs.copyFile() excepto que crean enlaces duros y enlaces simbólicos, respectivamente, en lugar de crear una copia.</p>
    <p>Finalmente, fs.unlink(), fs.unlinkSync(), y fs.promises.unlink() son las funciones de Node para borrar un archivo. (La denominación poco intuitiva se hereda de Unix, donde borrar un archivo es básicamente lo contrario de crear un enlace duro a él). Llame a esta función con la cadena, buffer o ruta URL del archivo a borrar, y pase una llamada de retorno si está usando la versión basada en llamadas de retorno:</p>
  </section>
  <section id="7-5" class="py-4 xs:py-5 sm:py-6">
    <h2>16.7.5 Metadatos de archivos</h2>
    <p>Las funciones fs.stat(), fs.statSync() y fs.promises.stat() permiten obtener metadatos de un archivo o directorio especificado. Por ejemplo:</p>
    <p>El objeto Stats devuelto contiene otras propiedades y métodos más oscuros, pero este código muestra los que es más probable que utilice.</p>
    <p>fs.lstat() y sus variantes funcionan igual que fs.stat(), excepto que si el archivo especificado es un enlace simbólico, Node devolverá metadatos para el propio enlace en lugar de seguir el enlace.</p>
    <p>Si ha abierto un archivo para producir un descriptor de archivo o un objeto FileHandle, puede utilizar fs.fstat() o sus variantes para obtener información de metadatos del archivo abierto sin tener que especificar de nuevo el nombre del archivo.</p>
    <p>Además de consultar metadatos con fs.stat() y todas sus variantes, también existen funciones para modificar metadatos.</p>
    <p>fs.chmod(), fs.lchmod() y fs.fchmod() (junto con las versiones sincrónicas y basadas en promesas) establecen el "modo" o los permisos de un archivo o directorio. Los valores de modo son enteros en los que cada bit tiene un significado específico y es más fácil pensar en ellos en notación octal. Por ejemplo, para hacer que un archivo sea de sólo lectura para su propietario e inaccesible para todos los demás, utilice 0o400:</p>
    <p>fs.chown(), fs.lchown(), y fs.fchown() (junto con las versiones sincrónicas y basadas en promesas) establecen el propietario y el grupo (como IDs) para un archivo o directorio. (Estos importan porque interactúan con los permisos de archivo establecidos por fs.chmod().)</p>
    <p>Por último, puede establecer el tiempo de acceso y modificación de un archivo o directorio con fs.utimes() y fs.futimes() y sus variantes.</p>
  </section>
  <section id="7-6">
    <h2>16.7.6 Trabajar con directorios</h2>
    <p>Para crear un nuevo directorio en Node, utilice fs.mkdir(), fs.mkdirSync(), o fs.prom ises.mkdir(). El primer argumento es la ruta del directorio que se va a crear. El segundo argumento opcional puede ser un entero que especifica el modo (bits de permisos) para el nuevo directorio. O puede pasar un objeto con las propiedades opcionales mode y recur sive. Si recursivo es true, entonces esta función creará cualquier directorio en la ruta que no exista ya:</p>
    <p>fs.mkdtemp() y sus variantes toman un prefijo de ruta que usted proporciona, le añaden algunos caracteres aleatorios (esto es importante por seguridad), crean un directorio con ese nombre y le devuelven (o pasan a una llamada de retorno) la ruta del directorio.</p>
    <p>Para borrar un directorio, utilice fs.rmdir() o una de sus variantes. Tenga en cuenta que los directorios deben estar vacíos antes de poder ser borrados:</p>
    <p>El módulo "fs" proporciona dos API distintas para listar el contenido de un directorio. En primer lugar, fs.readdir(), fs.readdirSync() y fs.promises.readdir() leen todo el directorio a la vez y proporcionan una matriz de cadenas o una matriz de objetos Dirent que especifican los nombres y tipos (archivo o directorio) de cada elemento. Los nombres de archivo devueltos por estas funciones son sólo el nombre local del archivo, no la ruta completa. He aquí algunos ejemplos:</p>
    <p>Si anticipa que necesitará listar directorios que pueden tener miles de entradas, puede que prefiera el enfoque de fs.opendir() y sus variantes. Estas funciones devuelven un objeto Dir que representa el directorio especificado. Puede utilizar los métodos read() o readSync() del objeto Dir para leer un Dirent cada vez. Si pasa una función de llamada de retorno a read(), ésta llamará a la llamada de retorno. Y si omite el argumento callback, devolverá una Promise. Cuando no haya más entradas de directorio, obtendrá null en lugar de un objeto Dirent.</p>
    <p>La forma más sencilla de utilizar objetos Dir es como iteradores asíncronos con un bucle for/await. Aquí, por ejemplo, hay una función que utiliza la API de streaming para listar entradas de directorio, llama a stat() en cada entrada, e imprime nombres y tamaños de archivos y directorios:</p>
  </section>
  <section id="8" class="py-4 xs:py-5 sm:py-6">
    <h2>16.8 Clientes y servidores HTTP</h2>
    <p>Los módulos "http", "https" y "http2" de Node son implementaciones completas pero de nivel relativamente bajo de los protocolos HTTP. Definen API completas para implementar clientes y servidores HTTP. Debido a que las APIs son relativamente de bajo nivel, no hay espacio en este capítulo para cubrir todas las características. Pero los ejemplos que siguen demuestran cómo escribir clientes y servidores básicos.</p>
    <p>La forma más sencilla de realizar una petición HTTP GET básica es con http.get() o https.get(). El primer argumento de estas funciones es la URL que se desea obtener. (Si es una URL http://, debe utilizar el módulo "http", y si es una URL https:// debe utilizar el módulo "https"). El segundo argumento es un callback que será invocado con un objeto IncomingMessage cuando la respuesta del servidor haya empezado a llegar. Cuando se llama al callback, el estado HTTP y las cabeceras están disponibles, pero el cuerpo puede no estar listo todavía. El objeto IncomingMessage es un flujo Readable, y puede utilizar las técnicas demostradas anteriormente en este capítulo para leer el cuerpo de la respuesta desde él.</p>
    <p>La función getJSON() al final de §13.2.6 usaba la función http.get() como parte de una demostración del constructor Promise(). Ahora que conoces los streams de Node y el modelo de programación de Node en general, vale la pena revisar ese ejemplo para ver cómo se usa http.get().</p>
    <p>http.get() y https.get() son variantes ligeramente simplificadas de las funciones más generales http.request() y https.request(). La siguiente función postJSON() demuestra cómo utilizar https.request() para realizar una solicitud HTTPS POST que incluya un cuerpo de solicitud JSON. Al igual que la función getJSON() del Capítulo 13, espera una respuesta JSON y devuelve una Promise que cumple con la versión analizada de esa respuesta:</p>
    <p>Además de realizar peticiones HTTP y HTTPS, los módulos "http" y "https" también permiten escribir servidores que respondan a esas peticiones. El planteamiento básico es el siguiente:</p>
    <ul>
      <li class="font-normal">Crea un nuevo objeto Servidor.</li>
      <li class="font-normal">Llama a su método listen() para comenzar a escuchar peticiones en un puerto especificado.</li>
      <li class="font-normal">Registra un manejador de eventos para eventos "request", usa ese manejador para leer la petición del cliente (particularmente la propiedad request.url), y escribe tu respuesta.</li>
    </ul>
    <p>El código que sigue crea un servidor HTTP simple que sirve archivos estáticos desde el sistema de archivos local y también implementa un punto final de depuración que responde a la solicitud de un cliente haciendo eco de esa solicitud.</p>
    <p>Los módulos integrados de Node son todo lo que necesitas para escribir servidores HTTP y HTTPS sencillos. Ten en cuenta, sin embargo, que los servidores de producción no suelen construirse directamente sobre estos módulos. En su lugar, la mayoría de los servidores no triviales se implementan utilizando librerías externas - como el framework Express- que proporcionan "middleware" y otras utilidades de alto nivel que los desarrolladores web esperan.</p>
  </section>
  <section id="9">
    <h2>16.9 Servidores y clientes de red no HTTP </h2>
    <p>Los servidores y clientes web se han vuelto tan omnipresentes que es fácil olvidar que es posible escribir clientes y servidores que no utilicen HTTP. Aunque Node tiene la reputación de ser un buen entorno para escribir servidores web, Node también tiene soporte completo para escribir otros tipos de servidores y clientes de red.</p>
    <p>Si te sientes cómodo trabajando con flujos, entonces la conexión en red es relativamente sencilla, porque los sockets de red son simplemente una clase de flujo dúplex. El módulo "net" define las clases Server y Socket. Para crear un servidor, llame a net.createServer(), luego llame al método listen() del objeto resultante para decirle al servidor en qué puerto debe escuchar las conexiones. El objeto Servidor generará eventos de "conexión" cuando un cliente se conecte en ese puerto, y el valor pasado al escuchador de eventos será un objeto Socket. El objeto Socket es un stream Duplex, y puedes usarlo para leer datos del cliente y escribir datos al cliente. Llame a end() en el Socket para desconectarse.</p>
    <p>Escribir un cliente es aún más fácil: pasa un número de puerto y nombre de host a net.createCon nection() para crear un socket para comunicarse con cualquier servidor que se esté ejecutando en ese host y escuchando en ese puerto. A continuación, utilice ese socket para leer y escribir datos desde y hacia el servidor.</p>
    <p>El siguiente código demuestra cómo escribir un servidor con el módulo "net". Cuando el cliente se conecta, el servidor cuenta un chiste de toc-toc:</p>
    <p>Los servidores sencillos basados en texto como éste no suelen necesitar un cliente personalizado. Si la utilidad nc ("netcat") está instalada en su sistema, puede utilizarla para comunicarse con este servidor de la siguiente manera:</p>
    <p>Por otro lado, escribir un cliente personalizado para el servidor de bromas es fácil en Node. Simplemente nos conectamos al servidor, luego canalizamos la salida del servidor a stdout y canalizamos stdin a la entrada del servidor:</p>
    <p>Además de soportar servidores basados en TCP, el módulo "net" de Node también soporta la comunicación entre procesos a través de "sockets de dominio Unix" que se identifican por una ruta del sistema de ficheros en lugar de por un número de puerto. No vamos a cubrir ese tipo de socket en este capítulo, pero la documentación de Node tiene más detalles. Otras características de Node que no tenemos espacio para cubrir aquí incluyen el módulo "dgram" para clientes y servidores basados en UDP y el módulo "tls" que es a "net" como "https" es a "http". Las clases "tls.Server" y "tls.TLSSocket" permiten la creación de servidores TCP (como el servidor de chistes "knock-knock") que utilizan conexiones cifradas SSL como lo hacen los servidores HTTPS.</p>
  </section>
  <section id="10" class="py-4 xs:py-5 sm:py-6">
    <h2>16.10 Trabajar con procesos infantiles</h2>
    <p>Además de escribir servidores altamente concurrentes, Node también funciona bien para escribir scripts que ejecutan otros programas. En Node, el módulo "child_process" define una serie de funciones para ejecutar otros programas como procesos hijo. Esta sección muestra algunas de esas funciones, empezando por las más sencillas y siguiendo por las más complicadas.</p>
  </section>
  <section id="10-1">
    <h2>16.10.1 execSync() y execFileSync()</h2>
    <p>La forma más sencilla de ejecutar otro programa es con child_process.execSync(). Esta función toma el comando a ejecutar como primer argumento. Crea un proceso hijo, ejecuta una shell en ese proceso, y utiliza la shell para ejecutar el comando que le pasaste. Luego se bloquea hasta que el comando (y el shell) salen. Si el comando sale con un error, execSync() lanza una excepción. De lo contrario, execSync() devuelve la salida que el comando escriba en su flujo stdout. Por defecto, este valor de retorno es un buffer, pero puede especificar una codificación en un segundo argumento opcional para obtener una cadena en su lugar. Si el comando escribe cualquier salida a stderr, esa salida simplemente se pasa al flujo stderr del proceso padre.</p>
    <p>Así, por ejemplo, si está escribiendo un script y el rendimiento no es una preocupación, puede utilizar child_process.execSync() para listar un directorio con un comando de shell Unix familiar en lugar de utilizar la función fs.readdirSync():</p>
    <p>El hecho de que execSync() invoque un shell Unix completo significa que la cadena que se le pasa puede incluir múltiples órdenes separadas por punto y coma, y puede aprovechar características del shell como comodines de nombre de archivo, tuberías y redirección de salida. Esto también significa que debe tener cuidado de no pasar nunca un comando a execSync() si alguna parte de ese comando es una entrada de usuario o proviene de una fuente similar no fiable. La compleja sintaxis de los comandos shell puede ser fácilmente subvertida para permitir a un atacante ejecutar código arbitrario.</p>
    <p>Si no necesita las características de un intérprete de órdenes, puede evitar la sobrecarga de iniciar un intérprete de órdenes utilizando child_process.execFileSync(). Esta función ejecuta un programa directamente, sin invocar una shell. Pero como no hay ningún intérprete de órdenes involucrado, no puede analizar una línea de órdenes, y debe pasar el ejecutable como primer argumento y una matriz de argumentos de línea de órdenes como segundo argumento:</p>
    <article>
      <p class="title-article">Opciones del proceso infantil</p>
      <p>execSync() y muchas otras funciones child_process tienen un segundo o tercer argumento opcional que especifica detalles adicionales sobre cómo se ejecutará el proceso hijo. La propiedad encoding de este objeto se utilizó anteriormente para especificar que deseamos que la salida del comando se entregue como una cadena en lugar de como un buffer. Otras propiedades importantes que puede especificar incluyen las siguientes (tenga en cuenta que no todas las opciones están disponibles para todas las funciones de proceso hijo):</p>
      <ul>
        <li class="font-normal">cwd especifica el directorio de trabajo para el proceso hijo. Si se omite, el proceso hijo hereda el valor de process.cwd().</li>
        <li class="font-normal">env especifica las variables de entorno a las que tendrá acceso el proceso hijo. Por defecto, los procesos hijos simplemente heredan process.env, pero puede especificar un objeto diferente si lo desea.</li>
        <li class="font-normal">input especifica una cadena o búfer de datos de entrada que debe utilizarse como entrada estándar del proceso hijo. Esta opción sólo está disponible para las funciones síncronas que no devuelven un objeto ChildProcess.</li>
        <li class="font-normal">maxBuffer especifica el número máximo de bytes de salida que serán recogidos por las funciones exec. (No se aplica a spawn() y fork(), que utilizan flujos). Si un proceso hijo produce más salida que esto, será matado y saldrá con un error.</li>
        <li class="font-normal">shell especifica la ruta a un ejecutable de shell o true. Para funciones de proceso hijo que normalmente ejecutan un comando shell, esta opción permite especificar qué shell utilizar. Para las funciones que normalmente no utilizan un intérprete de órdenes, esta opción permite especificar que se debe utilizar un intérprete de órdenes (estableciendo la propiedad en true) o especificar exactamente qué intérprete de órdenes se debe utilizar.</li>
        <li class="font-normal">timeout especifica el número máximo de milisegundos que se debe permitir ejecutar al proceso hijo. Si no ha salido antes de que transcurra este tiempo, será matado y saldrá con un error. (Esta opción se aplica a las funciones exec pero no a spawn() o fork().)</li>
        <li class="font-normal">uid especifica el ID de usuario (un número) bajo el cual debe ejecutarse el programa. Si el proceso padre se está ejecutando en una cuenta con privilegios, puede utilizar esta opción para ejecutar el proceso hijo con privilegios reducidos.</li>
      </ul>
    </article>

  </section>
  <section id="10-2" class="py-4 xs:py-5 sm:py-6">
    <h2>16.10.2 exec() y execFile()</h2>
    <p>Las funciones execSync() y execFileSync() son, como sus nombres indican, sincrónicas: se bloquean y no vuelven hasta que el proceso hijo sale. Utilizar estas funciones es muy parecido a escribir comandos Unix en una ventana de terminal: permiten ejecutar una secuencia de comandos de uno en uno. Pero si estás escribiendo un programa que necesita realizar una serie de tareas, y esas tareas no dependen unas de otras de ninguna manera, entonces es posible que desees paralelizarlas y ejecutar varios comandos al mismo tiempo. Puede hacerlo con las funciones asíncronas child_process.exec() y child_process.execFile().</p>
    <p>exec() y execFile() son como sus variantes síncronas, excepto que devuelven inmediatamente un objeto ChildProcess que representa el proceso hijo en ejecución, y toman una llamada de retorno de error como argumento final. La llamada de retorno se invoca cuando el proceso hijo sale, y en realidad se llama con tres argumentos. El primero es el error, si lo hay; será nulo si el proceso termina normalmente. El segundo argumento es la salida recolectada que fue enviada al flujo de salida estándar del proceso hijo. Y el tercer argumento es cualquier salida que haya sido enviada al flujo de error estándar del hijo.</p>
    <p>El objeto ChildProcess devuelto por exec() y execFile() le permite terminar el proceso hijo, y escribirle datos (que luego puede leer de su entrada estándar). Cubriremos ChildProcess con más detalle cuando hablemos de la función child_pro cess.spawn().</p>
    <p>Si planea ejecutar múltiples procesos hijo al mismo tiempo, entonces puede ser más fácil usar la versión "prometida" de exec() que devuelve un objeto Promise que, si el proceso hijo sale sin error, resuelve a un objeto con propiedades stdout y stderr. Aquí, por ejemplo, hay una función que toma un array de comandos shell como entrada y devuelve un Promise que resuelve el resultado de todos esos comandos:</p>
  </section>
  <section id="10-3">
    <h2>16.10.3 spawn()</h2>
    <p>Las diversas funciones exec descritas hasta ahora -tanto síncronas como asíncronas- están diseñadas para ser utilizadas con procesos hijo que se ejecutan rápidamente y no producen mucha salida. Incluso las funciones asíncronas exec() y execFile() no son de flujo continuo: devuelven la salida del proceso en un único lote, sólo después de que el proceso haya salido.</p>
    <p>La función child_process.spawn() le permite acceder a la salida del proceso hijo, mientras el proceso sigue en ejecución. También le permite escribir datos en el proceso hijo (que verá esos datos como entrada en su flujo de entrada estándar): esto significa que es posible interactuar dinámicamente con un proceso hijo, enviándole entrada basada en la salida que genera.</p>
    <p>spawn() no utiliza un intérprete de comandos por defecto, por lo que debe invocarlo como execFile() con el ejecutable a ejecutar y una matriz separada de argumentos de línea de comandos para pasarle. spawn() devuelve un objeto ChildProcess como hace execFile(), pero no toma un argumento de devolución de llamada. En lugar de utilizar una función de llamada de retorno, se escucha a los eventos en el objeto ChildProcess y en sus flujos.</p>
    <p>El objeto ChildProcess devuelto por spawn() es un emisor de eventos. Usted puede escuchar el evento "exit" para ser notificado cuando el proceso hijo sale. Un objeto ChildProcess también tiene tres propiedades de flujo. stdout y stderr son flujos legibles: cuando el proceso hijo escribe en sus flujos stdout y stderr, esa salida se vuelve legible a través de los flujos ChildProcess. Nótese la inversión de los nombres aquí. En el proceso hijo, "stdout" es un flujo de salida Writable, pero en el proceso padre, la propiedad stdout de un objeto ChildProcess es un flujo de entrada Readable.</p>
    <p>De forma similar, la propiedad stdin del objeto ChildProcess es un flujo Writeable: cualquier cosa que escriba en este flujo estará disponible para el proceso hijo en su entrada estándar.</p>
    <p>El objeto ChildProcess también define una propiedad pid que especifica el id del proceso hijo. Y define un método kill() que puedes usar para terminar un proceso hijo.</p>
  </section>
  <section id="10-4" class="py-4 xs:py-5 sm:py-6">
    <h2>16.10.4 bifurcarse()</h2>
    <p>child_process.fork() es una función especializada para ejecutar un módulo de código JavaScript en un proceso Node hijo. fork() espera los mismos argumentos que spawn(), pero el primer argumento debe especificar la ruta a un archivo de código JavaScript en lugar de un archivo binario ejecutable.</p>
    <p>Un proceso hijo creado con fork() puede comunicarse con el proceso padre a través de sus flujos de entrada y salida estándar, como se describe en la sección anterior para spawn(). Pero además, fork() permite otro canal de comunicación mucho más sencillo entre los procesos padre e hijo.</p>
    <p>Cuando creas un proceso hijo con fork(), puedes usar el método send() del objeto ChildProcess devuelto para enviar una copia de un objeto al proceso hijo. Y puedes escuchar el evento "message" en el ChildProcess para recibir mensajes de el hijo. El código que se ejecuta en el proceso hijo puede utilizar process.send() para enviar un mensaje al padre y puede escuchar los eventos "message" en process para recibir mensajes del padre.</p>
    <p>Aquí, por ejemplo, hay algo de código que usa fork() para crear un proceso hijo, luego envía a ese hijo un mensaje y espera una respuesta:</p>
    <p>Y aquí está el código que se ejecuta en el proceso hijo:</p>
    <p>Iniciar procesos hijo es una operación costosa, y el proceso hijo tendría que estar haciendo órdenes de magnitud más computacionales antes de que tuviera sentido usar fork() y la comunicación entre procesos de esta manera. Si está escribiendo un programa que necesita ser muy sensible a los eventos entrantes y también necesita realizar cálculos que consumen mucho tiempo, entonces podría considerar el uso de un proceso hijo separado para realizar los cálculos de manera que no bloqueen el bucle de eventos y reduzcan la capacidad de respuesta del proceso padre. (Aunque un hilo -ver §16.11- puede ser una mejor opción que un proceso hijo en este escenario).</p>
    <p>El primer argumento de send() será serializado con JSON.stringify() y deserializado en el proceso hijo con JSON.parse(), por lo que sólo debe incluir valores que sean soportados por el formato JSON. send() tiene un segundo argumento especial, sin embargo, que le permite transferir objetos Socket y Server (del módulo "net") a un proceso hijo. Los servidores de red tienden a estar ligados a la E/S más que a la computación, pero si ha escrito un servidor que necesita hacer más computación de la que una sola CPU puede manejar, y si está ejecutando ese servidor en una máquina con múltiples CPUs, entonces podría usar fork() para crear múltiples procesos hijo para manejar las peticiones. En el proceso par- ticular, podría escuchar eventos de "conexión" en su objeto Servidor, luego obtener el objeto Socket de ese evento de "conexión" y enviarlo() -usando el argumento especial sec- ond- a uno de los procesos hijos para ser manejado. (Tenga en cuenta que esta es una solución poco probable para un escenario poco común. En lugar de escribir un servidor que bifurque procesos hijo, probablemente sea más sencillo mantener tu servidor con un único hilo y desplegar múltiples instancias del mismo en producción para manejar la carga).</p>
  </section>
  <section id="11">
    <h2>16.11 Hilos de trabajo</h2>
    <p>Como se explicó al principio de este capítulo, el modelo de concurrencia de Node es monohilo y basado en eventos. Pero en la versión 10 y posteriores, Node permite una verdadera programación multihilo , con una API que se asemeja mucho a la API Web Workers definida por los navegadores web (§15.13). La programación multihilo tiene una merecida reputación de ser difícil. Esto se debe casi exclusivamente a la necesidad de sincronizar cuidadosamente el acceso de los hilos a la memoria compartida. Pero los hilos de JavaScript (tanto en Node como en los navegadores) no comparten memoria por defecto, así que los peligros y dificultades de usar hilos no se aplican a estos "trabajadores" en JavaScript.</p>
    <p>En lugar de utilizar memoria compartida, los subprocesos de trabajo de JavaScript se comunican mediante el paso de mensajes. El subproceso principal puede enviar un mensaje a un subproceso trabajador llamando al método postMessage() del objeto Worker que representa a ese subproceso. El subproceso trabajador puede recibir mensajes de su padre escuchando eventos "mensaje". Y los workers pueden enviar mensajes al hilo principal con su propia versión de postMes sage(), que el padre puede recibir con su propio manejador de eventos "message". El código de ejemplo de dejará claro cómo funciona esto.</p>
    <p>Hay tres razones por las que podrías querer utilizar hilos de trabajo en una aplicación Node:</p>
    <ul>
      <li class="font-normal">Si tu aplicación realmente necesita hacer más cálculos de los que un núcleo de CPU puede manejar, entonces los hilos te permiten distribuir el trabajo a través de los múltiples núcleos, que se han convertido en algo común en los ordenadores de hoy en día. Si estás haciendo computación científica o aprendizaje automático o procesamiento de gráficos en Node, entonces es posible que desees utilizar hilos simplemente para lanzar más potencia de cálculo a tu problema.</li>
      <li class="font-normal">Incluso si su aplicación no está utilizando toda la potencia de una CPU, es posible que desee utilizar hilos para mantener la capacidad de respuesta del hilo principal. Pensemos en un servidor que gestiona peticiones grandes pero relativamente infrecuentes. Supongamos que sólo recibe una petición por segundo, pero necesita emplear alrededor de medio segundo de cálculo (limitado a la CPU de bloqueo) para procesar cada petición. Por término medio, estará inactivo el 50% del tiempo. Pero cuando llegan dos peticiones con pocos milisegundos de diferencia, el servidor ni siquiera podrá empezar a responder a la segunda petición hasta que termine el cálculo de la primera respuesta. En cambio, si el servidor utiliza un subproceso de trabajo para realizar el cálculo, el servidor puede empezar a responder a ambas peticiones inmediatamente y proporcionar una mejor experiencia a los clientes del servidor. Suponiendo que el servidor tenga más de un núcleo de CPU, también puede calcular el cuerpo de ambas respuestas en paralelo, pero incluso si sólo hay un único núcleo, el uso de trabajadores mejora la capacidad de respuesta.</li>
      <li class="font-normal">En general, los workers nos permiten convertir operaciones síncronas bloqueantes en operaciones asíncronas no bloqueantes. Si estás escribiendo un programa que depende de código heredado que es inevitablemente síncrono, puedes utilizar workers para evitar el bloqueo cuando necesites llamar a ese código heredado.</li>
    </ul>
    <p>Los hilos de trabajo no son tan pesados como los procesos hijo, pero no son ligeros. Por lo general, no tiene sentido crear un trabajador a menos que tenga que realizar un trabajo significativo. Y, en términos generales, si su programa no está limitado por la CPU y no tiene problemas de respuesta, entonces probablemente no necesite hilos trabajadores.</p>
  </section>
  <section id="11-1" class="py-4 xs:py-5 sm:py-6">
    <h2>16.11.1 Creación de trabajadores y transmisión de mensajes</h2>
    <p>El módulo de Node que define los workers se conoce como "worker_threads". En esta sección nos referiremos a él con el identificador threads:</p>
    <p>Este módulo define una clase Worker para representar un hilo trabajador, y puedes crear un nuevo hilo con el constructor threads.Worker(). El siguiente código demuestra el uso de este constructor para crear un trabajador, y muestra cómo pasar mensajes del hilo principal al trabajador y del trabajador al hilo principal. También demuestra un truco que le permite poner el código del hilo principal y el código del hilo trabajador en el mismo archivo.2</p>
    <p>El primer argumento del constructor Worker() es la ruta a un archivo de código JavaScript que se ejecutará en el hilo. En el código anterior, hemos utilizado el identificador de nombre de archivo predefinido para crear un trabajador que carga y ejecuta el mismo archivo que el hilo principal. En general, sin embargo, se pasa una ruta de archivo. Tenga en cuenta que si especifica una ruta relativa, es relativa a process.cwd(), no relativa al módulo actualmente en ejecución. Si desea una ruta relativa al módulo actual, utilice algo como path.resolve( dirname, 'workers/reticulator.js').</p>
    <p>El constructor Worker() también puede aceptar un objeto como segundo argumento, y las propiedades de este objeto proporcionan una configuración opcional para el trabajador. Cubriremos algunas de estas opciones más adelante, pero por ahora ten en cuenta que si pasas &lbrace;eval: true} como segundo argumento, entonces el primer argumento de Worker() se interpreta como una cadena de código JavaScript a evaluar en lugar de un nombre de archivo:</p>
    <p>Node hace una copia del objeto pasado a postMessage() en lugar de compartirlo directamente con el hilo trabajador. Esto evita que la hebra del trabajador y la hebra principal compartan memoria. Se podría esperar que esta copia se hiciera con JSON.stringify() y JSON.parse() (§11.6). Pero de hecho, Node toma prestada una técnica más robusta conocida como el algoritmo de clonado estructurado de los navegadores web.</p>
    <p>El algoritmo de clonado estructurado permite la serialización de la mayoría de los tipos de JavaScript, incluyendo objetos Map, Set, Date y RegExp y arrays tipados, pero no puede, en general, copiar tipos definidos por el entorno anfitrión Node, como sockets y streams. Nótese, sin embargo, que los objetos Buffer están parcialmente soportados: si pasas un Buffer a postMes sage() será recibido como un Uint8Array, y puede ser convertido de nuevo en un Buffer con Buffer.from(). Más información sobre el algoritmo de clonación estructurada en "El algoritmo de clonación estructurada" en la página 513.</p>
  </section>
  <section id="11-2">
    <h2>16.11.2 Entorno de ejecución del trabajador</h2>
    <p>En su mayor parte, el código JavaScript en un subproceso de Node worker se ejecuta igual que en el subproceso principal de Node. Hay algunas diferencias que debes tener en cuenta, y algunas de estas diferencias implican propiedades del segundo argumento opcional del constructor Worker():</p>
    <ul>
      <li class="font-normal">Como hemos visto, threads.isMainThread es verdadero en el hilo principal pero siempre es false en cualquier hilo trabajador.</li>
      <li class="font-normal">En un subproceso trabajador, puedes utilizar threads.parentPort.postMessage() para enviar un mensaje al subproceso padre e threads.parentPort.on para registrar manejadores de eventos para mensajes del subproceso padre. En el hilo principal, threads.parentPort es siempre null.</li>
      <li class="font-normal">En un subproceso trabajador, threads.workerData se establece como una copia de la propiedad workerData del segundo argumento del constructor Worker(). En el hilo principal, esta propiedad es siempre nula. Puedes utilizar esta propiedad workerData para pasar una propiedad mensaje al trabajador que estará disponible tan pronto como se inicie para que el trabajador no tenga que esperar a un evento "mensaje" antes de que pueda empezar a hacer el trabajo.</li>
      <li class="font-normal">Por defecto, process.env en un subproceso trabajador es una copia de process.env en el subproceso padre. Pero el subproceso padre puede especificar un conjunto personalizado de variables de entorno estableciendo la propiedad env del segundo argumento del constructor Worker(). Como caso especial (y potencialmente peligroso), el subproceso padre puede establecer la propiedad env a threads.SHARE_ENV, lo que hará que los dos subprocesos compartan un único conjunto de variables de entorno de modo que un cambio en un subproceso sea visible en el otro.</li>
      <li class="font-normal">Por defecto, process.env en un subproceso trabajador es una copia de process.env en el subproceso padre. Pero el subproceso padre puede especificar un conjunto personalizado de variables de entorno estableciendo la propiedad env del segundo argumento del constructor Worker(). Como caso especial (y potencialmente peligroso), el subproceso padre puede establecer la propiedad env a threads.SHARE_ENV, lo que hará que los dos subprocesos compartan un único conjunto de variables de entorno de modo que un cambio en un subproceso sea visible en el otro.</li>
      <li class="font-normal">Por defecto, el flujo process.stdin de un trabajador nunca contiene datos legibles. Puedes cambiar este valor por defecto pasando stdin: true en el segundo argumento del constructor Worker(). Si lo haces, la propiedad stdin del objeto Worker será un flujo Writable. Cualquier dato que el padre escriba en worker.stdin se convierte en legible en process.stdin en el trabajador.</li>
      <li class="font-normal">Por defecto, los flujos process.stdout y process.stderr en el trabajador simplemente se canalizan a los flujos correspondientes en el hilo principal. Esto significa, por ejemplo, que console.log() y console.error() producen la salida exactamente de la misma manera en un hilo worker que en el hilo principal. Puede anular este valor por defecto pasando stdout:true o stderr:true en el segundo argumento del constructor Worker(). Si haces esto, entonces cualquier salida que el trabajador escriba en esos flujos será legible por el hilo padre en los hilos worker.stdout y worker.stderr. (Hay una inversión potencialmente confusa de las direcciones de los flujos aquí, y vimos lo mismo con los procesos hijo anteriormente en el capítulo: los flujos de salida de un hilo worker son flujos de entrada para el hilo par- ticular, y el flujo de entrada de un worker es un flujo de salida para el padre).</li>
      <li class="font-normal">Si un hilo trabajador llama a process.exit(), sólo sale el hilo, no todo el proceso.</li>
      <li class="font-normal">Los hilos de trabajo no pueden cambiar el estado compartido del proceso del que forman parte. Funciones como process.chdir() y process.setuid() lanzarán excepciones cuando sean invocadas desde un trabajador.</li>
      <li class="font-normal">Las señales del sistema operativo (como SIGINT y SIGTERM) sólo se envían al hilo principal; no pueden recibirse ni manejarse en los hilos trabajadores.</li>
    </ul>
  </section>
  <section id="11-3" class="py-4 xs:py-5 sm:py-6">
    <h2>16.11.3 Canales de comunicación y MessagePorts</h2>
    <p>Cuando se crea un nuevo hilo worker, se crea junto con él un canal de comunicación que permite pasar mensajes de ida y vuelta entre el worker y el hilo particular. Como hemos visto, el hilo worker utiliza threads.parentPort para enviar y recibir mensajes hacia y desde el subproceso padre, y el subproceso padre utiliza el objeto Worker para enviar y recibir mensajes hacia y desde el subproceso trabajador.</p>
    <p>La API de hilos de trabajo también permite la creación de canales de comunicación personalizados utilizando la API MessageChannel definida por los navegadores web y tratada en §15.13.5. Si has leído esa sección, mucho de lo que sigue te sonará familiar.</p>
    <p>Supongamos que un worker necesita manejar dos tipos diferentes de mensajes enviados por dos módulos diferentes en el hilo principal. Estos dos módulos diferentes podrían compartir el canal por defecto y enviar mensajes con worker.postMessage(), pero sería más limpio si cada módulo tiene su propio canal privado para enviar mensajes al trabajador. O consideremos el caso en el que el hilo principal crea dos trabajadores independientes. Un canal de comunicación personalizado puede permitir a los dos trabajadores comunicarse directamente entre sí en lugar de tener que enviar todos sus mensajes a través del hilo principal.</p>
    <p>Crea un nuevo canal de mensajes con el constructor MessageChannel(). Un objeto MessageChannel tiene dos propiedades, llamadas port1 y port2. Estas propiedades se refieren a un par de objetos MessagePort. Llamar a postMessage() en uno de los puertos hará que se genere un evento "mensaje" en el otro con un clon estructurado del objeto Message:</p>
    <p>También puede llamar a close() en cualquiera de los puertos para romper la conexión entre los dos puertos y señalar que no se intercambiarán más mensajes. Cuando se llama a close() en cualquiera de los puertos, se envía un evento "close" a ambos puertos.</p>
    <p>Observe que el ejemplo de código anterior crea un par de objetos MessagePort y luego utiliza esos objetos para transmitir un mensaje dentro del hilo principal. Para utilizar canales de comunicación personalizados con trabajadores, debemos transferir uno de los dos puertos desde el subproceso en el que se crea al subproceso en el que se utilizará. En la siguiente sección se explica cómo hacerlo.</p>
  </section>
  <section id="11-4">
    <h2>16.11.4 Transferencia de MessagePorts y matrices tipificadas</h2>
    <p>La función postMessage() utiliza el algoritmo de clonado estructurado, y como hemos señalado, no puede copiar objetos como SSockets y Streams. Puede manejar objetos MessagePort, pero sólo como un caso especial usando una técnica especial. El método postMessage() (de un objeto Worker, de threads.parentPort, o de cualquier objeto MessagePort) toma un segundo argumento opcional. Este argumento (llamado transferList) es un array de objetos que van a ser transferidos entre hilos en lugar de ser copiados.</p>
    <p>Un objeto MessagePort no puede ser copiado por el algoritmo de clonado estructurado, pero puede ser transferido. Si el primer argumento de postMessage() ha incluido uno o más objetos MessagePorts (anidados a una profundidad arbitraria dentro del objeto Message), entonces esos objetos Mes- sagePort también deben aparecer como miembros del array pasado como segundo argumento. Hacer esto le dice a Node que no necesita hacer una copia del MessagePort, y en su lugar puede dar el objeto existente al otro hilo. La clave para entender, sin embargo, sobre la transferencia de valores entre hilos es que una vez que un valor es transferido, ya no puede ser utilizado en el hilo que llamó a postMessage().</p>
    <p>Así es como se puede crear un nuevo MessageChannel y transferir uno de sus Message- Ports a un worker:</p>
    <p>Los objetos MessagePort no son los únicos que se pueden transferir. Si llamas a postMes sage() con un array tipado como mensaje (o con un mensaje que contiene uno o más arrays tipados anidados arbitrariamente dentro del mensaje), ese array tipado (o esos arrays tipados) simplemente serán copiados por el algoritmo de clonado estructurado. Pero las matrices tipadas pueden ser grandes; por ejemplo, si se está utilizando un hilo de trabajo para realizar el procesamiento de imágenes en millones de píxeles. Así que por eficiencia, postMessage() también nos da la opción de transferir matrices tipadas en lugar de copiarlas. (Los hilos comparten memoria por defecto. Los hilos de trabajo en JavaScript generalmente evitan la memoria compartida, pero cuando permitimos este tipo de transferencia controlada, se puede hacer de manera muy eficiente). Lo que hace que esto sea seguro es que cuando un array tipado se transfiere a otro hilo, se vuelve inutilizable en el hilo que lo transfirió. En el caso del procesamiento de imágenes, el subproceso principal podría transferir los píxeles de una imagen al subproceso trabajador, y luego el subproceso trabajador podría transferir los píxeles procesados de nuevo al subproceso principal cuando haya terminado. La memoria no necesitaría ser copiada, pero nunca sería accesible por dos hilos a la vez.</p>
    <p>Para transferir un array tipado en lugar de copiarlo, incluya el ArrayBuffer que respalda el array en el segundo argumento de postMessage():</p>
    <p>Al igual que con los MessagePorts transferidos, un array tipado transferido se vuelve inutilizable una vez transferido. No se lanzan excepciones si se intenta utilizar un MessagePort o un array tipado que ha sido transferido; estos objetos simplemente dejan de hacer algo cuando se interactúa con ellos.</p>
  </section>
  <section id="11-5" class="py-4 xs:py-5 sm:py-6">
    <h2>16.11.5 Compartir matrices tipadas entre subprocesos</h2>
    <p>Además de transferir arrays tipados entre threads, es posible compartir un array tipado entre threads. Simplemente crea un SharedArrayBuffer del tamaño deseado y luego usa ese buffer para crear un array tipado. Cuando un array tipado que está respaldado por un SharedArrayBuffer se pasa a través de postMessage(), la memoria subyacente será compartida entre los hilos. En este caso, no se debe incluir el buffer compartido en el segundo argumento de postMessage().</p>
    <p>Sin embargo, no deberías hacer esto, porque JavaScript nunca fue diseñado pensando en la seguridad de los hilos y la programación multihilo es muy difícil de hacer bien. (Y esta es la razón por la que SharedArrayBuffer no fue cubierto en §11.2: es una característica de nicho que es difícil de hacer bien). Incluso el simple operador ++ no es seguro para los hilos porque necesita leer un valor, incrementarlo y escribirlo de vuelta. Si dos hilos están incrementando un valor al mismo tiempo, a menudo sólo se incrementará una vez, como demuestra el siguiente código:</p>
    <p>Un escenario en el que podría ser razonable utilizar un SharedArrayBuffer es cuando los dos hilos operan en secciones completamente separadas de la memoria compartida. Se puede hacer esto creando dos matrices tipadas que sirvan como vistas de regiones no superpuestas del buffer compartido, y luego hacer que los dos subprocesos utilicen esas dos matrices tipadas separadas. Una ordenación merge paralela podría hacerse así: un subproceso ordena la mitad inferior de un array y el otro subproceso ordena la mitad superior, por ejemplo. O algunos tipos de algoritmos de procesamiento de imágenes también son adecuados para este enfoque: múltiples hilos trabajando en regiones separadas de la imagen.</p>
    <p>Si realmente debe permitir que varios subprocesos accedan a la misma región de una matriz compartida, puede dar un paso hacia la seguridad de los subprocesos con las funciones definidas por el objeto Atomics. Atomics se añadió a JavaScript con SharedArrayBuffer para definir operaciones atómicas sobre los elementos de una matriz compartida. Por ejemplo, la función Atomics.add() lee el elemento especificado de una matriz compartida, le añade un valor especificado y vuelve a escribir la suma en la matriz. Lo hace de forma atómica, como si se tratara de una sola operación, y se asegura de que ningún otro subproceso pueda leer o escribir el valor mientras se realiza la operación. Atomics.add() nos permite reescribir el código de incremento paralelo que acabamos de ver y obtener el resultado correcto de 20 millones de incrementos de un elemento de array compartido:</p>
    <p>Esta nueva versión del código imprime correctamente el número 20.000.000. Pero es unas nueve veces más lenta que el código incorrecto al que sustituye. Pero es unas nueve veces más lenta que el código incorrecto al que sustituye. Sería mucho más sencillo y mucho más rápido hacer los 20 millones de incrementos en un único subproceso. También hay que tener en cuenta que las operaciones atómicas pueden garantizar la seguridad de los subprocesos en algoritmos de procesamiento de imágenes para los que cada elemento de la matriz es un valor totalmente independiente de todos los demás valores. Pero en la mayoría de los programas del mundo real, múltiples elementos del array están a menudo relacionados entre sí y se requiere algún tipo de sincronización de hilos de alto nivel. Las funciones de bajo nivel Atomics.wait() y Atomics.notify() pueden ayudar con esto, pero una discusión de su uso está fuera del alcance de este libro.</p>
  </section>
  <section id="12" class="pb-4 xs:pb-5 sm:pb-6">
    <h2>16.12 Resume</h2>
    <p>Aunque JavaScript se creó para ejecutarse en navegadores web, Node lo ha convertido en un lenguaje de programación de uso general. Es especialmente popular para implementar servidores web, pero sus profundos vínculos con el sistema operativo lo convierten también en una buena alternativa a los shell scripts.</p>
    <p>Los temas más importantes tratados en este largo capítulo son:</p>
    <ul>
      <li class="font-normal">Las API asíncronas por defecto de Node y su estilo de concurrencia basado en un único hilo, callback y eventos.</li>
      <li class="font-normal">Tipos de datos, buffers y streams fundamentales de Node.</li>
      <li class="font-normal">Módulos "fs" y "path" de Node para trabajar con el sistema de archivos.</li>
      <li class="font-normal">Módulos "http" y "https" de Node para escribir clientes y servidores HTTP.</li>
      <li class="font-normal">Módulo "net" de Node para escribir clientes y servidores no HTTP.</li>
      <li class="font-normal">Módulo "child_process" de Node para crear procesos hijo y comunicarse con ellos.</li>
      <li class="font-normal">Módulo "worker_threads" de Node para una verdadera programación multihilo utilizando el paso de mensajes en lugar de la memoria compartida.</li>
    </ul>
  </section>
  </Layoutjavascript>