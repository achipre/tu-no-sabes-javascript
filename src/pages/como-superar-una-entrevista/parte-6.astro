---
import Layoutcracking from "../../layouts/Layoutcracking.astro"
---
<Layoutcracking title="Como superar una entrevista de codificación">
  <h1>Parte VI</h1>
  <h2>Big O</h2>
  <article>
    <p>
      Se trata de un concepto tan importante que le dedicamos un capítulo entero (log!).
    </p>
    <p>
      El tiempo Big O es el lenguaje y la métrica que utilizamos para describir la eficiencia de los algoritmos. No entenderlo bien puede perjudicarte a la hora de desarrollar un algoritmo. No sólo podrías ser juzgado duramente por no entender realmente el big 0, sino que también te costará juzgar cuándo tu algoritmo se está volviendo más rápido o más lento.
    </p>
    <p>
      Domina este concepto.
    </p>
  </article>
  <article>
    <h3>► Una analogía</h3>
    <p>
      Imagina el siguiente escenario: Tienes un archivo en un disco duro y necesitas enviárselo a tu amigo que vive al otro lado del país. Tienes que enviárselo lo antes posible. ¿Cómo se lo envías?
    </p>
    <p>
      Lo primero que piensa la mayoría de la gente es en el correo electrónico, el FTP o cualquier otro medio de transferencia electrónica. Es una idea razonable, pero correcta a medias.
    </p>
    <p>
      Si se trata de un archivo pequeño, sin duda tiene razón. Tardarías entre 5 y 10 horas en llegar a un aeropuerto, coger un vuelo y entregárselo a tu amigo.
    </p>
    <p>
      Pero, ¿y si el archivo fuera muy, muy grande? ¿Es posible que sea más rápido enviarlo físicamente en avión?
    </p>
    <p>
      Pues sí. Un archivo de un terabyte (1 TB) podría tardar más de un día en transferirse electrónicamente. Sería mucho más rápido cruzar el país en avión. Si su archivo es tan urgente (y el coste no es un problema), tal vez le convenga hacerlo así.
    </p>
    <p>
      ¿Y si no hubiera vuelos y tuvieras que atravesar el país en coche? Incluso en ese caso, para un archivo realmente enorme, sería más rápido conducir.
    </p>
  </article>
  <article>
    <h3>► Complejidad temporal</h3>
    <p>
      Esto es lo que significa el concepto de tiempo de ejecución asintótico, o tiempo big O. Podríamos describir el tiempo de ejecución del «algoritmo» de transferencia de datos como:
    </p>
    <ul>
      <li>Transferencia electrónica: <code>O(s)</code> , donde s es el tamaño del fichero. Esto significa que el tiempo para transferir el archivo aumenta linealmente con el tamaño del archivo. (Sí, esto es una simplificación, pero está bien para estos fines).</li>
      <li>Transferencia por avión: <code>O(1)</code>con respecto al tamaño del archivo. A medida que aumente el tamaño del archivo, no tardará más en llegarle a tu amigo. El tiempo es constante.</li>
    </ul>
    <div class="w-full flex justify-center">
      <div class="relative w-52 sm:w-64 md:w-80 h-44 sm:h-52 md:h-72 border-l-2 border-b-2 border-black">
        <div class="h-20 md:h-28 w-full absolute flex justify-center items-end top-0 border-black border-b-2 border-dashed">
          <p class="">O(1)</p>

        </div>
        <div class="h-20 sm:h-24 md:h-36 w-60 sm:w-72 md:w-96 -rotate-[30deg] absolute flex justify-center items-start bottom-0 border-black border-t-2 border-dotted">
          <p class="">O(s)</p>

        </div>
      </div>
    </div>
    <p>
      No importa lo grande que sea la constante y lo lento que sea el incremento lineal, en algún momento lo lineal superará a lo constante.
    </p>
    <p>
      Hay muchos más tiempos de ejecución que éste. Algunos de los más comunes son <code>O(log N)</code>, <code>O(N)</code>, <code>O(N<sup>2</sup>)</code> y <code>0(2<sup>N</sup>)</code>. Sin embargo, no hay una lista fija de posibles tiempos de ejecución.
    </p>
    <p>
      También puedes tener múltiples variables en tu tiempo de ejecución. Por ejemplo, el tiempo para pintar una valla de w metros de ancho y h metros de alto podría describirse como <code>O(wh)</code>. Si necesitas p capas de pintura, entonces podrías decir que el tiempo es <code>O(whp)</code>.
    </p>
  </article>
  <article>
    <p><strong>Big O, Big Theta y Big Omega</strong></p>
    <p>
      Si nunca has trabajado con la gran O en un entorno académico, probablemente puedas saltarte esta subsección. Puede confundirte más de lo que te ayuda. Este «FYI» es sobre todo aquí para aclarar la ambigüedad en la redacción para las personas que han aprendido gran O antes, para que no digan: "Pero pensé que gran O significaba ...:"
    </p>
    <p>
      Los académicos utilizan big 0, big &theta; (theta) y big Ω (omega) para describir los tiempos de ejecución.
    </p>
    <ul>
      <li><strong>O (big 0):</strong>
        En el mundo académico, big O describe un límite superior en el tiempo. Un algoritmo que imprime todos los valores de una matriz podría describirse como <code>O(N)</code>, pero también podría describirse como <code>O(N<sup>2</sup>)</code>, <code>O(N<sup>3</sup>)</code> o <code>0(2<sup>N</sup>)</code> (o muchos otros tiempos big O). El algoritmo es al menos tan rápido como cada uno de ellos, por lo que son límites superiores del tiempo de ejecución. Esto es similar a una relación menor-que-o-igual-a. Si Bob tiene X años (voy a suponer que nadie vive más de 130 años), entonces se podría decir <code class="language-js">X <= 130</code>. También sería correcto decir que <code class="language-js">X <= 1000</code> o <code class="language-js">X <= 1'000.000</code>. Es técnicamente cierto (aunque no terriblemente útil). Del mismo modo, un algoritmo sencillo para imprimir los valores de una matriz es <code>O(N)</code>, así como <code class="laguage-js">O(N<sup>3</sup>)</code> o cualquier tiempo de ejecución mayor que <code>O(N)</code>.
      </li>
      <li><strong>Ω (big omega):</strong>
        En el mundo académico, Ω es el concepto equivalente pero para el límite inferior. Imprimir los valores de una matriz es <code>Ω(N)</code>, así como <code>Ω(log N)</code> y <code>Ω(1)</code>. Después de todo, sabes que no será más rápido que esos tiempos de ejecución.
      </li>
      <li><strong>&theta; (big theta):</strong>
        En el mundo académico, &theta; significa tanto O como Ω. Es decir, un algoritmo es <code>&theta;(N)</code> si es tanto <code>O(N)</code> como <code>Ω(N)</code>. &theta; ofrece un límite estricto del tiempo de ejecución.
      </li>
    </ul>
    <p>
      En la industria (y, por tanto, en las entrevistas), la gente parece haber fusionado &theta; y O. El significado industrial de O grande se acerca más a lo que los académicos entienden por &theta;, en el sentido de que sería incorrecto describir la impresión de una matriz como <code>O(N<sup>2</sup>)</code>. La industria diría simplemente que es <code>O(N)</code>.
    </p>
    <p>
      Para este libro, utilizaremos big O de la forma en que la industria tiende a utilizarlo: Intentando siempre ofrecer la descripción más ajustada del tiempo de ejecución.
    </p>
  </article>
  <article>
    <p><strong>Mejor caso, peor caso y caso esperado</strong>
    </p>
    <p>
      En realidad, podemos describir el tiempo de ejecución de un algoritmo de tres formas distintas.
    </p>
    <p>
      Veámoslo desde la perspectiva de la ordenación rápida. La ordenación rápida elige un elemento aleatorio como «pivote» y luego intercambia valores en la matriz de forma que los elementos menores que el pivote aparecen antes que los elementos mayores que el pivote. Así se obtiene una «ordenación parcial». A continuación, ordena recursivamente los lados izquierdo y derecho mediante un proceso similar.
    </p>
    <ul>
      <li><strong>Mejor caso:</strong>
        Si todos los elementos son iguales, entonces la ordenación rápida, de media, sólo recorrerá el array una vez. Esto es <code>O(N)</code>. (En realidad, esto depende ligeramente de la implementación de la ordenación rápida. Hay implementaciones, sin embargo, que se ejecutarán muy rápidamente en un array ordenado).
      </li>
      <li><strong>El peor de los casos:</strong>
        ¿Qué pasa si tenemos muy mala suerte y el pivote es repetidamente el elemento más grande de la matriz? (En realidad, esto puede ocurrir fácilmente. Si el pivote se elige para que sea el primer elemento de la submatriz y la matriz se ordena en orden inverso, tendremos esta situación). En este caso, nuestra recursión no divide el array por la mitad y recursa en cada mitad. Sólo reduce la submatriz en un elemento. Esto degenerará en un tiempo de ejecución de <code>O(N<sup>2</sup>)</code>.
      </li>
      <li><strong>Caso esperado:</strong>
        Normalmente, sin embargo, estas situaciones maravillosas o terribles no ocurrirán. Claro, a veces el pivote será muy bajo o muy alto, pero no sucederá una y otra vez. Podemos esperar un tiempo de ejecución de <code>O(N log N)</code>.
      </li>
    </ul>
    <p>
      Rara vez hablamos de la complejidad temporal en el mejor de los casos, porque no es un concepto muy útil. Después de todo, podríamos tomar esencialmente cualquier algoritmo, caso especial de alguna entrada, y luego obtener un tiempo <code>O(1)</code> en el mejor de los casos.
    </p>
    <p>
      Para muchos -probablemente la mayoría- de los algoritmos, el peor caso y el caso esperado son el mismo. Sin embargo, a veces son diferentes y necesitamos describir ambos tiempos de ejecución.
    </p>
    <p><em>
      ¿Cuál es la relación entre el mejor/peor/caso esperado y el big O/theta/omega?</em>
    </p>
    <p>
      Es fácil que los candidatos confundan estos conceptos (probablemente porque ambos tienen algunos conceptos de «superior»: «inferior» y “exactamente correcto”), pero no hay ninguna relación particular entre los conceptos.
    </p>
    <p>
      Los casos mejor, peor y esperado describen el tiempo big O (o big theta) para entradas o escenarios particulares. 
    </p>
    <p>
      Big 0, big omega y big theta describen los límites superior, inferior y estrecho del tiempo de ejecución.
    </p>
  </article>
  <article>
    <h3>► Complejidad espacial</h3>
    <p>
      El tiempo no es lo único que importa en un algoritmo. También nos puede importar la cantidad de memoria o espacio que requiere un algoritmo.
    </p>
    <p>
      La complejidad espacial es un concepto paralelo a la complejidad temporal. Si necesitamos crear una matriz de tamaño n, necesitaremos <code>O(n)</code> de espacio. Si necesitamos una matriz bidimensional de tamaño nxn, necesitaremos <code>O(n<sup>2</sup>)</code> de espacio.
    </p>
    <p>
      El espacio de pila en las llamadas recursivas también cuenta. Por ejemplo, un código como éste requeriría <code>O(n)</code> de tiempo y <code>O(n)</code> de espacio.
    </p>
    <pre>
      <code class="language-js">
        int sum(int n) &#123/*Ex 1.*/
          if (n &#60= 0) &#123
            return 0;
          }
          return n + sum(n-1);
        }
      </code>
    </pre>
    <p>
      Cada llamada añade un nivel a la pila.
    </p>
    <pre>
      <code class="language-js">
        sum(4)
        -> sum(3)
          -> sum(2)
            -> sum(l)
              -> sum(0)
      </code>
    </pre>
    <p>
      Cada una de estas llamadas se añade a la pila de llamadas y ocupa memoria real.
    </p>
    <p>
      Sin embargo, que haya un total de n llamadas no significa que se necesite <code>O(n)</code> espacio. Considere la siguiente función, que añade elementos adyacentes entre O y n:
    </p>
    <pre>
      <code class="language-js">
        int pairSumSequence(int n) &#123/* Ex 2.*/
          int sum = 0;
          for (int i= 0; i &#60 n; i++) &#123
            sum += pairSum(i, i + 1);
          }
          return sum;
        }
        int pairSum(int a, int b) &#123
          return a + b;
        }
      </code>
    </pre>
    <p>
      Habrá aproximadamente <code>O(n)</code> llamadas a pairSum. Sin embargo, esas llamadas no existen simultáneamente en la pila de llamadas, por lo que sólo necesita <code>O(1)</code> espacio.
    </p>
  </article>
  <article>
    <h3>► Eliminar las constantes
    </h3>
    <p>
      Es muy posible que el código <code>O(N)</code> se ejecute más rápido que el código <code>0(1)</code> para entradas específicas. La O grande sólo describe la tasa de incremento.
    </p>
    <p>
      Por esta razón, eliminamos las constantes en tiempo de ejecución. Un algoritmo que uno podría haber descrito como <code>0(2N)</code> es en realidad <code>O(N)</code>.
    </p>
    <p>
      Mucha gente se resiste a hacer esto. Verán código que tiene dos bucles for (no anidados) y continuarán este <code>0(2N)</code>. Piensan que están siendo más «precisos:'No lo son.
    </p>
    <p>
      Considere el siguiente código:
    </p>
    <div class="flex gap-12">
      <div class="flex-grow">
        <p class="font-bold">Minimo y Maximo 1</p>
        <pre class="pb-12">
          <code class="language-js">
            int min = Integer.MAX_VALUE;
            int max = Integer.MIN_VALUE; 
            for (int x : array) &#123
            if (x &#60 min) min x; 
            if (x > max) max = x;
          }
          </code>
        </pre>
      </div>
      <div class="flex-grow">
        <p class="font-bold">Minimo y Maximo 2</p>
        <pre>
          <code class="language-js">
            int min = Integer.MAX_VALUE;
            int max = Integer.MIN_VALUE;
            for (int x : array) &#123
              if (x &#60 min) min = x;
            }
            for (int x : array) &#123
              if (x > max) max = x;
            }
          </code>
        </pre>
      </div>
    </div>
    <p>
      ¿Cuál es más rápido? El primero hace un bucle for y el otro hace dos bucles for. Pero entonces, la primera solución tiene dos líneas de código por bucle for en lugar de una.
    </p>
    <p>
      Si vas a contar el número de instrucciones, tendrías que ir al nivel de ensamblador y tener en cuenta que la multiplicación requiere más instrucciones que la suma, cómo optimizaría algo el compilador y todo tipo de detalles.
    </p>
    <p>
      Esto sería terriblemente complicado, así que ni se te ocurra empezar por ahí. Big O nos permite expresar cómo se escala el tiempo de ejecución. Sólo tenemos que aceptar que no significa que <code>O(N)</code> sea siempre mejor que <code>O(N<sup>2</sup>)</code>.
    </p>
  </article>
  <article>
    <h3>► Eliminar los términos no dominantes</h3>
    <p>
      ¿Qué hacer con un a expresión como <code>O(N<sup>2</sup> + N)</code>? La segunda N no es exactamente una constante. Pero no es especialmente importante.
    </p>
    <p>
      Ya dijimos que eliminamos constantes. Por lo tanto, <code>O(N<sup>2</sup> + N<sup>2</sup>)</code> sería <code>O(N<sup>2</sup>)</code>. Si no nos importa ese último término <code>N2</code>, ¿por qué nos importaría <code>N</code>? No nos importa.
    </p>
    <p>
      Deberías eliminar los términos no dominantes.
    </p>
    <ul>
      <li><code>O(N<sup>2</sup> + N)</code> se convierte en <code>O(N<sup>2</sup>)</code>.</li>
      <li><code>O(N + log N)</code> se convierte en <code>O(N)</code>.</li>
      <li><code>O(5*2<sup>N</sup> + 1000N<sup>100</sup>)</code> se convierte en <code>O(2<sup>N</sup>)</code>.</li>
    </ul>
    <p>
      Todavía podemos tener una suma en un tiempo de ejecución. Por ejemplo, la expresión <code>O(B<sup>2</sup> + A)</code> no se puede reducir (sin algún conocimiento especial de A y B).
    </p>
    <p>
      El siguiente gráfico representa la tasa de incremento para algunos de los tiempos grandes O comunes.
    </p>
    <div class="w-full flex justify-center">
      <div class="relative w-52 sm:w-64 md:w-80 h-44 sm:h-52 md:h-72 border-l-2 border-b-2 border-black">

        <div class="w-full absolute flex origin-bottom-left -rotate-6 justify-end items-end bottom-0 border-neutral-700 border-b-2">
          <p class="">O(log x)</p>
        </div>
        <div class="w-full absolute flex origin-bottom-left -rotate-45  justify-end items-end bottom-0 border-neutral-700 border-b-2">
          <p class="">O(x)</p>
        </div>
        <div class="w-full absolute flex origin-bottom-left -rotate-[55deg]  justify-end items-end bottom-0 border-neutral-700 border-b-2">
          <p class="leading-3">O(x log x)</p>
        </div>
        <div class="w-full absolute flex origin-bottom-left -rotate-[65deg]  justify-end items-end bottom-0 border-neutral-700 border-b-2">
          <p class="leading-3">O(x<sup>2</sup>)</p>
        </div>
        <div class="w-[95%] absolute flex origin-bottom-left -rotate-[75deg]  justify-end items-end bottom-0 border-neutral-700 border-b-2">
          <p class="leading-3">O(2<sup>x</sup>)</p>
        </div>
        <div class="w-[90%] absolute flex origin-bottom-left -rotate-[82deg]  justify-end items-end bottom-0 border-neutral-700 border-b-2">
          <p class="leading-3">O(x!)</p>
        </div>
      </div>
    </div>
    <p>
      Como puede ver, <code>O(x<sup>2</sup>)</code> es mucho peor que <code>O(x)</code>, pero no es tan malo como <code>O(2<sup>x</sup>)</code> u <code>O(x!)</code>. También hay muchos tiempos de ejecución peores que <code>O(x!)</code>, como <code>O(x<sup>x</sup>)</code> o <code>O(2<sup>x</sup> * x!)</code>.
    </p>
  </article>
  <article>
    <h3>► Algoritmos multiparte: Suma vs. multiplicación</h3>
    <p>
      Supongamos que tenemos un algoritmo que tiene dos pasos. ¿Cuándo se multiplican los tiempos de ejecución y cuándo se suman?
    </p>
    <p>
      Esta es una fuente común de confusión para los candidatos.
    </p>
    <div class="flex gap-12">
      <div class="flex-grow">
        <p class="font-bold">Suma en Tiempo de Ejecución: O(A + B)</p>
        <pre class="">
          <code class="language-js">
            for (int a : arrA) &#123 
              print(a);
            }
            for (int b : arrB) &#123
              print(b);
            }   
          </code>
        </pre>
      </div>
      <div class="flex-grow">
        <p class="font-bold">Multiplicación en Runtime: O(A * B)</p>
        <pre>
          <code class="language-js">
            for (int a : arrA) &#123
              for (int b : arrB) &#123
                print(a + "," + b);
              }
            }
          </code>
        </pre>
      </div>
    </div>
    <p>
      En el ejemplo de la izquierda, hacemos A trozos de trabajo y luego B trozos de trabajo. Por lo tanto, la cantidad total de trabajo es <code>O(A + B)</code>.
    </p>
    <p>
      En el ejemplo de la derecha, hacemos B trozos de trabajo por cada elemento de A. Por lo tanto, la cantidad total de trabajo es <code>O(A * B)</code>.
    </p>
    <p>
      Dicho de otro modo:
    </p>
    <ul>
      <li>Si tu algoritmo tiene la forma "haz esto, luego, cuando hayas terminado, haz aquello" entonces suma los tiempos de ejecución.</li>
      <li>Si tu algoritmo es del tipo "haz esto cada vez que hagas aquello", multiplica los tiempos de ejecución.</li>
    </ul>
    <p>
      Es muy fácil meter la pata en una entrevista, así que ten cuidado.
    </p>
  </article>
  <article>
    <h3>► Tiempo amortizado</h3>
    <p>
      Un <code>ArrayList</code>, o un array que cambia de tamaño dinámicamente, te permite tener los beneficios de un array a la vez que te ofrece flexibilidad en el tamaño. No te quedarás sin espacio en el <code>ArrayList</code> ya que su capacidad crecerá a medida que insertes elementos.
    </p>
    <p>
      Un Arraylist se implementa con un array. Cuando el array alcanza su capacidad, la clase <code>ArrayList</code> creará un nuevo array con el doble de capacidad y copiará todos los elementos al nuevo array.
    </p>
    <p>
      ¿Cómo se describe el tiempo de ejecución de la inserción? Es una pregunta delicada.
    </p>
    <p>
      El array puede estar lleno. Si la matriz contiene <code>N</code> elementos, insertar un nuevo elemento llevará <code>O(N)</code> tiempo. Tendrás que crear un nuevo array de tamaño <code>2N</code> y luego copiar <code>N</code> elementos. Esta inserción llevará <code>O(N)</code> tiempo.
    </p>
    <p>
      Sin embargo, también sabemos que esto no ocurre muy a menudo. La inmensa mayoría de las veces la inserción se hará en tiempo <code>O(1)</code>.
    </p>
    <p>
      Necesitamos un concepto que tenga en cuenta ambas cosas. Esto es lo que hace el tiempo amortizado. Nos permite describir que, sí, este peor caso ocurre de vez en cuando. Pero una vez que ocurre, no volverá a ocurrir durante tanto tiempo que el coste está «amortizado».
    </p>
    <p>
      En este caso, ¿cuál es el tiempo amortizado?
    </p>
    <p>
      A medida que insertamos elementos, duplicamos la capacidad cuando el tamaño de la matriz es una potencia de 2. Así, después de X elementos, duplicamos la capacidad con tamaños de matriz <code>1, 2, 4, 8, 16, ..., X</code>. Esa duplicación requiere, respectivamente, <code>1, 2, 4, 8, 16, 32, 64, ..., X</code> copias.
    </p>
    <p>
      ¿Cuál es la suma de <code>1 + 2 + 4 + 8 + 16 + ... + X</code>? Si lees esta suma de izquierda a derecha, empieza por 1 y se duplica hasta llegar a X. Si lees de derecha a izquierda, empieza por X y se reduce a la mitad hasta llegar a 1.
    </p>
    <p>
      ¿Cuál es entonces la suma de <code> X + <sup>x</sup>&frasl;<sub>2</sub> + <sup>x</sup>&frasl;<sub>4</sub> + <sup>x</sup>&frasl;<sub>8</sub> + ... + 1</code>? Es aproximadamente <code>2X</code>.
    </p>
    <p>
      Por lo tanto, las inserciones de X toman <code>O(2X)</code> de tiempo. El tiempo amortizado de cada inserción es <code>O(1)</code>.
    </p>
  </article>
  <article>
    <h3>► Tiempos de ejecución Log N
    </h3>
    <p>
      Es habitual ver tiempos de ejecución <code>O(log N)</code>. ¿De dónde viene esto?
    </p>
    <p>
      Veamos un ejemplo: la búsqueda binaria. En la búsqueda binaria, buscamos un ejemplo x en una matriz ordenada de N elementos. Primero comparamos x con el punto medio de la matriz. <code class="language-js">If x &#60 middle</code>, entonces retornamos. <code class="language-js">If x &#60 middle</code>, buscamos en el lado izquierdo de la matriz. Si x > medio, buscamos en el lado derecho de la matriz.
    </p>
    <pre>
      <code class="language-js">
        search 9 within &#123 1, 5, 8, 9, 11, 13, 15, 19, 21 } 
          compare 9 to 11 -> smaller.
          search 9 within &#123 1, 5, 8, 9, 11 }
            compare 9 to 8 -> bigger
            search 9 within &#123 9, 11 }
              compare 9 to 9
              return
      </code>
    </pre>
    <p>
      Empezamos con una matriz de N-elementos para buscar. Entonces, después de un solo paso, nos quedamos con <sup>N</sup>&frasl;<sub>2</sub> elementos. Un paso más, y estamos hasta <sup>N</sup>&frasl;<sub>4</sub> elementos. Nos detenemos cuando encontramos el valor o nos quedamos con un solo elemento.
    </p>
    <p>
      El tiempo de ejecución total es entonces una cuestión de cuántos pasos (dividiendo N por 2 cada vez) podemos tomar hasta que N se convierte en 1.
    </p>
    <pre>
      <code class="language-js">
        N = 16 
        N = 8         /* divide by 2 */
        N = 4         /* divide by 2 */
        N = 2         /* divide by 2 */
        N = 1         /* divide by 2 */
      </code>
    </pre>
    <p>
      Podríamos verlo a la inversa (yendo de 1 a 16 en lugar de 16 a 1). ¿Cuántas veces podemos multiplicar 1 por 2 hasta obtener N?
    </p>
    <pre>
      <code class="language-js">
        N = 1         /* multiply by 2 */
        N = 2         /* multiply by 2 */
        N = 4         /* multiply by 2 */
        N = 8         /* multiply by 2 */
        N = 16 
      </code>
    </pre>
    <p>
      ¿Qué es kin la expresión <code>2<sup>k</sup> = N</code>? Esto es exactamente lo que expresa <code>log</code>.
    </p>
    <pre>
      <code>
        2<sup>4</sup> = 16 -> log<sub>2</sub>16 = 4
        log<sub>2</sub>N = k -> 2<sup>k</sup> = N
      </code>
    </pre>
    <p>
      Este es un buen aprendizaje para ti. Cuando veas un problema en el que el número de elementos en el espacio del problema se reduce a la mitad cada vez, probablemente será un tiempo de ejecución <code>O(log N)</code>.
    </p>
    <p>
      Esta es la misma razón por la que encontrar un elemento en un árbol de búsqueda binario equilibrado es <code>O(log N)</code>. Con cada comparación, vamos a la izquierda o a la derecha. La mitad de los nodos están en cada lado, así que reducimos el espacio del problema a la mitad cada vez.
    </p>
    <p class="pl-4 sm:pl-6 md:pl-8 border-l-2 sm:border-l-4 md:border-l-8 border-black">
      ¿Cuál es la base del tronco? Es una pregunta excelente. La respuesta corta es que no importa a efectos del gran 0. La explicación más larga se encuentra en «Bases de troncos», en la página 630.
    </p>
  </article>
  <article>
    <h3>► Tiempos de ejecución recursivos</h3>
    <p>
      Esta es una pregunta complicada. ¿Cuál es el tiempo de ejecución de este código?
    </p>
    <pre>
      <code class="language-js">
        int f(int n) &#123
          if (n &#60= 1) &#123
            return 1;
          }
          return f(n - 1) + f(n - 1);
        }
      </code>
    </pre>
    <p>
      Mucha gente, por alguna razón, ve las dos llamadas a f y salta a <code>O(N<sup>2</sup>)</code>. Esto es completamente incorrecto.
    </p>
    <p>
      En lugar de hacer suposiciones, deduzcamos el tiempo de ejecución recorriendo el código. Supongamos que llamamos a <code>f(4)</code>. Esto llama a <code>f(3)</code> dos veces. Cada una de esas llamadas a <code>f(3)</code> llama a <code>f(2)</code>, hasta que llegamos a <code>f(1)</code>.
    </p>
    <div class="flex flex-col justify-center items-center gap-y-2 my-8">
      <div><code>f(4)</code></div>
      <div class="flex gap-4"><div class="w-16 -rotate-12 border-b-2 border-black"></div><div class="w-16 rotate-12 border-b-2 border-black"></div></div>
      
      <div class="flex flex-row gap-32"><code>f(3)</code><code>f(3)</code></div>
      <div class="flex gap-14"><div class="w-8 -rotate-45 border-b-2 border-black"></div><div class="w-8 rotate-45 border-b-2 border-black"></div><div class="w-8 -rotate-45 border-b-2 border-black"></div><div class="w-8 rotate-45 border-b-2 border-black"></div></div>
      
      <div class="flex flex-row gap-12"><code>f(2)</code><code>f(2)</code><code>f(2)</code><code>f(2)</code></div>
      <div class="flex gap-4"><div class="w-8 -rotate-45 border-b-2 border-black"></div><div class="w-8 rotate-45 border-b-2 border-black"></div><div class="w-8 -rotate-45 border-b-2 border-black"></div><div class="w-8 rotate-45 border-b-2 border-black"></div><div class="w-8 -rotate-45 border-b-2 border-black"></div><div class="w-8 rotate-45 border-b-2 border-black"></div><div class="w-8 -rotate-45 border-b-2 border-black"></div><div class="w-8 rotate-45 border-b-2 border-black"></div></div>
      
      <div><code>f(1)</code><code>f(1)</code><code>f(1)</code><code>f(1)</code><code>f(1)</code><code>f(1)</code><code>f(1)</code><code>f(1)</code></div>
    </div>
    <p>
      ¿Cuántas llamadas hay en este árbol? (¡No las cuentes!)
    </p>
    <p>
      El árbol tendrá una profundidad N. Cada nodo (es decir, llamada a una función) tiene dos hijos. Por lo tanto, cada nivel tendrá el doble de llamadas que el anterior.El número de nodos en cada nivel es:
    </p>
    <div class="w-full flex justify-center my-8">
      <table class="font-poppins">
        <thead>
          <tr>
            <td>Level</td>
            <td># Nodes</td>
            <td>Also expressed as...</td>
            <td>O...</td>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>0</td>
            <td>1</td>
            <td></td>
            <td>2<sup>0</sup></td>
          </tr>
          <tr>
            <td>1</td>
            <td>2</td>
            <td>2 * previous level = 2</td>
            <td>2<sup>1</sup></td>
          </tr>
          <tr>
            <td>2</td>
            <td>4</td>
            <td>2 * previous level = 2 * 2<sup>1</sup> = 2<sup>2</sup></td>
            <td>2<sup>2</sup></td>
          </tr>
          <tr>
            <td>3</td>
            <td>8</td>
            <td>2 * previous level = 2 * 2<sup>2</sup> = 2<sup>3</sup></td>
            <td>2<sup>3</sup></td>
          </tr>
          <tr>
            <td>4</td>
            <td>16</td>
            <td>2 * previous level = 2 * 2<sup>3</sup> = 2<sup>4</sup></td>
            <td>2<sup>4</sup></td>
          </tr>
        </tbody>
      </table>
    </div>
    <p>
      Por lo tanto, habrá <code>2<sup>0</sup> + 2<sup>1</sup> + 2<sup>2</sup> + 2<sup>3</sup> + 2<sup>4</sup> + ... + 2<sup>N</sup></code> (que es <code>2<sup>N+1</sup> - 1</code>) nodos.(Ver «Suma de Potencias de 2» en la página 630.)
    </p>
    <p>
      Trate de recordar este patrón. Cuando tienes una función recursiva que hace múltiples llamadas, el tiempo de ejecución a menudo (pero no siempre) se parecerá a <code>O(branches<sup>depth</sup>)</code>, donde branches es el número de veces que cada llamada recursiva se ramifica. En este caso, nos da <code>O(2<sup>N</sup>)</code>.
    </p>
    <p class="pl-4 sm:pl-6 md:pl-8 border-l-2 sm:border-l-4 md:border-l-8 border-black">
      Como recordarás, la base de un logaritmo no importa para big O, ya que los logaritmos de bases diferentes sólo difieren en un factor constante. Sin embargo, esto no se aplica a los exponentes. La base de un exponente sí importa. Compara <code>2<sup>n</sup></code> y <code>8<sup>n</sup></code>. Si expandes <code>8<sup>n</sup></code>, obtienes <code>(2<sup>3</sup>)<sup>n</sup></code>, que es igual a <code>2<sup>3n</sup></code>, que es igual <code>2<sup>2n</sup> * 2<sup>n</sup></code>. Como puedes ver, <code>8<sup>n</sup></code> y <code>2<sup>n</sup></code> son diferentes por un factor de <code>2<sup>2n</sup></code>. Esto no es un factor constante.
    </p>
    <p>
      La complejidad espacial de este algoritmo será <code>O(N)</code>. Aunque tengamos <code>O(2<sup>N</sup>)</code> nodos en el árbol en total, sólo <code>O(N)</code> existen en un momento dado. Por lo tanto, sólo necesitaríamos tener <code>O(N)</code> de memoria disponible.
    </p>
  </article>
  <article>
    <h3>► Ejemplos y ejercicios</h3>
    <p>
      El tiempo O grande es un concepto difícil al principio. Sin embargo, una vez que se entiende, resulta bastante fácil. Los mismos patrones aparecen una y otra vez, y el resto se puede deducir.
    </p>
    <p>
      Empezaremos por lo fácil y nos iremos complicando progresivamente.
    </p>
    <p><strong>
      Ejemplo 1</strong>
    </p>
    <p>
      ¿Cuál es el tiempo de ejecución del siguiente código?
    </p>
    <pre>
      <code class="language-js">
        void foo(int[] array) &#123
          int sum = 0;
          int product = 1;
          for (int i = 0; i  &#60 array.length; i++) &#123
            sum += array[i);
          }
          for (int i = 0; i  &#60 array.length; i++) &#123
            product *= array[i];
          }
          System.out.println(sum + ", " + product);
        }
      </code>
    </pre>
    <p>
      Esto llevará <code>O(N)</code> tiempo. El hecho de que iteremos a través del array dos veces no importa.
    </p>
    <p>
      <strong>Ejemplo 2</strong>
    </p>
    <p>
      ¿Cuál es el tiempo de ejecución del siguiente código?
    </p>
    <p>
      El bucle for interno tiene <code>O(N)</code> iteraciones y es llamado <code>N</code> veces. Por lo tanto, el tiempo de ejecución es <code>O(N<sup>2</sup>)</code>.
    </p>
    <p>
      Otra forma de ver esto es inspeccionando cuál es el «significado» del código. Está imprimiendo todos los pares (secuencias de dos elementos). Hay <code>O(N<sup>2</sup>)</code> pares; por lo tanto, el tiempo de ejecución es <code>O(N<sup>2</sup>)</code>.
    </p>
    <p>
      <strong>Ejemplo 3</strong>
    </p>
    <p>
      Se trata de un código muy similar al del ejemplo anterior, pero ahora el bucle for interior comienza en <code>i + 1</code>.
    </p>
    <pre>
      <code class="language-js">
        void printUnorderedPairs(int[] array) &#123
          for (int i = 0; i &#60 array.length; i++) &#123
            for (int j = i + 1; j &#60 array.length; j++) &#123
              System.out.println(array[i] + "," + array[j]);
            }
          }
        }
      </code>
    </pre>
    <p>
      Podemos obtener el tiempo de ejecución de varias maneras.
    </p>
    <p class="pl-4 sm:pl-6 md:pl-8 border-l-2 sm:border-l-4 md:border-l-8 border-black">
      Este patrón de bucle for es muy común. Es importante que conozcas el tiempo de ejecución y que lo entiendas en profundidad. No puedes confiar sólo en memorizar tiempos de ejecución comunes. La comprensión profunda es importante.
    </p>
    <p><em>Recuento de las iteraciones</em>
    </p>
    <p>
      La primera vez a través de j se ejecuta durante <code>N-1</code> pasos. La segunda vez, son <code>N-2</code> pasos. Luego <code>N-3</code> pasos. Y así sucesivamente. 
    </p>
    <p>
      Por lo tanto, el número total de pasos es:
    </p>
    <pre>
      <code class="language-js">
        (N-1) + (N-2) + (N-3) + ... + 2 + 1
            = 1 + 2 + 3 + ... + N-1
            = sum of 1 through N-1
      </code>
    </pre>
    <p>
      La suma de 1 a <code>N-1</code> es <span class="relative w-12 px-4 leading-3"><sup class="absolute w-12 h-2 border-b-2 text-center border-black">N(N-1)</sup><sub class="ml-4 mr-4 leading-3">2</sub></span> (ver "Suma de Enteros 1 a N" en la página 630), por lo que el tiempo de ejecución será <code>O(N<sup>2</sup>)</code>. 
    </p>
    <p><em>Qué significa</em>
    </p>
    <p>
      Alternativamente, podemos calcular el tiempo de ejecución pensando en lo que «significa» el código: Recorre cada par de valores para <code>(i, j)</code> donde <code>j</code> es mayor que <code>i</code>. 
    </p>
    <p>
      Hay <code>N<sup>2</sup></code> pares en total. Aproximadamente la mitad de ellos tendrán <code>i &#60 j</code> y la otra mitad tendrán <code>i > j</code>. Este código recorre aproximadamente <sup>N<sup>2</sup></sup>&frasl;<sub>x</sub> pares por lo que hace <code>O(N<sup>2</sup>)</code> trabajo.
    </p>
    <p><em>Visualización de lo que hace</em>
    </p>
    <p>
      El código itera a través de los siguientes pares <code>(i, j)</code> cuando <code>N = 8</code>:
    </p>
    <pre>
      <code class="language-js">
        (0, 1) (0, 2) (0, 3) (0, 4) (0, 5) (0, 6) (0, 7) 
               (1, 2) (1, 3) (1, 4) (1, 5) (1, 6) (1,'7) 
                      (2, 3) (2, 4) (2, 5) (2, 6) (2, 7) 
                             (3, 4) (3, 5) (3, 6) (3, 7) 
                                    (4, 5) (4, 6) (4, 7) 
                                           (5, 6) (5, 7) 
                                                  (6, 7)
      </code>
    </pre>
    <p>
      Esto parece la mitad de una matriz NxN, que tiene tamaño (aproximadamente) <sup>N<sup>2</sup></sup>&frasl;<sub>x</sub>. Por lo tanto, lleva <code>O(N<sup>2</sup>)</code> tiempo.
    </p>
    <p><em>Trabajo medio</em>
    </p>
    <p>
      Sabemos que el bucle exterior se ejecuta N veces. ¿Cuánto trabajo hace el bucle interior? Varía a lo largo de las iteraciones, pero podemos pensar en la iteración media.
    </p>
    <p>
      ¿Cuál es el valor medio de <code> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10</code>? El valor medio estará en el medio, así que será <em>aproximadamente</em> 5. (Podríamos dar una respuesta más precisa, por supuesto, pero no lo necesitamos para bigO).
    </p>
    <p>
      ¿Y para <code> 1, 2, 3, ... , N</code>? El valor medio en esta secuencia es <code>N/2</code>. 
    </p>
    <p>
      Por lo tanto, como el bucle interno hace <code><sup>N</sup>&frasl;<sub>x</sub></code> trabajo en promedio y se ejecuta <code>N</code> veces, el trabajo total es <code><sup>N<sup>2</sup></sup>&frasl;<sub>x</sub></code>, que es <code>O(N<sup>2</sup>)</code>.
    </p>
    <p>
      <strong>Ejemplo 4</strong>
    </p>
    <p>
      Es similar al anterior, pero ahora tenemos dos matrices diferentes.
    </p>
    <pre>
      <code class="language-js">
        void printUnorderedPairs(int[] arrayA, int[] arrayB) &#123
          for (int i = 0; i &#60 arrayA.length; i++) &#123
            for (int j = 0; j &#60 arrayB.length; j++) &#123
              if (arrayA[i] &#60 arrayB[j]) &#123
                System.out.println(arrayA[i] + "," + arrayB[j]);
              }
            }
          }
        }
      </code>
    </pre>
    <p>
      Podemos dividir este análisis. La sentencia if dentro del bucle for de j es de tiempo <code>O(1)</code> ya que es sólo una secuencia de sentencias de tiempo constante.
    </p>
    <p>
      Ahora tenemos esto:
    </p>
    <pre>
      <code class="language-js">
        void printUnorderedPairs(int[] arrayA, int[] arrayB) &#123
          for (int i= 0; i &#60 arrayA.length; i++) &#123
            for (int j = 0; j &#60 arrayB.length; j++) &#123
              /* 0(1) work*/
            }
          }
        }
      </code>
    </pre>
    <p>
      Por cada elemento de la <code>arrayA</code>, el bucle for interior pasa por b iteraciones, donde <code>b = arrayB.length</code>. <code>If a = arrayA.length</code>, entonces el tiempo de ejecución es <code>O(ab)</code>.
    </p>
    <p>
      Si dijiste <code>O(N<sup>2</sup>)</code>, recuerda tu error para el futuro. No es <code>O(N<sup>2</sup>)</code> porque hay dos entradas diferentes. Ambas importan. Este es un error extremadamente común.
    </p>
    <p>
      <strong>Ejemplo 5</strong>
    </p>
    <p>
      ¿Qué pasa con este extraño trozo de código?
    </p>
    <pre>
      <code class="language-js">
        void printUnorderedPairs(int[] arrayA, int[] arrayB) &#123
          for (int i = 0; i &#60 arrayA.length; i++) &#123
            for (int j = 0; j &#60 arrayB.length; j++) &#123
              for (int k= 0; k &#60 100000; k++) &#123
                System.out.println(arrayA[i] + "," + arrayB[j]);
              }
            }
          }
        }
      </code>
    </pre>
    <p>
      Aquí no ha cambiado nada. 100.000 unidades de trabajo siguen siendo constantes, por lo que el tiempo de ejecución es <code>0(ab)</code>.
    </p>
    <p>
      <strong>Ejemplo 6</strong>
    </p>
    <p>
      El siguiente código invierte una matriz. ¿Cuál es su tiempo de ejecución?
    </p>
    <pre>
      <code class="language-js">
        void reverse(int[] array) &#123
          for (int i= 0; i &#60 array.length / 2; i++) &#123
            int other = array.length - i - 1;
            int temp = array[i];
            array[i] = array[other];
            array[other] = temp;
          }
        }
      </code>
    </pre>
    <p>
      Este algoritmo se ejecuta en tiempo <code>O(N)</code>. El hecho de que sólo recorra la mitad de la matriz (en términos de iteraciones) no afecta al tiempo O grande.
    </p>
    <p>
      <strong>Ejemplo 7</strong>
    </p>
    <p>
      ¿Cuáles de los siguientes algoritmos son equivalentes a <code>O(N)</code>? ¿Por qué?
    </p>
    <ul>
      <li><code>O(N + P)</code>, donde <code>P &#60 <sup>N</sup>&frasl;<sub>2</sub></code>.</li>
      <li><code>O(2N)</code></li>
      <li><code>O(N + log N)</code></li>
      <li><code>O(N + M)</code></li>
    </ul>
    <p>
      Vamos a repasarlas.
    </p>
    <ul>
      <li>Si <code>P &#60 <sup>N</sup>&frasl;<sub>2</sub></code>, entonces sabemos que N es el término dominante por lo que podemos eliminar el <code>O(P)</code>.</li>
      <li><code>O(2N)</code> es <code>O(N)</code> ya que eliminamos las constantes.</li>
      <li><code>O(N)</code> domina a <code>O(log N)</code>, por lo que podemos eliminar <code>O(log N)</code>.</li>
      <li>No hay una relación establecida entre <code>N</code> y <code>M</code>, así que tenemos que mantener ambas variables.</li>
    </ul>
    <p>
      Por tanto, todos menos el último son equivalentes a <code>O(N)</code>.
    </p>
    <p>
      <strong>Ejemplo 8</strong>
    </p>
    <p>
      Supongamos que tenemos un algoritmo que toma un array de cadenas, ordena cada cadena y luego ordena el array completo. ¿Cuál sería el tiempo de ejecución?
    </p>
    <p>
      Muchos candidatos razonarán lo siguiente: ordenar cada cadena es <code>O(N log N)</code> y tenemos que hacerlo para cada cadena, así que eso es <code>O(N * N log N)</code>. También tenemos que ordenar esta matriz, por lo que es un trabajo adicional <code>O(N log N)</code>. Por lo tanto, el tiempo total de ejecución es <code>O(N2 log N + N log N)</code>, que es sólo <code>0(N<sup>2</sup> log N)</code>.
    </p>
    <p>
      Esto es completamente incorrecto. ¿Has detectado el error?
    </p>
    <p>
      El problema es que hemos utilizado <code>N</code> de dos formas distintas. En un caso, es la longitud de la cadena (¿qué cadena?). Y en otro caso, es la longitud de la matriz.
    </p>
    <p>
      En tus entrevistas, puedes evitar este error no utilizando la variable «N» en absoluto, o utilizándola sólo cuando no haya ambigüedad en cuanto a lo que <code>N</code> podría representar.
    </p>
    <p>
      De hecho, yo ni siquiera usaría a y b aquí, o m y n. Es demasiado fácil olvidar cuál es cuál y confundirlas. Un tiempo de ejecución <code>O(a<sup>2</sup>)</code> es completamente diferente de un tiempo de ejecución <code>O(a*b)</code>.
    </p>
    <p>
      Definamos nuevos términos y utilicemos nombres lógicos.
    </p>
    <ul>
      <li>Sea s la longitud de la cadena más larga.</li>
      <li>Sea a la longitud de la matriz.</li>
    </ul>
    <p>
      Ahora podemos trabajar por partes:
    </p>
    <ul>
      <li>Ordenar cada cadena es <code>0(s log s)</code>.</li>
      <li>Tenemos que hacer esto para cada cadena (y hay una cadena), por lo que es <code>0(a*s log s)</code>.</li>
      <li>Ahora tenemos que cortar las cuerdas. Hay cuerdas, así que puede que te sientas inclinado a decir que se tarda <code>O(a log a)</code> tiempo. Esto es lo que dirían la mayoría de los candidatos. También hay que tener en cuenta que hay que comparar las cadenas. Cada comparación de cadenas lleva <code>O(s)</code> tiempo.Hay <code>O(a log a)</code> comparaciones, por lo que esto llevará <code>0(a*s log a)</code> tiempo.</li>
    </ul>
    <p>
      Si sumas estas dos partes, obtienes <code>0(a*s(log a + log s)). 
    </p>
    <p>
      No hay forma de reducirlo más.
    </p>
    <p>
      <strong>Ejemplo 9</strong>
    </p>
    <p>
      El siguiente código simple suma los valores de todos los nodos de un árbol de búsqueda binario equilibrado. ¿Cuál es su tiempo de ejecución?
    </p>
    <pre>
      <code class="language-js">
        int sum(Node node) &#123
          if (node == null) &#123
            return 0;
          }
          return sum(node.left) + node.value + sum(node.right)
        }
      </code>
    </pre>
    <p>
      Que sea un árbol de búsqueda binario no significa que haya un registro en él.
    </p>
    <p>
      Podemos verlo de dos maneras.
    </p>
    <p><em>Qué significa</em>
    </p>
    <p>
      La forma más directa es pensar en lo que esto significa. Este código toca cada nodo del árbol una vez y hace una cantidad de trabajo constante en el tiempo con cada «toque» (excluyendo las llamadas recursivas).
    </p>
    <p>
      Por tanto, el tiempo de ejecución será lineal en función del número de nodos. Si hayN nodos, el tiempo de ejecución es <code>O(N)</code>.
    </p>
    <p><em>Patrón recursivo</em>
    </p>
    <p>
      En la página 44, discutimos un patrón para el tiempo de ejecución de funciones recursivas que tienen múltiples ramas. Intentemos ese enfoque aquí.
    </p>
    <p>
      Dijimos que el tiempo de ejecución de una función recursiva con múltiples ramas es típicamente <code>O(branches<sup>depth</sup>)</code>. Hay dos ramas en cada llamada, así que estamos buscando <code>O(2<sup>depth</sup>)</code>.
    </p>
    <p>
      Llegados a este punto, mucha gente podría suponer que algo ha ido mal, ya que tenemos un algoritmo exponencial: que algo en nuestra lógica es erróneo o que hemos creado sin querer un algoritmo de tiempo exponencial (¡caramba!).
    </p>
    <p>
      La segunda afirmación es correcta. Tenemos un algoritmo de tiempo exponencial, pero no es tan malo como uno podría pensar. Considere qué variable es exponencial con respecto a.
    </p>
    <p>
      ¿Qué es la profundidad? El árbol es un árbol de búsqueda binario equilibrado. Por lo tanto, si hay <code>N</code> nodos totales, entonces <code>depth</code> es aproximadamente <code>log N</code>.
    </p>
    <p>
      Por la ecuación anterior, obtenemos <code>O(2<sup>1og N</sup>)</code>.
    </p>
    <p>
      Recordemos lo que significa <code>log2</code>:
    </p>
    <code>2<sup>P</sup> = Q -> log<sup>2</sup>Q = P</code>
    <p>
      ¿Qué es <code>2<sup>log N</sup></code>? Existe una relación entre 2 y log, así que deberíamos poder simplificar esto.
    </p>
    <p>
      Let <code>P = 2<sup>log N</sup></code>. Por la definición de <code>log<sub>2</sub></code>, podemos escribirlo como <code>log<sub>2</sub>P = log<sub>2</sub>N</code>. Esto significa que <code>P = N</code>.

    </p>
    <pre>
      <code>
        Let P = 2<sup>log N</sup> 
            -> log<sub>2</sub>P = log<sub>2</sub>N 
            -> P = N 
            -> 2<sup>log N</sup> = N
      </code>
    </pre>
    <p>
      Por lo tanto, el tiempo de ejecución de este código es <code>O(N)</code>, donde <code>N</code> es el número de nodos.
    </p>
    <p>
      <strong>Ejemplo 10</strong>
    </p>
    <p>
      El siguiente método comprueba si un número es primo verificando la divisibilidad en números menores que él. Sólo necesita llegar hasta la raíz cuadrada de n porque si n es divisible por un número mayor que su raíz cuadrada entonces es divisible por algo menor que él.
    </p>
    <p>
      Por ejemplo, aunque 33 es divisible por 11 (que es mayor que la raíz cuadrada de 33), el «homólogo» de 11 es 3 (3 * 11 = 33). 33 ya habrá sido eliminado como número primo por 3.
    </p>
    <p>
      ¿Cuál es la complejidad temporal de esta función?
    </p>
    <p>
      Mucha gente se equivoca en esta pregunta. Si eres cuidadoso con tu lógica, es bastante fácil.
    </p>
    <p>
      El trabajo dentro del bucle for es constante. Por lo tanto, sólo necesitamos saber cuántas iteraciones realiza el bucle for en el peor de los casos.
    </p>
    <p>
      El bucle for empezará cuando x = 2 y terminará cuando x * x = n. O, en otras palabras, terminará cuando x=vn (cuando x es igual a la raíz cuadrada de n).
    </p>
    <p>
      Este bucle for es realmente algo como esto
    </p>
    <p>
      Se ejecuta en tiempo O( vn).
    </p>
    <p>
      <strong>Ejemplo 11</strong>
    </p>
    <p>
      ¡El siguiente código calcula n ! (n factorial). ¿Cuál es su complejidad temporal?
    </p>
    <p>
      Esto es sólo una recursión directa de n a n-1 a n-2 hasta 1. Tomará O(n) tiempo.
    </p>
    <p>
      <strong>Ejemplo 12</strong>
    </p>
    <p>
      Este código cuenta todas las permutaciones de una cadena.
    </p>
    <p>
      Esto es (¡muy!) complicado. Podemos pensarlo mirando cuántas veces se llama a la permutación y cuánto tarda cada llamada. Intentaremos obtener un límite superior lo más ajustado posible.
    </p>
    <p>
      ¿Cuántas veces se llama a la permutación en su caso base?
    </p>
    <p>
      Si tuviéramos que generar una permutación, tendríamos que elegir caracteres para cada «ranura»: Supongamos que tenemos 7 caracteres en la cadena. En la primera ranura, tenemos 7 opciones. Una vez elegida la letra, tenemos 6 opciones para el siguiente espacio. (Tenga en cuenta que se trata de 6 opciones para cada una de las 7 opciones anteriores.) A continuación, 5 opciones para la siguiente ranura, y así sucesivamente.
    </p>
    <p>
      Por lo tanto, el número total de opciones es 7 * 6 * 5 * 4 * 3 * 2 * 1,que también se expresa como ¡7! (factorial 7).
    </p>
    <p>
      Esto nos dice que hay n! permutaciones. Por lo tanto, la permutación se llama n ! veces en su caso base (cuando el prefijo es la permutación completa).
    </p>
    <p>
      ¿Cuántas veces se llama a la permutación antes de su caso base?
    </p>
    <p>
      Pero, por supuesto, también tenemos que considerar cuántas veces se llama a las líneas 9 a 12. Imagine un gran árbol de llamadas que represente todas las llamadas. Hay n hojas, como se muestra arriba. Cada hoja está unida a un camino de longitud n. Por lo tanto, sabemos que no habrá más de n * n ! nodos (llamadas a funciones) en este árbol.
    </p>
    <p>
      ¿Cuánto tarda cada llamada a una función?
    </p>
    <p>
      Ejecutar la línea 7 lleva 0(n) tiempo, ya que hay que imprimir cada carácter.
    </p>
    <p>
      Las líneas 10 y 11 también tardarán O(n) tiempo combinadas, debido a la concatenación de cadenas. Observe que la suma de las longitudes de rem, prefix y str. charAt(i) siempre será n.
    </p>
    <p>
      Por tanto, cada nodo de nuestro árbol de llamadas corresponde a 0(n) trabajo.
    </p>
    <p>
      ¿Cuál es el tiempo de ejecución total?
    </p>
    <p>
      Puesto que estamos llamando a la permutación 0(n * n!) veces (como límite superior), y cada una tarda 0(n) veces, el tiempo de ejecución total no excederá de O(n2 * n ! ).
    </p>
    <p>
      A través de matemáticas más complejas, podemos obtener una ecuación de tiempo de ejecución más estricta (aunque no necesariamente una buena expresión de forma cerrada). Es casi seguro que esto quedaría fuera del alcance de cualquier entrevista normal.
    </p>
    <p>
      <strong>Ejemplo 13</strong>
    </p>
    <p>
      El siguiente código calcula el enésimo número de Fibonacci.
    </p>
    <p>
      Podemos utilizar el patrón anterior que habíamos establecido para las llamadas recursivas: O(profundidad de ramas).
    </p>
    <p>
      Hay 2 ramas por llamada, y vamos tan profundo como N, por lo tanto el tiempo de ejecución es O(2N).
    </p>
    <p>
      A través de algunas matemáticas muy complicadas, en realidad podemos obtener un tiempo de ejecución más ajustado. En efecto, el tiempo es exponencial, pero en realidad está más cerca de 0(1. 6 ). La razón de que no sea exactamente 0(2 ) es que, en la parte inferior de la pila de llamadas, a veces sólo hay una llamada. Resulta que muchos de los nodos están en la parte inferior (como ocurre en la mayoría de los árboles), por lo que esta llamada única frente a la doble supone una gran diferencia. Decir O(2N) sería suficiente para el ámbito de una entrevista, sin embargo (y sigue siendo técnicamente correcto, si usted lee la nota sobre big theta en la página 39). Podrías conseguir «puntos extra» si eres capaz de reconocer que en realidad será menos que eso.
    </p>
    <p>
      En general, cuando se ve un algoritmo con múltiples llamadas recursivas, se está ante un tiempo de ejecución exponencial.
    </p>
    <p>
      <strong>Ejemplo 14</strong>
    </p>
    <p>
      El siguiente código imprime todos los números Fibonacci desde O hasta n. ¿Cuál es su complejidad temporal?
    </p>
    <p>
      Mucha gente se apresurará a concluir que como fib(n) tarda 0(2°) veces y es llamado n veces, entonces es O(n2°).
    </p>
    <p>
      No tan rápido. ¿Puedes encontrar el error en la lógica?
    </p>
    <p>
      El error es que n cambia. Sí, fib(n) tarda 0(2°) de tiempo, pero importa cuál sea ese valor de n. 
    </p>
    <p>
      En su lugar, vamos a caminar a través de cada llamada.
    </p>
    <p>
      Por lo tanto, la cantidad total de trabajo es:
    </p>
    <p>
      Como mostramos en la página 44, es 2°+1. Por lo tanto, el tiempo de ejecución para calcular los primeros n números Fibonacci (usando este terrible algoritmo) sigue siendo O(2°).
    </p>
    <p>
      <strong>Ejemplo 15</strong>
    </p>
    <p>
      El siguiente código imprime todos los números Fibonacci de O a n. Sin embargo, esta vez, almacena (es decir, guarda en caché) los valores calculados previamente en una matriz de enteros. Si ya se ha calculado, sólo devuelve la caché. ¿Cuál es su tiempo de ejecución?
    </p>
    <p>
      Veamos lo que hace este algoritmo.
    </p>
    <p>
      En cada llamada a fib(i), ya hemos calculado y almacenado los valores de fib(i-1) y fib(i-2). Simplemente buscamos esos valores, los sumamos, almacenamos el nuevo resultado y volvemos. Esto lleva una cantidad constante de tiempo.
    </p>
    <p>
      Estamos haciendo una cantidad constante de trabajo N veces, por lo que este es O ( n) tiempo.
    </p>
    <p>
      Esta técnica, llamada memoización, es muy común para optimizar algoritmos recursivos de tiempo exponencial.
    </p>
    <p>
      <strong>Ejemplo 16</strong>
    </p>
    <p>
      La siguiente función imprime las potencias de 2 desde 1 hasta n (inclusive). Por ejemplo, si n es 4, imprimiría 1, 2 y 4. ¿Cuál es su tiempo de ejecución?
    </p>
    <p>
      Hay varias formas de calcular este tiempo de ejecución.
    </p>
    <p>
      Qué hace
    </p>
    <p>
      Recorramos una llamada como powers0f2 (50).
    </p>
    <p>
      El tiempo de ejecución, entonces, es el número de veces que podemos dividir 50 (o n) por 2 hasta llegar al caso base (1). Como vimos en la página 44, el número de veces que podemos dividir n por la mitad hasta llegar a 1 es O(log n).
    </p>
    <p>
      Qué significa
    </p>
    <p>
      También podemos aproximarnos al tiempo de ejecución pensando en lo que se supone que está haciendo el código. Se supone que está calculando las potencias de 2 de 1 a n.
    </p>
    <p>
      Cada llamada a potencias0f2 resulta en exactamente un número impreso y devuelto (excluyendo lo que sucede en las llamadas recursivas). Así que si el algoritmo imprime 13 valores al final, entonces powers0f2 fue llamado 13 veces.
    </p>
    <p>
      En este caso, se nos dice que imprime todas las potencias de 2 entre 1 y n. Por lo tanto, el número de veces que se llama a la función (que será su tiempo de ejecución) debe ser igual al número de potencias de 2 entre 1 y n. Hay log N potencias de 2 entre 1 y n. Por lo tanto, el tiempo de ejecución es 0(log n).
    </p>
    <p>
      Hay log N potencias de 2 entre 1 y n. Por tanto, el tiempo de ejecución es 0(log n).
    </p>
    <p>
      Tasa de incremento
    </p>
    <p>
      Una última forma de abordar el tiempo de ejecución es pensar en cómo cambia el tiempo de ejecución a medida que n aumenta. Después de todo, esto es exactamente lo que significa tiempo O grande.
    </p>
    <p>
      Si N pasa de P a P+l, el número de llamadas a powersOfTwo podría no cambiar en absoluto. ¿Cuándo aumentará el número de llamadas a powersOfTwo? Aumentará en 1 cada vez que n duplique su tamaño.
    </p>
    <p>
      Entonces, cada vez que n se duplica, el número de llamadas a potenciasDos aumenta en 1. Por lo tanto, el número de llamadas a potenciasDos es el número de veces que puedes duplicar 1 hasta obtener n. Es x en la ecuación 2x = n.
    </p>
    <p>
      ¿Qué es x? El valor de x es log n. Esto es exactamente lo que significa x log n. 
    </p>
    <p>
      Por lo tanto, el tiempo de ejecución es O(log n).
    </p>
    <h3>
      Problemas adicionales
    </h3>
    <ol>
      <li>
        El siguiente código calcula el producto de a y b. ¿Cuál es su tiempo de ejecución?
      </li>
      <li>
        El siguiente código calcula ab. ¿Cuál es su tiempo de ejecución?
      </li>
      <li>
        El siguiente código calcula a % b. ¿Cuál es su tiempo de ejecución?
      </li>
      <li>
        El siguiente código realiza la división de enteros. ¿Cuál es su tiempo de ejecución (suponiendo que a y b son ambos positivos)?
      </li>
      <li>
        El siguiente código calcula la raíz cuadrada [entera] de un número. Si el número no es un cuadrado perfecto (no hay raíz cuadrada entera), entonces devuelve -1. Lo hace por conjeturas sucesivas. Si n es 100, primero adivina SO. ¿Demasiado alto? Prueba con algo más bajo, a medio camino entre 1 y SO. ¿Cuál es su tiempo de ejecución?
      </li>
      <li>
        El siguiente código calcula la raíz cuadrada [entera] de un número. Si el número no es cuadrado perfecto (no hay raíz cuadrada entera), entonces devuelve -1. Lo hace probando con números cada vez más grandes hasta que encuentra el valor correcto (o es demasiado alto). ¿Cuál es su tiempo de ejecución?
      </li>
      <li>
        Si un árbol de búsqueda binario no está equilibrado, ¿cuánto tiempo puede tardar (en el peor de los casos) en encontrar un elemento?
      </li>
      <li>
        Estás buscando un valor específico en un árbol binario, pero el árbol no es un árbol de búsqueda binario. ¿Cuál es su complejidad temporal?
      </li>
      <li>
        El método appendToNew añade un valor a un array creando un nuevo array más largo y devolviendo este array más largo. Has utilizado el método appendToNew para crear una función copyArray que llama repetidamente a appendToNew. ¿Cuánto tarda en copiarse un array?
      </li>
      <li>
        El siguiente código suma los dígitos de un número. ¿Cuál es su tiempo O grande?
      </li>
      <li>
        El siguiente código imprime todas las cadenas de longitud k en las que los caracteres están ordenados. Para ello, genera todas las cadenas de longitud k y comprueba si cada una está ordenada. ¿Cuál es su tiempo de ejecución?
      </li>
      <li>
        El siguiente código calcula la intersección (el número de elementos en común) de dos matrices. Asume que ninguna de las dos matrices tiene duplicados. Calcula la intersección ordenando una matriz (matriz b) y luego iterando a través de la matriz a comprobando (mediante búsqueda binaria) si cada valor está en b. ¿Cuál es su tiempo de ejecución?
      </li>
    </ol>
    
    <h3>Soluciones</h3>
    <ol>
      <li>
        1. O(b). El bucle for sólo itera a través de b.
      </li>
      <li>
        2. 0(b). El código recursivo itera a través de b llamadas, ya que resta uno en cada nivel.
      </li>
      <li>
        3. 0(1). Hace una cantidad constante de trabajo.
      </li>
      <li>
        4. 0( X ). La variable count eventualmente será igual a X. El bucle while itera count veces. Por lo tanto, itera X veces.
      </li>
      <li>
        5. 0(log n). Este algoritmo es esencialmente hacer una búsqueda binaria para encontrar la raíz cuadrada. Por lo tanto, el tiempo de ejecución es O(log n).
      </li>
      <li>
        6. O(sqrt(n)). Esto es sólo un bucle directo que se detiene cuando guess*guess > n (o, en otras palabras, cuando guess > sqrt(n)).
      </li>
      <li>
        7. O(n), donde n es el número de nodos del árbol. El tiempo máximo para encontrar un elemento es la profundidad árbol.El árbol podría ser una lista recta hacia abajo y tienen profundidad n.
      </li>
      <li>
        8. O(n). Sin ninguna propiedad de ordenación en los nodos, podríamos tener que buscar a través de todos los nodos.
      </li>
      <li>
        9. O(n2), donde n es el número de elementos de la matriz. La primera llamada a append To New requiere 1 copia, la segunda 2 copias, la tercera 3 copias y así sucesivamente. El tiempo total será la suma de 1 a n, que es O(n2).
      </li>
      <li>
        10. El tiempo de ejecución será el número de dígitos del número. Un número con d dígitos puede tener un valor de hasta 10d. Si n = 10d, entonces d = log n. Por lo tanto, el tiempo de ejecución es 0(log n).
      </li>
      <li>
        11. 0(kck), siendo k la longitud de la cadena y c el número de caracteres del alfabeto. Se tarda 0(c k) de tiempo en generar cada cadena. Luego, hay que comprobar que cada una de ellas está ordenada, lo que lleva O(k) tiempo.
      </li>
      <li>
        12. 0(b log b + a log b).Primero, tenemos que ordenar el array b, lo que lleva O(b log b) tiempo. Luego, para cada elemento de a, hacemos una búsqueda binaria en tiempo 0(log b). La segunda parte tarda O(a log b).
      </li>
      <li>
      </li>
    </ol>
  </article>
  <footer class="flex justify-end">
    <a class="font-khand font-bold text-3xl py-4 sm:py-8 md:py-12 sm:text-4xl md:text-5xl" href="parte-7">
      <div class="transition-all text-nowrap relative ease-linear duration-500 w-28 sm:w-40 md:w-52
      hover:w-36 sm:hover:w-48 md:hover:w-56  hover:text-sky-500
      after:content-['↦'] after:text-red-500 after:transition-all after:ease-linear after:duration-500 after:opacity-0 after:relative after:-left-3 
      hover:after:content-['↦'] hover:after:transition-all hover:after:ease-linear hover:after:duration-500 hover:after:opacity-100 hover:after:left-3"> Parte VII</div>
    </a>
  </footer>
</Layoutcracking>